{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dead51b72fd1a250e0a7d49699201f26",
     "grade": false,
     "grade_id": "cell-f25302677986d7e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 5: Confidence Intervals Based on the Central Limit Theorem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8573ead45801fb3b80a0259bb97b6c97",
     "grade": false,
     "grade_id": "cell-e9bf9d37265bf582",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lecture and Tutorial Learning Goals:\n",
    "From this section, students are expected to be able to:\n",
    "\n",
    "1. Explain the role of the Central Limit Theorem in constructing confidence intervals.\n",
    "2. Describe the $t$-distribution family and its relationship with the normal distribution.\n",
    "3. Write a computer script to calculate confidence intervals based on distributional assumptions.\n",
    "4. Calculate z-scores.\n",
    "5. Discuss the potential limitations of these methods.\n",
    "6. Decide whether to use asymptotic theory or bootstrapping to compute estimator uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b18bf60a963c9751ee8bad7192c9167c",
     "grade": false,
     "grade_id": "cell-e285d20b2c0dc818",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(datateachr)\n",
    "library(digest)\n",
    "library(infer)\n",
    "library(gridExtra)\n",
    "library(cowplot)\n",
    "penguins <- read.csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\")\n",
    "source(\"tests_worksheet_05.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f16115ce4ea943e2feadfabdcf21d72c",
     "grade": false,
     "grade_id": "cell-5af6102ed3b34159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Short Recap & Warm-Up\n",
    "\n",
    "Before we start exploring the new material for this week, let's remind ourselves of some of the most important points that we covered in the previous week by answering a couple of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a60a48c0af8c88e1e69965ed0b528831",
     "grade": false,
     "grade_id": "cell-7851c9b637f7df2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "In Module 4, you calculated confidence intervals based on a simulation method: bootstrapping. What is one use of bootstrapping? \n",
    "\n",
    "A. Since bootstrapping resamples from our original sample many times, it helps reduce the variability of our statistic, which allows us to obtain narrower confidence intervals.  \n",
    "\n",
    "B. Bootstrapping does not improve the quality of our estimate. Bootstrapping just allows us to study the sampling distribution of our statistic, which would be otherwise unknown.\n",
    "\n",
    "C. Bootstrapping allows us to estimate the center as well as the variability of the sampling distribution of our statistic.\n",
    "\n",
    "D. Bootstraping estimates the population parameter.\n",
    "\n",
    "_Assign your answer to an object called `answer1.0`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbdb4a1b13a97ce2d932d6cfa6384599",
     "grade": false,
     "grade_id": "cell-5bd2ecd6c9b3b46e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.0 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32e9f2f19d394d71860f68421e91eabe",
     "grade": true,
     "grade_id": "cell-4a12caec5d6c5346",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "319bcacd5ee641745d7b4bd5ff52b926",
     "grade": false,
     "grade_id": "cell-e17615d6ad9efeb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Obtaining confidence intervals based on the CLT\n",
    "\n",
    "In this section, you will explore how to obtain the confidence interval for the proportion and mean using the Central Limit Theorem. Remember that to calculate a confidence interval for a parameter (e.g., the population mean) using bootstrap you had to:\n",
    "\n",
    "1. Take a sample;\n",
    "2. Construct the bootstrap sampling distribution. \n",
    "3. Get the quantiles from the estimated sampling distribution. \n",
    "\n",
    "Now, the only thing that will change here is that we are going to use the CLT instead of bootstrap to estimate the sampling distribution (in some cases -- remember that CLT is not always applicable). Therefore, you get to skip Step 2 because you will approximate the sampling distribution using the Normal distribution (or as we will see later the $t$-distribution for the sample mean). \n",
    "\n",
    "We will be focused on two parameters in this section: proportion and mean.\n",
    "\n",
    "For many of the following questions, we will use the `penguins` dataset, which contains the body mass of multiple penguin species. Run the following code, to extract the body mass of Adelie penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71c08379d58496a4736390f58e319525",
     "grade": false,
     "grade_id": "cell-e17615d6ad9efeb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "body_mass_g_adelie <- \n",
    "    penguins %>% \n",
    "    filter(species == 'Adelie' & !is.na(body_mass_g)) %>% \n",
    "    pull(body_mass_g)\n",
    "body_mass_g_adelie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffed265ef95ee5c6e987cbd15903d525",
     "grade": false,
     "grade_id": "cell-792a2542da99d1ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0 - Estimating the proportion using CLT**\n",
    "<br>{points: 1}\n",
    "\n",
    "For this question, we want to estimate the proportion of `Adelie` penguins with `body_mass_g` over 4000g.\n",
    "\n",
    "You are going to apply the CLT to obtain the confidence interval for the proportion. A proportion is the average of a random variable that can only assume either 0 or 1. Therefore, by calculating proportions, you are summing up random terms, and we can apply the CLT. The CLT for proportions states that the sample proportion follows a Normal distribution with mean equals to $p$, the population proportion, and standard deviation $\\sqrt{p(1-p)/n}$:\n",
    "$$\n",
    "\\hat{p}\\sim N\\left(p, \\sqrt{\\frac{p(1-p)}{n}}\\right)\n",
    "$$\n",
    "\n",
    "Since, we do not know $p$, the best we can do is to use $\\hat{p}$ instead of $p$. For the case of proportions, the CLT provides a fairly good approximation for values of $n$ such that $n\\hat{p}\\geq 10$ and $n(1-\\hat{p})\\geq 10$. Again, the larger $n$ is, the more accurate is the approximation. \n",
    "\n",
    "\n",
    " What would you use as the mean and standard deviation of the sampling distribution of $\\hat{p}$? \n",
    "\n",
    "_Assign the mean to an object called `answer2.0_mean` and the standard deviation to an object called `answer2.0_std_error`. These objects should be numbers, not data frames._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57e6b6aa75a11d3841265f1dfc3fbaa5",
     "grade": false,
     "grade_id": "cell-bb4eb112247eaf06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#phat <- mean(...)\n",
    "#answer2.0_mean <- ... \n",
    "#answer2.0_std_error <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "cat(\"The phat estimate is\", round(phat,4), \"\\nThe std. error estimate is\", round(answer2.0_std_error,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3d459bc43d369b5f33d1893249fedd1",
     "grade": true,
     "grade_id": "cell-e5ae1dc9ef00b7e8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07670fd3b0a3f0b697e8c677333bc396",
     "grade": false,
     "grade_id": "cell-34cf808878a5a645",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Using the sampling distribution you specified in the previous question, obtain a 90\\%  confidence interval for the proportion of `Adelie` penguins with `body_mass_g` over 4000g. Use the scaffolding below:\n",
    "\n",
    "```r\n",
    "prop_adelie_ci <- tibble(\n",
    "    lower_ci = ...,\n",
    "    upper_ci = ...\n",
    ")\n",
    "```\n",
    "(Hint: the function `qnorm` can help you).\n",
    "\n",
    "_Assign your data frame to an object called `prop_adelie_ci`. The data frame should contain two columns only: `lower_ci` and `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ead6058fabacb18b4e3ffc95ba2288f",
     "grade": false,
     "grade_id": "cell-010a58d81b219cd3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(prop_adelie_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d67ceca1ecd1dd73d0c0a838d78141b2",
     "grade": true,
     "grade_id": "cell-d120a19aedf198fc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a7572a21338d287933ac666d25cb4e5",
     "grade": false,
     "grade_id": "cell-ada4e5b7b77d206a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2 - Estimating the mean using CLT**\n",
    "<br>{points: 1}\n",
    "\n",
    "To estimate the population mean, we use the sample average, $\\bar{X}$. The CLT roughly says that $\\bar{X}$ follows a Normal distribution with parameters $\\mu$ and $\\frac{\\sigma}{\\sqrt{n}}$:\n",
    "$$\n",
    "\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n",
    "$$\n",
    "Since we do not know $\\mu$ and $\\sigma$ we replace them with their estimates $\\bar{x}$ and $s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2}$ (you can calculate $s$ with the `sd` function in R).\n",
    "\n",
    "\n",
    "For this question, consider the `penguins` dataset. We want to estimate the mean `body_mass_g` of the `Adelie` species. What would you use as the mean and standard deviation of the sampling distribution of $\\bar{X}$? \n",
    "\n",
    "_Assign the mean to an object called `answer2.2_mean` and the standard deviation to an object called `answer2.2_std_error`. These values should be numbers, not data frames._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df7ebffcb797dbbe988bc74ff044f853",
     "grade": false,
     "grade_id": "cell-c271d6b73d562521",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.2_mean <- \n",
    "#    mean(..., na.rm = TRUE)\n",
    "\n",
    "#answer2.2_std_error <-\n",
    "#    sd(..., na.rm = TRUE) / ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "cat(\"The mean estimate is\", round(answer2.2_mean,4), \"\\nThe std. error estimate is\", round(answer2.2_std_error, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d62d73eeed81d18d8144be124027ae7",
     "grade": true,
     "grade_id": "cell-817e982e570fe86e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "790b887aa36896fdfc0389058a1d8214",
     "grade": false,
     "grade_id": "cell-512429054f09c03b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Using the sampling distribution you specified in the previous question, obtain a 95\\%  confidence interval for the mean. Use the scaffolding below:\n",
    "\n",
    "```r\n",
    "body_mass_ci <- tibble(\n",
    "    lower_ci = qnorm(..., ..., ...),\n",
    "    upper_ci = qnorm(..., ..., ...)\n",
    ")\n",
    "```\n",
    "While we will use the $t$-distribution below, here we will first explore the Normal distribution.\n",
    "\n",
    "_Assign your data frame to an object called `mean_body_mass_adelie_ci`. The data frame should contain two columns only: `lower_ci` and `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a5ef2e55be1dc6daa7b3dc6539b8e39",
     "grade": false,
     "grade_id": "cell-45aa3ef0abf1831c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# mean_body_mass_adelie_ci <-\n",
    "#     tibble(\n",
    "#         lower_ci = qnorm(0.025, ..., ...),\n",
    "#         upper_ci = qnorm(..., ..., ...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "mean_body_mass_adelie_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bab136ff8f98fe8a038975dd1847555",
     "grade": true,
     "grade_id": "cell-075ecde878f0fad0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ee49c3244a709e2bd58cf75ec9d80c9",
     "grade": false,
     "grade_id": "cell-f7cee08f7346b6be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br> {points: 1}\n",
    "\n",
    "For the sake of comparison, obtain a 95% confidence interval for the mean `body_mass_g` of `Adelie` specie using bootstrap with 3000 replicates. You can use the scaffolding below to help you:\n",
    "\n",
    "```r\n",
    "bootstrap_ci <- \n",
    "    penguins %>% \n",
    "    filter(...) %>% \n",
    "    specify(...) %>% \n",
    "    generate(...) %>% \n",
    "    calculate(...) %>% \n",
    "    get_ci()\n",
    "```\n",
    "\n",
    "_Assign your data frame to an object called `bootstrap_ci`. The data frame should contain two columns only: `lower_ci` and `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e757e9079abe9ccd23ce75cc30879dc",
     "grade": false,
     "grade_id": "cell-9c99694899d1f5ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(54612) # Do not change this.\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01ae33e506fbca32073d68042844573e",
     "grade": true,
     "grade_id": "cell-dd345adb6ddbbf71",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cf2e9a3952904b0edae2ce577fc9a3b",
     "grade": false,
     "grade_id": "cell-6d12a522b751be1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_Note: The bootstrap and CLT confidence intervals are quite close in this case, but the bootstrap interval is a little bit wider than the interval based on the CLT. One of the reasons is that we do not know $\\sigma$, and we are using the sample standard deviation, $s$, to estimate it. Therefore, there is more uncertainty around our estimator $\\bar{X}$ than we are accounting for. By underestimating our uncertainty, we are making our interval narrower than it should be and, consequently, the coverage can be lower than the specified. Although in this case the difference is small, in cases of smaller sample sizes, say $n<30$ or $n<20$, the difference can be notable. In question 3, you will learn how to improve the confidence interval based on the CLT by properly accounting for the extra uncertainty of using $s$ in place of $\\sigma$._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a5f2f9d2de204f00264dd86ce22c400",
     "grade": false,
     "grade_id": "cell-ed779909e05c6d10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Student's t Distribution (or, $t$-distribution)\n",
    "\n",
    "The $t$-distribution family is quite similar to the standard Normal distribution:\n",
    "- it is symmetric;\n",
    "- it is bell-shaped;\n",
    "- it is unimodal;\n",
    "\n",
    "Run the cell below to see a plot of some $t$-distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac66856386f18e4f96d5534e0dea38c4",
     "grade": false,
     "grade_id": "cell-c77e09df133080cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=7)\n",
    "\n",
    "densities <- \n",
    "    tibble(degrees_of_freedom = c(1, 5, 10)) %>% \n",
    "    mutate(tdensity = map(degrees_of_freedom, ~tibble(x = seq(-4, 4, 0.01),\n",
    "                                     t_density = dt(x,.x),\n",
    "                                     std_Gaussian = dnorm(x) ))) %>% \n",
    "    mutate(degrees_of_freedom = as_factor(degrees_of_freedom)) %>% \n",
    "    unnest(tdensity)\n",
    "    \n",
    "\n",
    "densities %>% \n",
    "    ggplot() +\n",
    "    geom_line(aes(x, t_density, color = degrees_of_freedom)) + \n",
    "    geom_line(aes(x, std_Gaussian), lwd = 1.2) + \n",
    "    ggtitle(\"Densities of t-Distributions and Standard Gaussian (the thicker black line)\") + \n",
    "    ylab(\"Density\") + \n",
    "    theme(text = element_text(size=20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "595bf0168f9ac0d9818235872add2b6f",
     "grade": false,
     "grade_id": "cell-83597fc22c9da81e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Although $t$-distributions are very similar to the Standard Gaussian distribution, there are some key differences. A $t$-distribution:\n",
    "\n",
    "- is always centred around 0.\n",
    "- has only one parameter: the degrees of freedom (which controls the spread)\n",
    "- has heavier tails (mostly for low values of degrees of freedom)\n",
    "- converges to the Normal distribution for large degrees of freedom (it does not need to be very large, a $t$-distribution with 50 or more degrees of freedom is almost identical to the Normal distribution).\n",
    "\n",
    "The heavier tails of the t-distribution allow us to account for \"additional\" uncertainty compared to the Normal distribution. In fact, that was the reason it came up. The t-distribution family was found by William Gosset, an employee at Guinness Brewery, when studying the error around the sample mean for small samples (so, CLT was not applicable). The story behind $t$-Distribution is quite interesting, and you can read more [here](https://priceonomics.com/the-guinness-brewer-who-revolutionized-statistics/) if you are curious.\n",
    "\n",
    "To understand better the heavier tails of the $t$-distributions, let us discuss an example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6e0a9e6c0b33b8065d93d6fa9d1e758",
     "grade": false,
     "grade_id": "cell-40eae262499f58c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing. \n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "mu = 1.7\n",
    "sigma = 0.07\n",
    "gaussian_pop <- \n",
    "    tibble(height = rnorm(10000, mu, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df5716a9581ae677be1ad199752332d1",
     "grade": false,
     "grade_id": "cell-4628997437de3e10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "In the tibble `gaussian_pop`, we measured the height of 10,000 people, which will be our population of interest. Let us take a look at the population distribution. Use the scaffolding provided in the code box below to plot the histogram with the normal distribution.\n",
    "\n",
    "Note that the Normal distribution is often called the Gaussian distribution.\n",
    "\n",
    "_Assign your answer to an object named `gaussian_pop_dist`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5d8145fb5b072af494cbd8fd1b492b9",
     "grade": false,
     "grade_id": "cell-f16aa82937997e64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# gaussian_pop_dist <- \n",
    "#     ... %>%   \n",
    "#     ... +\n",
    "#     ...(aes(..., y = after_stat(density)), color = 'white') +\n",
    "#     geom_line(data = tibble(x = seq(mu - 3.5*sigma, mu + 3.5*sigma, 0.01), \n",
    "#                             density = dnorm(x, mu, sigma)), \n",
    "#               aes(x = x, y = density), color = \"red\", lwd = 2) +\n",
    "#     ggtitle(...) +\n",
    "#     theme(text = element_text(size = 22))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "gaussian_pop_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4b9e993a2ca14e38cd4ee0a1321c572",
     "grade": true,
     "grade_id": "cell-4e3592460e341c52",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "813f809c66c66b76a3db69f88be0b383",
     "grade": false,
     "grade_id": "cell-7041748307409496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2**\n",
    "<br> {points: 1}\n",
    "\n",
    "In Module 03, we saw that the Central Limit Theorem roughly states that the sampling distribution of the sample mean converges to $N\\left(\\mu, \\sigma/\\sqrt{n}\\right)$, where $\\mu$ and $\\sigma$ are, respectively, the mean and standard deviation of the population. But what is the distribution of the sample mean for small sample sizes? Unfortunately, it will be highly dependent on the population distribution. If the population is normally distributed, the sampling distribution of the mean is also normally distributed. More specifically, it is $N\\left(\\mu, \\sigma/\\sqrt{n}\\right)$. \n",
    "\n",
    "The previous question clearly showed that our population follows a Normal distribution. Now, we are going to draw a large number of **small** samples from the population and calculate their sample means. But this time, we want to standardize the sample means by calculating the Z-score:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x}_i - \\mu}{\\sigma/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "We are still pretending that we know $\\mu$ and $\\sigma$, which are stored in the `mu` and `sigma` variables, respectively. Our Z-score distribution will be the Standard Normal, i.e., $N(0,1)$. \n",
    "\n",
    "Here's your job:\n",
    "\n",
    "1. draw 2000 samples of size seven from the `gaussian_pop`;\n",
    "2. for each sample, calculate the sample average;\n",
    "3. then, obtain the transformed Z-scores of the sample averages and store them in a column named `z`;\n",
    "\n",
    "_Assign your data frame to an object called `zscore_sample_means`. The data frame should have three columns `replicate`, `sample_mean` and `z`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aafc417386fb056ff3fe525b7e7b240c",
     "grade": false,
     "grade_id": "cell-9d2c2dd1c3c43a64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(89) # Do not change this\n",
    "n <- 7\n",
    "\n",
    "# zscore_sample_means <-\n",
    "#     gaussian_pop %>% \n",
    "#     rep_sample_n(...) %>% \n",
    "#     group_by(...) %>% \n",
    "#     summarise(sample_mean = ...) %>% \n",
    "#     mutate(z = ... )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(zscore_sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "872978bb19ab00824b7f216d82eb0f54",
     "grade": true,
     "grade_id": "cell-c51d9be59541f814",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a45ccd0254e3caae6b18657407c0ed6",
     "grade": false,
     "grade_id": "cell-9500a6592baa41e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br> {points: 1}\n",
    "\n",
    "Compare the sampling distribution of the z-scores of the sample mean that you obtained in the previous question with the density line of a $N(0, 1)$. Use `binwidth` equals 0.3.\n",
    "\n",
    "_Assign your plot to an object called `sampling_dist_sample_mean_z`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "392ba7152065194a33555335fd80e042",
     "grade": false,
     "grade_id": "cell-149d7a16a57d0af2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sampling_dist_sample_mean_z <- \n",
    "#     ... %>% \n",
    "#     ... + \n",
    "#     geom_...(aes(..., after_stat(density)), color = 'white', binwidth = ...) + \n",
    "#     geom_line(data = tibble(x = seq(-3.5, 3.5, 0.01), \n",
    "#                             density = dnorm(x, 0, 1)), \n",
    "#               aes(x = x, y = density), color = \"red\", lwd = 2) +\n",
    "#     theme(text = element_text(size = 22)) +\n",
    "#     xlab(\"Sample Mean of Z-score\") +\n",
    "#     ggtitle(\"Sampling distribution of the Z-scores of the sample mean vs Standard Normal density\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "sampling_dist_sample_mean_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c768a782e356d1cc2324f16c12cd0c5b",
     "grade": true,
     "grade_id": "cell-9e7679510421fd2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "122a052da6d6724c517a31fd41fa39b3",
     "grade": false,
     "grade_id": "cell-5e7920cd01f0e699",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.4**\n",
    "<br> {points: 1}\n",
    "\n",
    "In the previous question, you used the population standard deviation (which almost always is unknown) to calculate the z-scores. What can we do in the cases we do not know the true value of $\\sigma$? A reasonable answer would be to use the sample standard deviation, $s$. However, by using this approach, there will be an increase in uncertainty. The value of $\\sigma$ is fixed, a constant that is just unknown. If we use $s$ instead, we are replacing a constant $\\sigma$ with a random variable that changes from sample to sample. Therefore, it would certainly increase our uncertainty as the formula for the z-score now is changing from sample to sample. Would this additional uncertainty affect the sampling distribution of the z-scores of the sample mean? Take a minute to think about this. What do you expect to happen to the sampling distribution above if we have this extra layer of uncertainty?\n",
    "\n",
    "In this exercise, you are going to:\n",
    "1. take 10000 samples of size $n=7$\n",
    "2. calculate the sample average and sample standard deviation of each sample, store them in  variables named `sample_mean` and `sample_sd`, respectively\n",
    "3. calculate the z-scores of the sample average, but this time using $s$ instead of $\\sigma$, store them in a column called `z`\n",
    "4. plot the histogram of the z-scores\n",
    "5. plot the density line of the $N(0, 1)$\n",
    "6. plot the density line of the $t_{6}$\n",
    "\n",
    "Note that $t_6$ means that it's a $t$-distribution with 6 degrees of freedom. The $t$-distribution associated with the sample mean has $n-1$ degrees of freedom. It is 6 here, because the sample size is 7. \n",
    "\n",
    "The scaffolding below is provided to help you accomplish these steps. \n",
    "Pay close attention to the tails of the distributions.\n",
    "\n",
    "_Assign your plot to an object called `sampling_dist_zscore_s`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0ef40dfa988c56cd092de4b56a53f55",
     "grade": false,
     "grade_id": "cell-0b53f7183cb0d781",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(5) # Do not change this\n",
    "\n",
    "# n <- ...\n",
    "# sampling_dist_zscore_s <-\n",
    "#     ... %>% \n",
    "#     rep_sample_n(reps = ..., size = n, replace = ...) %>% \n",
    "#     group_by(...) %>% \n",
    "#     summarise(sample_mean = ..., sample_sd = ...) %>% \n",
    "#     mutate(z = ...) %>% \n",
    "#     ggplot() +\n",
    "#     ...(aes(..., after_stat(density)), color = 'white', binwidth = 0.3) + \n",
    "#     geom_line(data = tibble(x = seq(-3.5, 3.5, 0.01), \n",
    "#        std_normal = dnorm(x, 0, 1), \n",
    "#        t = dt(x, n-1)) %>% pivot_longer(cols = c(std_normal, t), names_to = \"distribution\", values_to = \"density\"), \n",
    "#               aes(x = x, y = density, color = distribution), lwd = 2) +\n",
    "#     theme(text = element_text(size = 22)) + \n",
    "#     xlab(\"Sample Mean of Z-score\") +\n",
    "#     ggtitle(...) +\n",
    "#     xlim(-4, 4)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "sampling_dist_zscore_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4aac6887e420644671055b85cd3f390",
     "grade": true,
     "grade_id": "cell-a9dbd7b65d217f3b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2562286f558f98d4ab075bac8e3b7f5",
     "grade": false,
     "grade_id": "cell-52703efe93dc8b14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please take a close look at the distribution's tails and note how our Z-Scores are more spread. If we use the normal distribution to approximate this sampling distribution, we will end up with narrower confidence intervals than we should. Remember when you compared the bootstrap confidence interval with the CLT confidence interval in the previous worksheet? However, for larger sample sizes, the t-distribution becomes much closer to the normal distribution, and the difference of using the normal distribution instead of t-distribution diminishes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3d4c312719f35ac9797819b5f37ce01",
     "grade": false,
     "grade_id": "cell-ed779909e05c6d20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Further comparisons between confidence intervals based on the Normal and the t-distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf9c58e46ada51b6f572f3ce84e5e69d",
     "grade": false,
     "grade_id": "cell-32fa6561e361c5d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 4.0 - Estimating the difference in means using CLT**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let's return to the penguins data set. Are `Adelie` penguins heavier than `Chinstrap` penguins? To answer this question, \n",
    "we will estimate the difference in the weights between the two species. Let's refer to the `Adelie` penguins as population 1 and `Chinstrap` penguins as population 2. \n",
    "\n",
    "Assuming the sample size is large enough, we can approximate the sampling distribution of $\\bar{X}_1-\\bar{X}_2$ by\n",
    "$$\n",
    "\\bar{X}_1-\\bar{X}_2\\sim N\\left(\\mu_1 - \\mu_2, \\sqrt{\\frac{\\sigma^2_1}{n_1}+\\frac{\\sigma^2_2}{n_2}}\\right)\n",
    "$$\n",
    "\n",
    "For comparison purposes, let's first ignore the fact that using the sample standard deviations, $s_1$ and $s_2$, instead of the population standard deviations, $\\sigma_1$ and $\\sigma_2$, adds additional uncertainty, and let's obtain the confidence interval as:\n",
    "\n",
    "$$\n",
    "CI\\left(\\mu_1 - \\mu_2\\right) = \\left(\\bar{X}_1-\\bar{X}_2\\right) \\pm z^*\\sqrt{\\frac{s^2_1}{n_1}+\\frac{s^2_2}{n_2}}\n",
    "$$\n",
    "where $z^*$ is the quantile of a standard Normal.\n",
    "\n",
    "Using this equation, obtain the 95% confidence interval for the difference in means of Adelie penguins' weight and Chinstrap penguins' weight. The sample is stored in the object `adelie_chinstrap_sample`.\n",
    "\n",
    "_Assign your data frame to an object called `penguins_diff_means_ci`. The data frame should have two columns: `lower_ci` and `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0fca10fc2357ef1ebaf213b08798570",
     "grade": false,
     "grade_id": "cell-614ccc9d5bd7a966",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing\n",
    "adelie_chinstrap_sample <- \n",
    "    penguins %>%\n",
    "    filter(species %in% c(\"Adelie\", \"Chinstrap\") & !is.na(body_mass_g)) %>% \n",
    "    select(species, body_mass_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab97286a815e3e8878b62338c9621323",
     "grade": false,
     "grade_id": "cell-ece0ac6f18c7df78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "adelie <- \n",
    "    adelie_chinstrap_sample %>% \n",
    "    filter(species == 'Adelie') %>% \n",
    "    pull(body_mass_g)\n",
    "\n",
    "chinstrap <- \n",
    "    adelie_chinstrap_sample %>% \n",
    "    filter(species == 'Chinstrap') %>% \n",
    "    pull(body_mass_g)\n",
    "\n",
    "# penguins_diff_means_ci <- \n",
    "#     tibble(\n",
    "#         lower_ci = mean(...) - mean(...) - qnorm(...) * sqrt(var(...)/length(...) + var(...)/length(...)),\n",
    "#         upper_ci = ...\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "penguins_diff_means_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3aa7cc110baf0ce1773fd38ac8b1d4e",
     "grade": true,
     "grade_id": "cell-62b6d949bba6d942",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65aa8c3c6d76cccab36bb569627936c3",
     "grade": false,
     "grade_id": "cell-51c3794e6b5317b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 4.1 - Estimating the difference in means using the t-distribution**\n",
    "\n",
    "As we mentioned in question 3, it would be more appropriate to approximate the sampling distribution using the $t$-distribution, since we do not know the population standard deviations $\\sigma_1$ and $\\sigma_2$, and we are using the sample standard deviations, $s_1$ and $s_2$, to estimate them. Therefore, there is more uncertainty around our estimator $\\bar{X}_1-\\bar{X}_2$ than we are accounting for. \n",
    "\n",
    "Thus, we will now compute confidence intervals with the $t$-distribution. The degrees of freedom we will use here is $min(n_1-1, n_2 -1)$\n",
    "\n",
    "Using a similar scaffolding as in the previous question, obtain the 95% confidence interval for the difference in means of Adelie penguins' weight and Chinstrap penguins' weight using the $t$-distribution. The sample is stored in the object `adelie_chinstrap_sample`.\n",
    "\n",
    "_Assign your data frame to an object called `penguins_diff_means_ci_t`. The data frame should have two columns: `lower_ci` and `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac211cb75956a839b260ac103116d235",
     "grade": false,
     "grade_id": "cell-ffc5cced63f424de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# penguins_diff_means_ci_t <- \n",
    "#     tibble(\n",
    "#         lower_ci = mean(...) - mean(...) - qt(..., df = min(..., ...)) * sqrt(var(...)/length(...) + var(...)/length(...)),\n",
    "#         upper_ci = ...\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "penguins_diff_means_ci_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f71bfeaee057f80f5a59e7a0c0517f07",
     "grade": true,
     "grade_id": "cell-153ebc0c3fc446e1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c51ad2f4037c6ce3c2ad9df5ada2917",
     "grade": false,
     "grade_id": "cell-a4843e06d1356b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the confidence interval based on the $t$-distribution is wider as it accounts for the additional uncertainty."
   ]
  }
 ],
 "metadata": {
  "docker": {
   "latest_iamge_tag": "TAG_HERE"
  },
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
