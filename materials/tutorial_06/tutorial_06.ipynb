{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb04bcf19b5edd42d7cd4fec2da6576c",
     "grade": false,
     "grade_id": "cell-57c92078710d7670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tutorial 6: Hypothesis Testing\n",
    "\n",
    "### Lecture and Tutorial Learning Goals\n",
    "From this section, students are expected to be able to:\n",
    "\n",
    "1.\tGive an example of a question you could answer with a hypothesis test.\n",
    "2.\tIdentify potential limitations in the data, arising from the methods of data collection, to answer the question\n",
    "3.\tSpecify a null and alternative hypothesis.\n",
    "4.\tGiven an inferential question, formulate hypotheses to be used in a hypothesis test.\n",
    "5.\tIdentify the correct steps and components of a basic hypothesis test.\n",
    "6.\tWrite computer scripts to perform hypothesis testing via simulation, randomization and bootstrapping approaches, as well as interpret the output.\n",
    "7.\tIdentify the advantages of simulation/randomization tests when estimating parameters different from proportions and means.\n",
    "8.\tDescribe the relationship between confidence intervals and hypothesis testing.\n",
    "9.\tDiscuss the potential limitations of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e43a30efef2360252cba7ac4d5c01a0",
     "grade": false,
     "grade_id": "cell-fc07df746fa2acae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(cowplot)\n",
    "library(datateachr)\n",
    "library(digest)\n",
    "library(infer)\n",
    "library(repr)\n",
    "library(taxyvr)\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(datateachr)\n",
    "penguins <- read.csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\")\n",
    "source(\"tests_tutorial_06.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88060d8ac496cc55a192a70838f7da6e",
     "grade": false,
     "grade_id": "cell-5452f0b8e3cc9640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Annual Maximum Flow Rate of Bow River\n",
    "\n",
    "&emsp; When the snow melts in spring and summer, tons of water are released into the rivers, and floodings occur. One preventative measure is to keep track of the maximum flow of a river each year. For this question, we aim to prevent flooding by first studying the annual maximum daily discharge (in $m^3/s$) at a hydrometric station called <i> Bow River at Banff </i>, which is near Banff, Alberta. The data are saved to the data table <i>flow_sample</i>. Let's preview this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530b6198d5db0ee7c236808939074faa",
     "grade": false,
     "grade_id": "cell-00f0bba26d76ed06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "?flow_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e58a73aba2024881beb58c72138344e7",
     "grade": false,
     "grade_id": "cell-5c3c13289a0b767a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "head(flow_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ee198293c06467eb0bca1cf7e7ccb35",
     "grade": false,
     "grade_id": "cell-1d4382bf89c3623d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A village downstream wants to build a dam to mitigate the effects of annual flooding. To design this dam, we’re interested in studying the distribution of the maximum flow of Bow River at this station. A retired employee, who was monitoring many hydrometric stations in the area, claims that the annual maximum flow is typically around $210 m^3/s$. However, residents in the area claim  that the annual maximum flow is typically higher than $210 m^3/s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "977555584e553e2b145f78d65ac516a7",
     "grade": false,
     "grade_id": "cell-eb547880fb23e1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.1: Selecting Parameter</b><br>\n",
    "{points: 2}\n",
    "\n",
    "Which of the parameters below would be most suitable to investigate and ultimately test the residents’ claim? (Select all that apply)\n",
    "\n",
    "A. The mean of the annual maximum flow distribution at Bow River\n",
    "\n",
    "B. The median of the annual maximum flow distribution at Bow River\n",
    "\n",
    "C. The variance of the annual maximum flow distribution at Bow River\n",
    "\n",
    "D. The proportion of annual maximum flow values at Bow River exceeding the residents’ claim\n",
    "\n",
    "_Assign your answer to an object called `answer1.1`. Your answer should be a sequence of characters surrounded by quotes (e.g., \"ABCD\")._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92b44dd65494d8e0c41e09f02c5f5d46",
     "grade": false,
     "grade_id": "cell-59d0d769a179b776",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.1 <- \"\"\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01e425eee5a50df4575342548871608a",
     "grade": true,
     "grade_id": "cell-5b21334104d55645",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer1.1\"', {\n",
    "    expect_true(exists(\"answer1.1\"))\n",
    "  })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46bf9b41371063ea1361a3e7593184fd",
     "grade": false,
     "grade_id": "cell-f8c1adc7133c799b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; For now, let us focus on the mean of the annual maximum flow. We want to test hypotheses about the mean <b>at the 5% significance level</b>. Here we assume that the annual maximum flow data originate from a distribution that does not change over the years (due to climate change, tectonic activities, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59a4591d4eee64ea4bdb9e62bca836e9",
     "grade": false,
     "grade_id": "cell-d04e69597c43ec20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.2: Null Hypothesis</b><br>\n",
    "{points: 2}\n",
    "\n",
    "Which of the following would be an appropriate null hypothesis for us to set, given the residents’ and retired employee’s claims?\n",
    "\n",
    "A. $H_0$: The mean of the annual maximum flow at Bow River is equal to $210 m^3/s$.\n",
    "\n",
    "B. $H_0$: The mean of the annual maximum flow at Bow River is greater than $210 m^3/s$.\n",
    "\n",
    "C. $H_0$: The mean of the annual maximum flow at Bow River is greater than or equal to $210 m^3/s$.\n",
    "\n",
    "D. $H_0$: The mean of the annual maximum flow at Bow River is NOT equal to $210 m^3/s$.\n",
    "\n",
    "Your answer should be a string containing one letter.\n",
    "\n",
    "_Assign your answer to an object called `answer1.2`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51cf42e331910c1553435fcde20e2e94",
     "grade": false,
     "grade_id": "cell-bbdcf0abb3076bb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.2 <-\"\"\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "560b397b6882cdd316a23ce897fb9f3b",
     "grade": true,
     "grade_id": "cell-09943b30d60804fe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer1.2\"', {\n",
    "expect_true(exists(\"answer1.2\"))\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb21c3c737aa8ff6540048e77d1b2ec9",
     "grade": false,
     "grade_id": "cell-0adb8800e06c8afc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.3: Alternative Hypothesis </b><br>\n",
    "{points: 2}\n",
    "\n",
    "Which of the following would be an appropriate alternative hypothesis for us to set, given the residents’ and retired employee’s claims?\n",
    "\n",
    "A. $H_1$: The mean of the annual maximum flow at Bow River is less than $210 m^3/s$.\n",
    "\n",
    "B. $H_1$: The mean of the annual maximum flow at Bow River is greater than $210 m^3/s$.\n",
    "\n",
    "C. $H_1$: The mean of the annual maximum flow at Bow River is greater than or equal to $210 m^3/s$.\n",
    "\n",
    "D. $H_1$: The mean of the annual maximum flow at Bow River is <b>NOT</b> equal to $210 m^3/s$.\n",
    "\n",
    "Your answer should be a string containing one letter.\n",
    "\n",
    "_Assign your answer to an object called `answer1.3`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab84a13e7b643e488fbc2816c7c48916",
     "grade": false,
     "grade_id": "cell-276a5cceb1bb36f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.3 <-\"\"\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18be84f15c3a1b09b3fa9f576bc69856",
     "grade": true,
     "grade_id": "cell-54163d50760ddff3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer1.3\"', {\n",
    "    expect_true(exists(\"answer1.3\"))\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3dbbb38f885b9b8c96e42ab437881245",
     "grade": false,
     "grade_id": "cell-e29939b4e2828732",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; Now we select the maximum flow, keep only the year and the flow columns. We also find the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25e6bf52fd4f0902ae496c057b89a025",
     "grade": false,
     "grade_id": "cell-97d809446f479cf4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this code before continuing\n",
    "max_flow_sample <- \n",
    "    flow_sample %>%\n",
    "    filter(extreme_type == 'maximum') %>%\n",
    "    select(year, flow) %>% \n",
    "    rename(maximum_flow = flow)\n",
    "\n",
    "head(max_flow_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d608e43d2a606526b9733fcee959840",
     "grade": false,
     "grade_id": "cell-67097464296d3c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.4</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Calculate the observed test statistic from `max_flow_sample` with the `infer` package, specify the response, and use the `calculate` function. Leave your answer as a 1x1 tibble with a column named `stat`.\n",
    "\n",
    "_Assign your data frame to an object called `observed_mean`. Your data frame should have only one column, `stat`, and one row._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "251af4465bbcf92741da6eb2cd9e5acb",
     "grade": false,
     "grade_id": "cell-d9f83fc59d078643",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#observed_mean <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "observed_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ce6d9931580e093593af9baa5a1c15c",
     "grade": true,
     "grade_id": "cell-c0e444ce1fc5f664",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"observed_mean\"', {\n",
    "    expect_true(exists(\"observed_mean\"))\n",
    "})\n",
    "\n",
    "test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(observed_mean))\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58a5b30e9555ab30deafe2537962c09d",
     "grade": false,
     "grade_id": "cell-4d47bff6731fa8a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.5: Simulating from the null distribution</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Using the `infer` workflow, generate 1000 samples from the null distribution. Remember the steps:\n",
    "\n",
    "1. `specify` the response;\n",
    "2. `hypothesize`;\n",
    "3. `generate` 1000 samples; \n",
    "4. and `calculate` the mean of each sample. \n",
    "\n",
    "_Assign your data frame to an object called `null_max_flow`. Your data frame should have two columns: `replicate` and  `stat`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2e51ae1c6f00e074f7448ab9971f5e4",
     "grade": false,
     "grade_id": "cell-3c6d6c2eb789d852",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1432) # Do not change this\n",
    "\n",
    "#null_max_flow <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(null_max_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c8813fe4cdd88c8c069c6747bbe5ecd",
     "grade": true,
     "grade_id": "cell-81b290784b27c6d1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "\n",
    "test_that('Did not assign answer to an object called \"null_max_flow\"', {\n",
    "    expect_true(exists(\"null_max_flow\"))\n",
    "  })\n",
    "\n",
    "  test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(null_max_flow))\n",
    "  })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8da7605ed3b14286340909019f99bdff",
     "grade": false,
     "grade_id": "cell-145ec8e33ab901cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.6</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Plot the result of the hypothesis test using `visualize` with 10 bins, put a vertical bar for the observed test statistic, and shade the tail(s). Label the x-axis as `Mean`.\n",
    "\n",
    "```r\n",
    "max_flow_result_plot <- \n",
    "    null_max_flow %>% \n",
    "    visualize(bins = ...) + \n",
    "    shade_p_value(obs_stat = ..., direction = ...) +\n",
    "    xlab(...)\n",
    "```\n",
    "\n",
    "<i>Assign your answer to an object called </i>`max_flow_result_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aceafcf818632275a02379a43d1f4f92",
     "grade": false,
     "grade_id": "cell-2999b00535bb274a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#max_flow_result_plot <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "max_flow_result_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08c8ed60e6153c25d561e1600fafe764",
     "grade": true,
     "grade_id": "cell-0f59fcb4d9912b65",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bde4a2296d4709dfead8d499d727fbd4",
     "grade": false,
     "grade_id": "cell-d24a21794f869182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.7</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Use the `get_p_value` function from `infer` package to get the p-value from `null_max_flow`. \n",
    "\n",
    "```r\n",
    "answer1.7 <- \n",
    "    ... %>% \n",
    "    get_p_value(obs_stat = ..., direction = ...)\n",
    "```\n",
    "<i>Assign your answer to an object called </i>`answer1.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b59e6e81df7d1f2acab00de082cb4026",
     "grade": false,
     "grade_id": "cell-cdd5fa2b8770bc9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.7 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24fe8e8e72799ade4c1a195c5a7eb9cd",
     "grade": true,
     "grade_id": "cell-ec34f3b254715300",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d392d3731191bc2bc3ae97b8d5233a1e",
     "grade": false,
     "grade_id": "cell-726b2577fe97afcd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.8: Conclusion of the test </b><br>\n",
    "{points: 3}\n",
    "\n",
    "What can we conclude based on the result of the hypothesis test?\n",
    "\n",
    "A. Given a p-value of 0.369 we do not reject the null hypothesis.\n",
    "\n",
    "B. Given a p-value of 0.369 we reject the null hypothesis.\n",
    "\n",
    "C. Given a p-value of 0.369 we do not reject the null hypothesis at the 5% significance level.\n",
    "\n",
    "D. Given a p-value of 0.369 we reject the null hypothesis at the 5% significance level.\n",
    "\n",
    "_Assign your answer to an object called `answer1.8`. Your response should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f38e7357bf6e59eb460c3a7228978b7",
     "grade": false,
     "grade_id": "cell-cd83d388742b5c1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.8 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b297e4aed32afb5c864dbe1c9abff0c4",
     "grade": true,
     "grade_id": "cell-c01da46960066eff",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer1.8\"', {\n",
    "    expect_true(exists(\"answer1.8\"))\n",
    "})\n",
    "\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "    expect_match(answer1.8, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "722f8cbdaa93dff0cc63824cfdc7bc6d",
     "grade": false,
     "grade_id": "cell-015747aad9f99ed7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.9: Conclusion at a different significance level</b>\n",
    "\n",
    "{Points: 3}\n",
    "\n",
    "If we conducted the test at the 10% significance level instead, would our conclusion have been different?\n",
    "\n",
    "A. Yes, it would have, the null hypothesis would be rejected.\n",
    "\n",
    "B. Yes, it would have, the null hypothesis would be accepted.\n",
    "\n",
    "C. Yes, it would have, the null hypothesis would NOT be rejected.\n",
    "\n",
    "D. No, it wouldn’t.\n",
    "\n",
    "Your answer should be a string containing one letter.\n",
    "\n",
    "_Assign your answer to an object called `answer1.9`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1011d3b67e17f1bc7e42ee4556e82a45",
     "grade": false,
     "grade_id": "cell-ff07ff67d5a1ed83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.9 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8990b7c5992a94cca6f30e1fc01b167",
     "grade": true,
     "grade_id": "cell-9f2fd9fe55309574",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abfaaf30075ba916c1d297257f433706",
     "grade": false,
     "grade_id": "cell-ffa16ff57f4b5a8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.10</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Now we would like to find the 90% confidence interval for the mean. First, let's find the bootstrap distribution for the mean by generating 1000 samples. Use the `infer` package and `max_flow_sample` to specify the response, generate 1000 samples, and calculate the mean. \n",
    "\n",
    "\n",
    "_Assign your data frame to an object called `mean_max_bootstrap_dist`. Your data frame should have two columns: `replicate` and  `stat`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "326aa36e85e7c49f49eaccda0ef4cc9d",
     "grade": false,
     "grade_id": "cell-64f8e7f7f47c3a85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(6882) # Do not change this\n",
    "\n",
    "#mean_max_bootstrap_dist <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(mean_max_bootstrap_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb0458262ae0144211f45388e16870cc",
     "grade": true,
     "grade_id": "cell-5f0b57fbbf90a7d5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43fa57827223ba935735482c3b022270",
     "grade": false,
     "grade_id": "cell-d56135d0ece3219e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.11 </b> <br>\n",
    "{points: 2}\n",
    "\n",
    "Using the boostrap distribution `mean_max_bootstrap_dist`, find the 90% confidence interval given by the 0.1-quantile and 1-quantile (max). \n",
    "\n",
    "```r\n",
    "mean_max_flow_ci <- \n",
    "    ... %>% \n",
    "    summarise(lower_ci = ..., upper_ci = ...)\n",
    "```\n",
    "\n",
    "_Assign your data frame to an object called `mean_max_flow_ci`. Your data frame should have two columns: `lower_ci` and  `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "301d05c8193cf892ff977ef54e66dd1b",
     "grade": false,
     "grade_id": "cell-a7989458209c905e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# mean_max_flow_ci <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "mean_max_flow_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "539e64073c701e4b387fce5279f743cf",
     "grade": true,
     "grade_id": "cell-c238fc99168e92b5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8aca906fc0413801d5daf70564dd2fd",
     "grade": false,
     "grade_id": "cell-d5cf433a7e810709",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.12 </b> <br>\n",
    "{points: 2}\n",
    "\n",
    "Using the `infer` package, visualize the confidence interval `mean_max_flow_ci` with the bootstrap distribution `mean_max_bootstrap_dist`.\n",
    "\n",
    "<i>Assign your plot to an object called </i>`mean_flow_ci_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3190b252dca4827532ac278c79bfefe9",
     "grade": false,
     "grade_id": "cell-5d7f7b1bc05b579e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# mean_flow_ci_plot <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "mean_flow_ci_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c870e61e40d6ab3fb3b3bce69be56983",
     "grade": true,
     "grade_id": "cell-4e8a5c776697d937",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.12()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b126835e221531953193f262c09af24",
     "grade": false,
     "grade_id": "cell-43d4cea695e5b6f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.  Flipper Lengths of Penguins\n",
    "\n",
    "The dataset `penguins` contains size measurements for adult foraging penguins near Palmer Station, Antarctica. First, let's take a look at the first few rows of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3976cf2c5691b63ffa6ec590d18f08b7",
     "grade": false,
     "grade_id": "cell-9434eda90796aebe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "head(penguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56175989d491cc29655a70a497b6c2c5",
     "grade": false,
     "grade_id": "cell-827c6561abf44dc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; We want to study how Adelie and Chinstrap penguins are different. First, we study their flipper lengths (in mm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cca2e07fac483638e9eb33d621e5865",
     "grade": false,
     "grade_id": "cell-245a0ab4a2611869",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.1: Pre-processing</b> <br>\n",
    "{points: 2}\n",
    "\n",
    "Filter the `penguins` dataset to remove all rows with `NA` in `flipper_length_mm`, keep only the `Adelie` and `Chinstrap` species, and select the two columns `species` and `flipper_length_mm`.\n",
    "\n",
    "_Assign your data frame to an object called `adelie_chinstrap_flipper`. Your data frame should have only two columns, `species` and `flipper_length_mm`._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcaa12d43fdc1b2d239bacdf20e30d81",
     "grade": false,
     "grade_id": "cell-4befd1c3dc62017f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#adelie_chinstrap_flipper <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(adelie_chinstrap_flipper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62f4004efe9827aaf5e4e1271d87d62d",
     "grade": true,
     "grade_id": "cell-8e8fea9ac0fa10b3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b4c8ba3eb0c028e2fbd87fe603f9ae6",
     "grade": false,
     "grade_id": "cell-13b20a70bc1ac634",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.2: Null hypothesis</b> <br>\n",
    "{points: 2}\n",
    "\n",
    "&emsp; An ecologist suspects that flipper lengths affect their ability to swim. But are the flipper lengths different between the species? Looking at photos of the two penguin species, some claim that their flippers are generally the same length. However, an ecologist hypothesizes that they may not be the same length. To study the distributions of the flipper lengths of the two species, let's conduct a hypothesis test to examine their <b> difference in medians</b>.\n",
    "\n",
    "Which of the following would be an appropriate null hypothesis for us to set, given the above situation?\n",
    "\n",
    "A. $H_0$: The median flipper length of the Adelie penguins is the same as the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "B. $H_0$: The mean flipper length of the Adelie penguins is the same as the mean flipper length of the Chinstrap penguins.\n",
    "\n",
    "C. $H_0$: The median flipper length of the Adelie penguins is different from the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "D. $H_0$: The median flipper length of the Adelie penguins is greater than the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "Your answer should be a string containing one letter.\n",
    "\n",
    "_Assign your answer to an object called `answer2.2`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c9c151b2500264dcb61cb8fcb01c26a",
     "grade": false,
     "grade_id": "cell-d2bf2e8a134f2895",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.2 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30acad59ad0bf964ec75a0b741c380f9",
     "grade": true,
     "grade_id": "cell-101813e2ab74aecd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer2.2\"', {\n",
    "    expect_true(exists(\"answer2.2\"))\n",
    "})\n",
    "\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "    expect_match(answer2.2, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57e70901acadb444bc293b0d74647078",
     "grade": false,
     "grade_id": "cell-bb806d6682525df9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.3: Alternative Hypothesis</b><br>\n",
    "{points: 2}\n",
    "\n",
    "Which of the following would be an appropriate alternative hypothesis for us to set, given the above situation?\n",
    "\n",
    "A. $H_1$: The median flipper length of the Adelie penguins is the same as the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "B. $H_1$: The mean flipper length of the Adelie penguins is different from the mean flipper length of the Chinstrap penguins.\n",
    "\n",
    "C. $H_1$: The median flipper length of the Adelie penguins is different from the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "D. $H_1$: The median flipper length of the Adelie penguins is less than the median flipper length of the Chinstrap penguins.\n",
    "\n",
    "Your answer should be a string containing one letter.\n",
    "\n",
    "_Assign your answer to an object called `answer2.3`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e261003998b7e3394435ce03d6c5c600",
     "grade": false,
     "grade_id": "cell-d05d1675c44c9eb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.3 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b59b80b2e0857c646645ccf56ee768af",
     "grade": true,
     "grade_id": "cell-550bdafdc0a5c4c6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer2.3\"', {\n",
    "    expect_true(exists(\"answer2.3\"))\n",
    "})\n",
    "\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "    expect_match(answer2.3, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c29c22c3eb15b03615853e8e5fe1070",
     "grade": false,
     "grade_id": "cell-f4da9409ad2b8f49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.4 </b> <br>\n",
    "{points: 2}\n",
    "\n",
    "Count the numbers of Adelie penguins and Chinstrap penguins examined in `adelie_chinstrap_flipper`.\n",
    "\n",
    "```r\n",
    "penguin_count <-\n",
    "    ... %>% \n",
    "    count(...)\n",
    "```\n",
    "\n",
    "_Assign your data frame to an object called `penguin_count`. Your data frame should have only two columns: `species` and `n`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "806ded0de932e3c8dac0e3dc22d72788",
     "grade": false,
     "grade_id": "cell-743723213f0f9cb1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# penguin_count <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "penguin_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc2950245a351fcf6f2acf3aa2701420",
     "grade": true,
     "grade_id": "cell-541be377c0b58516",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7965666b24111ef9c1f3e88dc27f28dc",
     "grade": false,
     "grade_id": "cell-d74ad5c7b9e32c98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.5</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Calculate the observed test statistic with the `infer` package. Use `adelie_chinstrap_flipper` to specify the response and explanatory variables, and calculate Adelie's median minus Chinstrap's median. \n",
    "\n",
    "_Assign your data frame to an object called `observed_diff_in_medians`. Your data frame should have only one column, `stat`, and one row._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bceeb78bc6f0ca154975f0b0b97dfae8",
     "grade": false,
     "grade_id": "cell-8944e82a58ce1446",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#obs_diff_in_medians <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "obs_diff_in_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc78f353bf4cf506152c2941d333bfd0",
     "grade": true,
     "grade_id": "cell-9e72fe57d4e4d98c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47fb8fed6f8dd21e214313ca29f20910",
     "grade": false,
     "grade_id": "cell-b818e868e059e825",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.6: Simulating from the null distribution</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Using the `infer` package, generate 1000 samples from the null distribution. Use `adelie_chinstrap_flipper` to specify the response and explanatory variables, hypothesize, generate 1000 samples and calculate Adelie's median minus Chinstrap's median.\n",
    "\n",
    "_Assign your data frame to an object called `null_diff_in_medians`. Your data frame should have only two columns: `replicate` and `stat`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ffcf13dfcd0713e4d243b96d9ef2ecd",
     "grade": false,
     "grade_id": "cell-9a967990242fda67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(5437) # Do not change this\n",
    "\n",
    "#null_diff_in_medians <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(null_diff_in_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc743206cc386dd945a3bf5fea328c3a",
     "grade": true,
     "grade_id": "cell-0c90dd8cb33e5c6b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bc3535fd4adc34a4bc4c6c6a6dfc27e",
     "grade": false,
     "grade_id": "cell-a8e5bf9578f7b714",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.7</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Plot the result of the hypothesis test with `visualize` with 10 bins, put a vertical bar for the observed test statistic `obs_diff_in_medians`, and shade the tail(s).\n",
    "\n",
    "_Assign your plot to an object called `diff_in_medians_plot`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d23e39af21e50f8cd74075bfb7700b57",
     "grade": false,
     "grade_id": "cell-88088363709a3021",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#diff_in_medians_plot <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "diff_in_medians_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63adea0680ea7d89391acfd16cb3ce9e",
     "grade": true,
     "grade_id": "cell-722525e3c18b6163",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a758671124603b3e24261a638dc183bd",
     "grade": false,
     "grade_id": "cell-4efbcadd10da44f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.8</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Obtain the p-value of `obs_diff_in_medians` from `null_diff_in_medians`. Leave your answer as a $1 \\times 1$ tibble with column name `p_value`.\n",
    "\n",
    "_Assign your data frame to an object called `answer2`. Your data frame should have only one column: `p_value`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b12c17996890716e9e4962dfa81dc0b",
     "grade": false,
     "grade_id": "cell-9cc94e6fc7915e7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.8 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b6f50e542add65b9608c2654c00f0f6",
     "grade": true,
     "grade_id": "cell-6ae9456876481e63",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b7acd8848a85509c9e86d28a261f590",
     "grade": false,
     "grade_id": "cell-79472809acf073c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.9 </b> <br>\n",
    "{points: 2}\n",
    "\n",
    "We should never report a p-value of 0 because this suggests that making a Type I error is impossible. But this is too bold of a claim to make.\n",
    "\n",
    "What would be the best way to report the p-value? Think about what the next smallest p-value is possible to be calculated, given that we are using 1000 repetitions to calculate the sample.\n",
    "\n",
    "A. The p-value is < 0.05\n",
    "\n",
    "B. The p-value is < 0.01\n",
    "\n",
    "C. The p-value is < 0.001\n",
    "\n",
    "D. The p-value is < 0.0001\n",
    "\n",
    "\n",
    "_Assign you answer to an object called `answer2.9`. Your answer should be a string containing one letter._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6201c3eec45b97846ac64f2fed3c9297",
     "grade": false,
     "grade_id": "cell-38a0bd20fb422203",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.9 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0ab1fc2246fffaa35429e37a97745e3",
     "grade": true,
     "grade_id": "cell-dca9a139679d58de",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e26a3f7108a91ca53dce089d56d1fae3",
     "grade": false,
     "grade_id": "cell-eae8d4303213040d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.10: Conclusion of the test </b> <br>\n",
    "{points: 3}\n",
    "\n",
    "What can we conclude based on the result of the hypothesis test?\n",
    "\n",
    "A. Given a p-value < 0.001 we reject the null hypothesis.\n",
    "\n",
    "B. Given a p-value < 0.001 we accept the alternative hypothesis at the 5% significance level.\n",
    "\n",
    "C. Given a p-value < 0.001 we do not reject the null hypothesis at the 5% significance level.\n",
    "\n",
    "D. Given a p-value < 0.001 we reject the null hypothesis at the 5% significance level.\n",
    "\n",
    "\n",
    "_Assign your answer to an object called `answer2.10`. Your answer should be a string containing one letter._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22a7faea9ef4cefe6780364be6382576",
     "grade": false,
     "grade_id": "cell-f0c4498d52c61f7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.10 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f44d3244456a0ba9cf120107401901a7",
     "grade": true,
     "grade_id": "cell-48cf027f333efc2a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer2.10\"', {\n",
    "    expect_true(exists(\"answer2.10\"))\n",
    "})\n",
    "\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "    expect_match(answer2.10, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6eaedfca1a6dce001bb83b71a410b80",
     "grade": false,
     "grade_id": "cell-b442d7a4c1941e61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.11</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Now we would like to find the 90% confidence interval for the difference in median. First, let's find the bootstrap distribution for the difference in medians with the `infer` package. Use `diff_in_medians_bootstrap_dist` to specify the response and explanatory variables, generate 1000 samples, and calculate Adelie's median minus Chinstrap's median. \n",
    "\n",
    "_Assign your data frame to an object called `diff_in_medians_bootstrap_dist`. Your data frame should have only two columns: `replicate` and `stat`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3aa770f21085b7c3258c4b047817574",
     "grade": false,
     "grade_id": "cell-32def599d1f74cff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(9263) # Do not change this\n",
    "\n",
    "#diff_in_medians_bootstrap_dist <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(diff_in_medians_bootstrap_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bdfc269f619f2338d01288049b596e1",
     "grade": true,
     "grade_id": "cell-1f971841b9de346a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df807146b0e9fdbf2a5302d91b94baf5",
     "grade": false,
     "grade_id": "cell-3841d11be9807d7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.12 </b><br>\n",
    "{points: 2}\n",
    "\n",
    "Use `diff_in_medians_bootstrap_dist` to find the 90% confidence interval.\n",
    "\n",
    "_Assign your data frame to an object called `diff_in_medians_ci`. Your data frame should have two columns: `lower_ci` and  `upper_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2134b19355737a2e1dce67a19feb48d1",
     "grade": false,
     "grade_id": "cell-314b02546d1b8263",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#diff_in_medians_ci <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "diff_in_medians_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "425191d45f0ab67578de06fe7f7a0297",
     "grade": true,
     "grade_id": "cell-02c49394935e92c8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"diff_in_medians_ci\"', {\n",
    "expect_true(exists(\"diff_in_medians_ci\"))\n",
    "})\n",
    "\n",
    "test_that(\"Solution should be a data frame\", {\n",
    "expect_true(\"data.frame\" %in% class(diff_in_medians_ci))\n",
    "})\n",
    "\n",
    "expected_colnames <- c(\"lower_ci\", \"upper_ci\")\n",
    "given_colnames <- colnames(diff_in_medians_ci)\n",
    "test_that(\"Data frame does not have the correct columns\", {\n",
    "    expect_equal(length(setdiff(\n",
    "      union(expected_colnames, given_colnames),\n",
    "      intersect(expected_colnames, given_colnames)\n",
    "    )), 0)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d11211a5820ae491ae2867d71a29e33b",
     "grade": false,
     "grade_id": "cell-aa117608bf62ed0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 2.13 </b><br>\n",
    "{points: 2}\n",
    "\n",
    "Visualize the confidence interval `diff_in_medians_ci` with the bootstrap distribution `diff_in_medians_bootstrap_dist`.\n",
    "\n",
    "<i>Assign your plot to an object called </i>`diff_in_medians_ci_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1818d45b088980938daa2a7106b4d35",
     "grade": false,
     "grade_id": "cell-33ccfe26348df47a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# diff_in_medians_ci_plot <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "diff_in_medians_ci_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65918957b8e789763c4ade0d71c58120",
     "grade": true,
     "grade_id": "cell-a56d2bec8b964479",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.13()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9bde7c3c315ef9c2003c7a0d51dc7a3",
     "grade": false,
     "grade_id": "cell-1146dfe6f077838a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Breast Cancer and Radiation Therapy\n",
    "\n",
    "&emsp; For this question, we will use the dataset found at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer. The dataset contains information on 286 breast cancer patients, including variables on tumour size, tumour location, radiation therapy, cancer recurrence, and other basic medical history data. Given this dataset, we want to investigate whether there is a significant difference in the proportions of cancer recurrence between patients who were treated with experimental radiation therapy and patients who were not (i.e. received an alternate treatment). We will assume that the patients have been randomized into each of these two treatment groups.\n",
    "\n",
    "&emsp; Let's load this dataset. Note that the \"irradiat\" column indicates whether or not the patient received radiation therapy, while the \"Class\" column indicates whether or not the patient experienced a cancer recurrence event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c692b2030ef65c0c4dd7c380ee4797e5",
     "grade": false,
     "grade_id": "cell-5ce07a14b10cac34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "breast_cancer <- read.csv(url(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"),header=FALSE)\n",
    "colnames(breast_cancer) <- c(\"class\", \"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\")\n",
    "head(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9c3a63574e0e1ab5a05b857924e34fa",
     "grade": false,
     "grade_id": "cell-f86991f96a49f4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "recurrence_irradiat <- \n",
    "    breast_cancer %>%\n",
    "    select(class, irradiat)\n",
    "\n",
    "head(recurrence_irradiat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "666e8089d01e11154811fdd038871121",
     "grade": false,
     "grade_id": "cell-dacb75318f7c5a87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; Let's group by `class` and `irradiat` and tally how many samples are in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdc25dc2ee67ea05cfa1995a295930e4",
     "grade": false,
     "grade_id": "cell-4b0dd6b1d19b03b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "recurrence_irradiat %>%\n",
    "    group_by(irradiat, class) %>%\n",
    "    tally() %>%\n",
    "    spread(irradiat, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "710a59096eab221b57d9d74652bcb5df",
     "grade": false,
     "grade_id": "cell-b5bfec02b1f8467d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.1</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Let $p_{1}$ be the proportion of radiation therapy patients (irradiat=true) that subsequently experienced cancer recurrence, and let $p_{2}$ be the proportion of patients that did not receive radiation therapy (irradiat=false) and subsequently experienced cancer recurrence. \n",
    "\n",
    "We want to test $$H_0: p_{1} = p_{2},$$ and $$H_a: p_{1} \\neq p_{2}.$$\n",
    "\n",
    "Calculate the observed test statistic $\\hat{p}_1 - \\hat{p}_2$ using `recurrence_irradiat` by first specifying the response and explanatory variables.\n",
    "\n",
    "_Assign your data frame to an object called `obs_diff_prop`. Your data frame should have only one column, `stat`, and one row._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0513ff0c44df51c985fefb16cf4ffe3",
     "grade": false,
     "grade_id": "cell-50f5046219d6451d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#obs_diff_prop <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "obs_diff_prop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52c6d4b1434417425bfc15ebd3dfd6e2",
     "grade": true,
     "grade_id": "cell-1149952055648d06",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdebfa9d75e7fb0b241940e2ea362d81",
     "grade": false,
     "grade_id": "cell-8b47ef7e19d98891",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.2: Null Distribution</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Generate 1000 samples from the null distribution. Use `recurrence_irradiat` to specify the response and explanatory variables, hypothesize, generate 1000 samples and calculate the proportion of irradiated patients having recurrent cancer minus the proportion of non-irradiated patients having recurrent cancer. \n",
    "\n",
    "_Assign your data frame to an object called `irradiat_null_distribution`. Your data frame should have only two columns: `replicate` and `stat`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df5a2ade9c4b3829b7470f35f3a4dece",
     "grade": false,
     "grade_id": "cell-e6801b15b4258c14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(3526)\n",
    "#irradiat_null_distribution <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(irradiat_null_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ed8fa0eb7bf868775377c0209ddfdb1",
     "grade": true,
     "grade_id": "cell-3a16b15f5692aca8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa10e62d57f04d37b5f1eb5e1ccf9ce8",
     "grade": false,
     "grade_id": "cell-fcaaa01f1f5c44a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.3</b><br>\n",
    "{points: 3}\n",
    "\n",
    "Plot the result of the hypothesis test using `visualize` with 10 bins, put a vertical bar for the observed test statistic `obs_diff_prop`, and shade the tail(s).\n",
    "\n",
    "<i>Assign your answer to an object called </i>`irradiate_result_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73262f6ab1a548b80faac6a5ecb24887",
     "grade": false,
     "grade_id": "cell-7818997009c7aef4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#irradiate_result_plot <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "irradiate_result_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eb82ca605bc9341f4d48370ab5070bd",
     "grade": true,
     "grade_id": "cell-c5d0b20f2d897555",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e746765dd6e03b19efa171a66f267e91",
     "grade": false,
     "grade_id": "cell-cfc255e700f115c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.4: Calculate p-value</b> <br>\n",
    "{points: 3}\n",
    "\n",
    "Obtain the p-value from `irradiat_null_distribution`. Leave your answer as a $1 \\times 1$ tibble with column name `p_value`.\n",
    "\n",
    "<i>Assign your answer to an object called </i>`answer3.4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61e82491699cc7bea0c066dbed6d16eb",
     "grade": false,
     "grade_id": "cell-cdd617571e2e7956",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.4<-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac9c583a088dfe2e62365d918aeb964d",
     "grade": true,
     "grade_id": "cell-506d7cba4ff83f8d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "\n",
    "test_that('Did not assign answer to an object called \"answer3.4\"', {\n",
    "    expect_true(exists(\"answer3.4\"))\n",
    "  })\n",
    "\n",
    "  test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(answer3.4))\n",
    "  })\n",
    "\n",
    "expected_colnames <- c(\"p_value\")\n",
    "given_colnames <- colnames(answer3.4)\n",
    "test_that(\"Data frame does not have the correct columns\", {\n",
    "    expect_equal(length(setdiff(\n",
    "      union(expected_colnames, given_colnames),\n",
    "      intersect(expected_colnames, given_colnames)\n",
    "    )), 0)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "514a984880ac3bdd93ff4918682f41a8",
     "grade": false,
     "grade_id": "cell-a5c982b6b269f9be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; Thus, given the p-value above, we reject the null hypothesis at 5% significance level.\n",
    "\n",
    "&emsp; Given this result and the test statistic that we observed in Question 3.1, there is evidence to suggest that cancer recurrence is associated with the type of treatment received. Specifically, patients who received the experimental radiation therapy may be more likely to experience cancer recurrence than patients who did not. This may be attributable to its lower effectiveness at eliminating the cancer present, compared to alternative treatments."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
