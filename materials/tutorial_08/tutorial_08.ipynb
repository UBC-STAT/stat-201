{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d7b17d2d636d6f6dd66e706583fb626",
     "grade": false,
     "grade_id": "cell-9789477e89b5b9a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#  Tutorial 8: Classical Tests Based on Normal and t- Distributions\n",
    "\n",
    "#### Lecture and Tutorial Learning Goals:\n",
    "From this section, students are expected to be able to:\n",
    "\n",
    "1. Describe a t-distribution and its relationship with the normal distribution.\n",
    "2. Use results from the assumption of normality or the Central Limit Theorem to perform estimation and hypothesis testing.\n",
    "3. Compare and contrast the parts of estimation and hypothesis testing that differ between simulation- and resampling-based approaches with the assumption of normality or the Central Limit Theorem-based approaches.\n",
    "4. Write a computer script to perform hypothesis testing based on results from the assumption of normality or the Central Limit Theorem.\n",
    "5. Discuss the potential limitations of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3664060d060f1d02bf834336544d6b0c",
     "grade": false,
     "grade_id": "cell-31ba334fdcee78a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(cowplot)\n",
    "library(datateachr)\n",
    "library(digest)\n",
    "library(infer)\n",
    "library(repr)\n",
    "library(taxyvr)\n",
    "library(tidyverse)\n",
    "library(broom)\n",
    "library(digest)\n",
    "library(testthat)\n",
    "source(\"tests_tutorial_08.r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa8c12d705a2d367c3f9ac08ae385406",
     "grade": false,
     "grade_id": "cell-9abf3ecffe3e519e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Lotto 6/42\n",
    "\n",
    "Though the lottery is fair in general, many believe that the distribution of winning numbers is not even. Some lottery enthusiasts spend years studying the pattern of numbers and come up with complex theories to win the grand prize in the next draw. For this question, we will study past winning numbers of Lotto 6/42, which is a lottery in Ireland. Every time, six winning numbers are drawn from a pool of 42 numbers without replacement. You can view the description of the data [here](http://jse.amstat.org/datasets/lotto.txt). Let's load and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04de45fd1169971431a23fe2fde7e34c",
     "grade": false,
     "grade_id": "cell-ff138e8dcafe9fb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lotto6_42 <- read.delim(\"http://jse.amstat.org/datasets/lotto.dat.txt\", header = FALSE, sep = \"\\t\", dec = \".\")\n",
    "colnames(lotto6_42) <- c(\"code\", \"first\", \"second\", \"third\", \"fourth\", \"fifth\", \"sixth\")\n",
    "lotto6_42 <- lotto6_42 %>%\n",
    "                filter(code == 2) %>% ## to look at actual lottory numbers\n",
    "                subset(select=-c(code))\n",
    "head(lotto6_42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6aec4c98193ff1805d543115051f9b0c",
     "grade": false,
     "grade_id": "cell-024efa85c80baca9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One claim is that the winning numbers are usually double-digit numbers, and in most cases, there is at most one single-digit winning number in each draw. Looking at the first six rows, we may agree with this claim. But now, we know better than just look at anecdotal evidence. Let's test the hypothesis that the probability of having more than one single-digit winning number in a draw is not what it should be if the lottery was fair. What does the data tell us?\n",
    "\n",
    "Note that, in total, ${42 - 9 \\choose 6}+{42 - 9 \\choose 5}{9 \\choose 1} = 3,243,592$ out of ${42 \\choose 6} = 5,245,786$ games have zero or one single-digit winning number. If the lottery is fair, we expect all the games to have the same chance of occurrence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87d9e37ef28c44ccf260311dbfadd32b",
     "grade": false,
     "grade_id": "cell-6a86aa28c97c5914",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let $p$ be the probability of having at least two single-digit winning numbers in a draw. \n",
    "Considering the scenario above, the null hypothesis is:\n",
    "\n",
    "A. $H_0: p = \\frac{2,002,194}{5,245,786}$\n",
    "\n",
    "B. $H_0: p = \\frac{3,243,592}{5,245,786}$\n",
    "\n",
    "C. $H_0: p = \\frac{2,002,194}{3,243,592}$\n",
    "\n",
    "D. $H_0: p = \\frac{9}{42}$\n",
    "\n",
    "_Assign your answer to an object called `answer1.1`. Your answer should be a single character surrounded by quotes. Also, create a variable `lotto_p0` and assign the probability of the null hypothesis._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb822ce5b8b5abe38b2812830fb11d6c",
     "grade": false,
     "grade_id": "cell-a031ed67de158eb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.1 <- ...\n",
    "# lotto_p0 <- ..\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lotto_p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a69d4b814cae03c2534c432a8bdc2f",
     "grade": true,
     "grade_id": "cell-3dd24214ec4a72bc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer1.1\"', {\n",
    "  expect_true(exists(\"answer1.1\"))\n",
    "})\n",
    "\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "  expect_match(answer1.1, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})\n",
    "\n",
    "test_that('Did not assign answer to an object called \"lotto_p0\"', {\n",
    "  expect_true(exists(\"lotto_p0\"))\n",
    "})\n",
    "\n",
    "answer_as_numeric <- as.numeric(lotto_p0)\n",
    "test_that(\"Solution should be a number\", {\n",
    "  expect_false(is.na(answer_as_numeric))\n",
    "})\n",
    "\n",
    "test_that(\"Solution is incorrect\", {\n",
    "  expect_equal(digest(as.integer(answer_as_numeric * 10e6)), \"089e824515c530884e22bea2dd98a447\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef67cb585d754b46e8e88815c1d08e47",
     "grade": false,
     "grade_id": "cell-e4522fe39863266d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.2 </b>\n",
    "<br> {points: 1}\n",
    "\n",
    "What is the correct alternative hypothesis?\n",
    "\n",
    "A. $H_a: p > \\frac{2,002,194}{5,245,786}$\n",
    "\n",
    "B. $H_a: p \\neq \\frac{2,002,194}{5,245,786}$\n",
    "\n",
    "C. $H_a: p < \\frac{2,002,194}{5,245,786}$\n",
    "\n",
    "D. $H_a: p > \\frac{3,243,592}{5,245,786}$\n",
    "\n",
    "E. $H_a: p \\neq \\frac{3,243,592}{5,245,786}$\n",
    "\n",
    "F. $H_a: p > \\frac{3,243,592}{5,245,786}$\n",
    "\n",
    "G. $H_0: p < \\frac{2,002,194}{3,243,592}$\n",
    "\n",
    "H. $H_0: p < \\frac{9}{42}$\n",
    "\n",
    "<i>Assign your answer to an object called</i> `answer1.2`</i>. Your answer should be a single character surrounded by quotes.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ba20be491c4fc466c392d2d750ea696",
     "grade": false,
     "grade_id": "cell-953de2b41250600f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer1.2 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cc695f363dd186bfe27c17ac30edee3",
     "grade": true,
     "grade_id": "cell-42a8b3c3f979c582",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer1.2\"', {\n",
    "  expect_true(exists(\"answer1.2\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", or \"H\")', {\n",
    "  expect_match(answer1.2, \"a|b|c|d|e|f|g|h\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bc0c06bb90df96201c4bf06c75a316f",
     "grade": false,
     "grade_id": "cell-579c0ef6d5874140",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 1.3</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the sample proportion, $\\hat{p}$, of draws with at least two single-digit numbers. \n",
    "(Hint: take a look at the function `rowSums`.)\n",
    "\n",
    "<i>Assign your answer to an object called `lotto_p_hat`. Your answer should be a single number.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80fa16b93404635dd3a678a95694a14a",
     "grade": false,
     "grade_id": "cell-13dbbb252d779073",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# lotto_p_hat <- mean(rowSums(... < ..) > 1)\n",
    "    \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lotto_p_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475aea070a7b943f6d40cb5288b8affd",
     "grade": true,
     "grade_id": "cell-7f864d2096f6d498",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19a7129ae1545774be36c69c14155993",
     "grade": false,
     "grade_id": "cell-11d8b8dca0afa388",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.4</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the standard error of $\\hat{p}$ of the null model.\n",
    "\n",
    "<i>Assign your answer to an object called `lotto_std_error`. Your answer should be a single number.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "529297c72203e9b3781f95165a09c681",
     "grade": false,
     "grade_id": "cell-e7e6e899ede534af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#lotto_std_error <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lotto_std_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "231356d0c407eea37fe19edc32e264ab",
     "grade": true,
     "grade_id": "cell-e4c4cc60a51fa19f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16e280739294844926ed06f71785b28b",
     "grade": false,
     "grade_id": "cell-f926f2539510a90c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.5: Calculate p-value</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Check if the assumptions for the CLT hold. Calculate the p-value.\n",
    "\n",
    "<i>Assign your answer to an object called </i>`lotto_p_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96f7920eaa274e6f71ed01f213647aaf",
     "grade": false,
     "grade_id": "cell-1810d3e9653d014f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# lotto_p_value<-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lotto_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9574129611982d29beca3eb59593a06a",
     "grade": true,
     "grade_id": "cell-42eeed6d8d08211c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acddc7f8bb9f17a63989e78ede0ecd7e",
     "grade": false,
     "grade_id": "cell-5504dffbcf46731b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.6: Conclusion</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "What can we conclude from this test?\n",
    "\n",
    "A. It would be very unlikely to observe $\\hat{p} = 0.375$ in 264 draws, if the true proportion were $p =\\frac{2,002,194}{5,245,786}$. Therefore, we reject $H_0$ and conclude that the lottery is not fair.\n",
    "\n",
    "B. It would be very unlikely to observe $\\hat{p} = 0.375$ in 264 draws, if the true proportion were $p =\\frac{2,002,194}{5,245,786}$. Therefore, we accept $H_0$ and conclude that the lottery is fair.\n",
    "\n",
    "C. It is quite plausible to observe $\\hat{p} = 0.375$ in 264 draws, if the true proportion were $p =\\frac{2,002,194}{5,245,786}$. Therefore, we have enough evidence to reject $H_0$ and conclude that the lottery is not fair.\n",
    "\n",
    "D. It is quite plausible to observe $\\hat{p} = 0.375$ in 264 draws, if the true proportion were $p =\\frac{2,002,194}{5,245,786}$. Therefore, we do not have enough evidence to reject $H_0$ and conclude that the lottery is not fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49e56632536a545f0b103a44f7861caa",
     "grade": false,
     "grade_id": "cell-71803e10c6d1d886",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3c38baa2eff9369d51ad1c26142c3a5",
     "grade": true,
     "grade_id": "cell-5450be7f522aa485",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer1.6\"', {\n",
    "  expect_true(exists(\"answer1.6\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "  expect_match(answer1.6, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73ec400182b33554c546688619a63adf",
     "grade": false,
     "grade_id": "cell-33bf61389d1a7058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 1.7</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Use R's `prop.test`function to test the hypothesis. Make sure to use the `correct = FALSE` and `broom::tidy()` to get a more organized result.\n",
    "\n",
    "<i>Assign your answer to an object called </i>`lotto_prop_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "197ac3dd1678cc4795feb3f7d028f35e",
     "grade": false,
     "grade_id": "cell-54eef665dd5eab4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#lotto_prop_test <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lotto_prop_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aec258a8a874267dad6b74703d62bb53",
     "grade": true,
     "grade_id": "cell-fbfcca60e4b8ad6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"lotto_prop_test\"', {\n",
    "  expect_true(exists(\"lotto_prop_test\"))\n",
    "})\n",
    "test_that(\"Solution should be the output of t.test\", {\n",
    "    expect_true(\"data.frame\" %in% class(lotto_prop_test))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10d376f7d3827d9a8d079f6252c7c47f",
     "grade": false,
     "grade_id": "cell-49a8a83b1b680f59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Jellyfish\n",
    "\n",
    "&emsp; For this question, we will study the length of jellyfish from Hawkesbury River in New South Wales, Australia. First, let's load and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12e4c6e154c893c7490e43b9638da6aa",
     "grade": false,
     "grade_id": "cell-ebcc92b8aeec9ee7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "jellyfish <- read_csv(\"data/jellyfish.csv\")\n",
    "head(jellyfish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5602a8e8c13aca11cc14a23030a3b075",
     "grade": false,
     "grade_id": "cell-605ad75042742cef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let $\\mu$ be the average length of Jellyfish in Dangar, and we will perform hypothesis testing on $\\mu$ at a <b>10% significance level</b>. Our null hypothesis is that the average length $\\mu$ is 11 cm, while the alternate hypothesis is that $\\mu \\neq 11$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd1dcecf87c4059e0a17655c8b9934f4",
     "grade": false,
     "grade_id": "cell-ca10698dd448e089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Select only the fish in Dangar and select the `length` column. Also, create a variable `dangar_mu0` to store the hypothesized $\\mu$.\n",
    "\n",
    "_Assign your data frame to an object called `dangar`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea9d00b793ba9ce03f3f0d8a80a19d25",
     "grade": false,
     "grade_id": "cell-1f8c8499695a51d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dangar <- \n",
    "#dangar_mu0 <-\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(dangar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9d8142b1de402d35564b7522f6f1253",
     "grade": true,
     "grade_id": "cell-e76bf600ed48ac37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ddc0c6a25976ad668fbe72fecdb47de",
     "grade": false,
     "grade_id": "cell-a34e08d6194fc3c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.2: Calculate the observed test statistics</b>\n",
    "<br>{points: 1}\n",
    "\n",
    "Calculate the observed mean length. \n",
    "\n",
    "_Assign your answer to an object called `dangar_x_bar`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e77058abad52bc59d6e19de2f1ef96b",
     "grade": false,
     "grade_id": "cell-7810bd7565f60e8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dangar_x_bar <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dangar_x_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b2956d680f56aed69d3011b42915a5d",
     "grade": true,
     "grade_id": "cell-81334746e4af0371",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cf578a23cf8403b9032c9a54e015b97",
     "grade": false,
     "grade_id": "cell-b6c97e0e7e611020",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.3: Standard Error</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the standard error of the test statistic. \n",
    "\n",
    "_Assign your answer to an object called `dangar_std_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42a306d381a7ad7898f3d1463f4c62a4",
     "grade": false,
     "grade_id": "cell-4ddc593b0daca66d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dangar_std_error <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dangar_std_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5990faecbb1263e06b97bc6dd556d684",
     "grade": true,
     "grade_id": "cell-fd3aeec68bf192f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "715928f1ac32a8f808f7966fa0f3361e",
     "grade": false,
     "grade_id": "cell-b1bbbaefdfde818a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.4: P-Value</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the p-value of the observed test statistic using t-distribution.\n",
    "\n",
    "_Assign your answer to an object called `dangar_p_value`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d9e0cfddbb95921a603a59568d2a7f1",
     "grade": false,
     "grade_id": "cell-01689a7333b0a91b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dangar_p_value <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dangar_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "553424ba1c7520252be31aef9f7a7391",
     "grade": true,
     "grade_id": "cell-ffbdf5552e7f97b5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"dangar_p_value\"', {\n",
    "  expect_true(exists(\"dangar_p_value\"))\n",
    "})\n",
    "answer_as_numeric <- as.numeric(dangar_p_value)\n",
    "test_that(\"Solution should be a number\", {\n",
    "  expect_false(is.na(answer_as_numeric))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5212a3b76e2d85ebc7f2dd2fb3587f",
     "grade": false,
     "grade_id": "cell-ed20fd90fed54c31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 2.5: Confidence Interval </b>\n",
    "<br> {points:1}\n",
    "\n",
    "Calculate the 90% confidence interval of the population mean $\\mu$. \n",
    "\n",
    "Use the scaffolding below:\n",
    "\n",
    "`dangar_mean_ci <- tibble(\n",
    "    lower_ci = ...\n",
    "    upper_ci = ...\n",
    ")` \n",
    "\n",
    "(Hint: the function `qt` can help you).\n",
    "\n",
    "_Assign your data frame to an object called `dangar_mean_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd0e14796538488f8c6506e4779f856c",
     "grade": false,
     "grade_id": "cell-ee48198e8bb5266c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dfed020f499c95acb9c405da120b939",
     "grade": true,
     "grade_id": "cell-8412a03985988198",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"dangar_mean_ci\"', {\n",
    "  expect_true(exists(\"dangar_mean_ci\"))\n",
    "})\n",
    "test_that(\"Solution should be a data frame\", {\n",
    "  expect_true(\"data.frame\" %in% class(dangar_mean_ci))\n",
    "})\n",
    "\n",
    "expected_colnames <- c(\"lower_ci\", \"upper_ci\")\n",
    "given_colnames <- colnames(dangar_mean_ci)\n",
    "test_that(\"Data frame does not have the correct columns\", {\n",
    "  expect_equal(length(setdiff(\n",
    "    union(expected_colnames, given_colnames),\n",
    "    intersect(expected_colnames, given_colnames)\n",
    "  )), 0)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e0ee9d315ae0f562dce552c643427ec",
     "grade": false,
     "grade_id": "cell-686d44b65da860c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6: Conclusion**\n",
    "<br>{points: 1}\n",
    "\n",
    "What can we conclude from this test?\n",
    "\n",
    "A. Since the `p-value` is lower than 10%, we don't have enough evidence to reject $H_0$ and conclude that the average fish's length in Dangar is 11cm.\n",
    "\n",
    "B. Since the `p-value` is lower than 10%, we have enough evidence to reject $H_0$ and conclude that the average fish's length in Dangar is not 11cm.\n",
    "\n",
    "_Assign your answer to an object called `answer2.6`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4067d3d6df2c8fac002b1692c98963b7",
     "grade": false,
     "grade_id": "cell-1cfe84eb36891a94",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e5ada96166c8c515354c9fa0d972817",
     "grade": true,
     "grade_id": "cell-85b5e16fd3160d91",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer2.6\"', {\n",
    "  expect_true(exists(\"answer2.6\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\" or \"B\")', {\n",
    "  expect_match(answer2.6, \"a|b\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a13aac9ef09908bd700b0b9011579b81",
     "grade": false,
     "grade_id": "cell-42738f7f4f0d52ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.7** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use R's `t.test` function to test the hypotheses $H_0: \\mu = 11$. Make sure to use `broom::tidy()` to get a more organized result.\n",
    "\n",
    "_Assign your data frame to an object called `dangar_t_test`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40f22382bac33e2178306226745e9e0c",
     "grade": false,
     "grade_id": "cell-d4e5e466203bcc2b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dangar_t_test <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dangar_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "499db3a3a3b7467121c12928e62d756e",
     "grade": true,
     "grade_id": "cell-ee8be1f61a5a8f39",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"dangar_t_test\"', {\n",
    "  expect_true(exists(\"dangar_t_test\"))\n",
    "})\n",
    "test_that(\"Solution should be the output of t.test\", {\n",
    "    expect_true(\"data.frame\" %in% class(dangar_t_test))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9151b2a5fb5548372d81c979ecbb8dcd",
     "grade": false,
     "grade_id": "cell-3975cc4fd8ece220",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Chronic Bronchial Reaction to Dust\n",
    "\n",
    "In this section, we will study the `dust` dataset, which records the survey result of the chronic bronchial reaction of employees of a Munich factory. Let's load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70900b9af9dad4f881bbe6db0b3a414c",
     "grade": false,
     "grade_id": "cell-09bbc9ab6c12a176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dust <- read_csv(\"data//dust.csv\")\n",
    "head(dust %>% slice_sample(n = 6)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46fad33f6c78b9f794d326bb0e07469f",
     "grade": false,
     "grade_id": "cell-8374bbf47fddcf90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's assume that all of the employees are exposed to the same dust concentration within the factory. Let $p_{0}$ be the proportion of non-smoking employees (`smoke==0`) that have a chronic bronchial reaction, and let $p_{1}$ be the proportion of smoking employees (`smoke==1`) that have a chronic bronchial reaction. We will perform hypothesis testing on the difference in proportions $p_{1}-p_{0}$ at a 5% significance level.\n",
    "\n",
    "Our null hypothesis is that smoking is unrelated to chronic bronchitis in this factory ($p_{1}=p_{0}$), while the alternative hypothesis is that there is a difference in proportions of employees having chronic bronchitis between the smokers and the non-smokers ($p_{1} \\neq p_{0}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "671cdf7a019e12042a66d0319e5bdbb2",
     "grade": false,
     "grade_id": "cell-b1e26d08a125a208",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "smoke_bronch <- dust %>%\n",
    "                    select(\"bronch\", \"smoke\") %>%\n",
    "                    filter(!is.na(smoke))  %>%\n",
    "                    mutate(smoke = recode(smoke, `0`=\"non_smoker\", `1`=\"smoker\"),\n",
    "                           bronch = fct_recode(factor(bronch), \"no_reaction\" = \"0\", \"reaction\" = '1'))\n",
    "head(smoke_bronch)\n",
    "table(smoke_bronch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79e9aa410ae76e0b77abe10d5b54bfa9",
     "grade": false,
     "grade_id": "cell-e7e1924b2d648a46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.1: Observed test statistic</b>\n",
    "<br> {points:1}\n",
    "\n",
    "Calculate the observed test statistic $\\hat{p}_1-\\hat{p}_0$. \n",
    "\n",
    "_Assign your data frame to an object called `dust_summary`. The data frame should contain five columns: `n_non_smoker`,\t`n_smoker`,\t`p_hat_non_smoker`,\t`p_hat_smoker`, and `prop_diff`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "544f8114d643ba69a95d9c00c1d747bf",
     "grade": false,
     "grade_id": "cell-d6047bea6a8ece4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# dust_summary <-\n",
    "#     smoke_bronch %>% \n",
    "#     group_by(...) %>% \n",
    "#     summarise(n = ..., \n",
    "#               p_hat = ...,  \n",
    "#              `.groups` = \"drop\") %>% \n",
    "#     pivot_wider(names_from = smoke, values_from = c(n, p_hat)) %>% \n",
    "#     mutate(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dust_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f2c98c07f9fd73904b105ccb947856f",
     "grade": true,
     "grade_id": "cell-321f77d28e5cfd66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7073775326cadab2e705b8564b2e868",
     "grade": false,
     "grade_id": "cell-fba8e97df6d6e6d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.2</b>\n",
    "<br> {points:1}\n",
    "\n",
    "Add a sixth column to `dust_summary`, named `null_std_error`, with the standard error of the test statistic under the null model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e5d8802cbcabd62ffd45a54ce0bbf9c",
     "grade": false,
     "grade_id": "cell-e74749361b4da832",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dust_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2cad626023469beca49c131d42748c",
     "grade": true,
     "grade_id": "cell-fb16182231ab71f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "  test_that('Did not assign answer to an object called \"dust_summary\"', {\n",
    "    expect_true(exists(\"dust_summary\"))\n",
    "  })\n",
    "\n",
    "  test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(dust_summary))\n",
    "  })\n",
    "\n",
    "  expected_colnames <- c(\"n_non_smoker\", \"n_smoker\", \"p_hat_non_smoker\", \"p_hat_smoker\", \"prop_diff\", \"null_std_error\")\n",
    "  given_colnames <- colnames(dust_summary)\n",
    "  test_that(\"Data frame does not have the correct columns\", {\n",
    "    expect_equal(length(setdiff(\n",
    "      union(expected_colnames, given_colnames),\n",
    "      intersect(expected_colnames, given_colnames)\n",
    "    )), 0)\n",
    "  })\n",
    "\n",
    "  test_that(\"Data frame does not contain the correct number of rows\", {\n",
    "    expect_equal(digest(as.integer(nrow(dust_summary))), \"4b5630ee914e848e8d07221556b0a2fb\")\n",
    "  })\n",
    "\n",
    "  test_that(\"Data frame does not contain the correct data\", {\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$n_non_smoker))), \"87f3407882014ba8f18016b8e408ad35\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$n_smoker))), \"76bb48cccd68153482cda2b8ebfecd93\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$p_hat_non_smoker) * 10e6)), \"e772aa3c54a729784d27e153931979c7\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$p_hat_smoker) * 10e6)), \"65105150a89cf0f1e8f0b93ae773058d\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$prop_diff) * 10e6)), \"2b59c114711ded35f1991bdb2cfe5562\")\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5004bf3be103be390fb9e520c21b9942",
     "grade": false,
     "grade_id": "cell-6e35b178ece4b5ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 3.3:</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Add another column to `dust_summary`, named `p_value`, with the p-value of the test statistic calculated using the CLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50bc2ec770dd48217d695e1441c73ffc",
     "grade": false,
     "grade_id": "cell-478ce0cc8ccaa607",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dust_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6c6e3f07ea73e66fb55f556b372bc2",
     "grade": true,
     "grade_id": "cell-b2957c7169b94d37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "  test_that('Did not assign answer to an object called \"dust_summary\"', {\n",
    "    expect_true(exists(\"dust_summary\"))\n",
    "  })\n",
    "\n",
    "  test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(dust_summary))\n",
    "  })\n",
    "\n",
    "  expected_colnames <- c(\"n_non_smoker\", \"n_smoker\", \"p_hat_non_smoker\", \"p_hat_smoker\", \"prop_diff\", \"null_std_error\", \"p_value\")\n",
    "  given_colnames <- colnames(dust_summary)\n",
    "  test_that(\"Data frame does not have the correct columns\", {\n",
    "    expect_equal(length(setdiff(\n",
    "      union(expected_colnames, given_colnames),\n",
    "      intersect(expected_colnames, given_colnames)\n",
    "    )), 0)\n",
    "  })\n",
    "\n",
    "  test_that(\"Data frame does not contain the correct number of rows\", {\n",
    "    expect_equal(digest(as.integer(nrow(dust_summary))), \"4b5630ee914e848e8d07221556b0a2fb\")\n",
    "  })\n",
    "\n",
    "  test_that(\"Data frame does not contain the correct data\", {\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$n_non_smoker))), \"87f3407882014ba8f18016b8e408ad35\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$n_smoker))), \"76bb48cccd68153482cda2b8ebfecd93\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$p_hat_non_smoker) * 10e6)), \"e772aa3c54a729784d27e153931979c7\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$p_hat_smoker) * 10e6)), \"65105150a89cf0f1e8f0b93ae773058d\")\n",
    "    expect_equal(digest(as.integer(sum(dust_summary$prop_diff) * 10e6)), \"2b59c114711ded35f1991bdb2cfe5562\")\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c013f9412c4d8379004d018900a1d98d",
     "grade": false,
     "grade_id": "cell-90e5cb997b7e41a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use R's `prop.test` function to test the hypothesis. Make sure to use the `correct = FALSE`.\n",
    "Make sure to use `broom::tidy()` to get a more organized result.\n",
    "\n",
    "_Assign your data frame to an object called `dust_prop_test`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2d9fef2996649cd362b7566e5b5da32",
     "grade": false,
     "grade_id": "cell-f3f2e5e35a535fc4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "dust_prop_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47a443b4e4a38242f2f9768e76a13a2",
     "grade": true,
     "grade_id": "cell-e99c6f5030213b7c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "435c86b13dbaccd2a93cdf29e5258692",
     "grade": false,
     "grade_id": "cell-4d435a1af0f72198",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "What can we conclude from this test?\n",
    "\n",
    "A. It would be very unlikely to observe a difference in proportion $\\hat{p}_1 - \\hat{p}_2 = 0.104749$ among 325 smokers and 921 non-smokers, if the proportions were the same. Therefore, we reject $H_0$ at 5% significance level and conclude that smokers have a higher chance of having a reaction.\n",
    "\n",
    "B. It would be very unlikely to observe a difference in proportion $\\hat{p}_1 - \\hat{p}_2 = 0.104749$ among 325 smokers and 921 non-smokers, if the proportions were the same. Therefore, we accept $H_0$ at 5% significance level and conclude that smokers do not have a higher chance of having a reaction.\n",
    "\n",
    "C. It is quite plausible to observe a difference in proportion $\\hat{p}_1 - \\hat{p}_2 = 0.104749$ among 325 smokers and 921 non-smokers, if the proportions were the same. Therefore, we do not reject $H_0$ at 5% significance level and conclude that smokers do not have a higher chance of having a reaction.\n",
    "\n",
    "D. It is quite plausible to observe a difference in proportion $\\hat{p}_1 - \\hat{p}_2 = 0.104749$ among 325 smokers and 921 non-smokers, if the proportions were the same. Therefore, we reject $H_0$ at 5% significance level and conclude that smokers have a higher chance of having a reaction.\n",
    "\n",
    "_Assign your answer to an object called `answer3.5`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03fe2c45b94a6b5ec0d0ce8985deb863",
     "grade": false,
     "grade_id": "cell-1849f303dfd420d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.5 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a866f9d236d3c0fda28a8547101e742",
     "grade": true,
     "grade_id": "cell-597712c9e4a395eb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer3.5\"', {\n",
    "  expect_true(exists(\"answer3.5\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "  expect_match(answer3.5, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1863850f64004d310a388aa1a8bf009b",
     "grade": false,
     "grade_id": "cell-52d053e74919bd2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. The difference in lengths of fish species\n",
    "\n",
    "We will use the `fishcatch` dataset, which records the measurement of 159 fish of 7 species from the lake Laengelmavesi near Tampere in Finland. More details of the dataset are in http://jse.amstat.org/datasets/fishcatch.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10de1d7f0abbbcfa2ae3aee6479ae66c",
     "grade": false,
     "grade_id": "cell-caee0e7a808b7b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fish <- read.table(\"http://jse.amstat.org/datasets/fishcatch.dat.txt\", header=FALSE)\n",
    "colnames(fish) <- c(\"Obs\", \"Species\", \"Weight\", \"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\", \"Sex\")\n",
    "head(fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fb64aa5d0d767da60deb0f7cb6b6d33",
     "grade": false,
     "grade_id": "cell-a288c75a0ddb7ae8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We are interested to see if there is a significant difference in the length from the nose to the end of the tail (`Length3`) of the two species Bream (`Species==1`) and Roach (`Species==3`). Let $\\mu_1$ be the mean of Bream's length, and let $\\mu_2$ be the mean of Roach's length. We will perform hypothesis testing on $\\mu_1 - \\mu_2$ at a 5 % significance level. The null hypothesis is $\\mu_1 = \\mu_2$.\n",
    "\n",
    "<b>Question 4.1: Alternative Hypothesis</b>\n",
    "<br> {point: 1}\n",
    "\n",
    "What is an appropriate alternative hypothesis?\n",
    "\n",
    "A. $\\mu_1 > \\mu_2$\n",
    "\n",
    "B. $\\mu_1 \\neq \\mu_2$\n",
    "\n",
    "C. $\\mu_1 < \\mu_2$\n",
    "\n",
    "<i>Your answer should be a string with one letter assigned to the variable </i>`answer4.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b0e79b4d9fbb1675860e38735af3363",
     "grade": false,
     "grade_id": "cell-e11fbc487a032a19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer4.1 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "answer4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92ccb1056eeddfd4f09efcc43495d8f4",
     "grade": true,
     "grade_id": "cell-e16a90d8922ce521",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer4.1\"', {\n",
    "  expect_true(exists(\"answer4.1\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", or \"C\")', {\n",
    "  expect_match(answer4.1, \"a|b|c\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6316e7fffbd9ca5f39592b77ef8e148",
     "grade": false,
     "grade_id": "cell-5bf2fc6cb7a33dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 4.2</b>\n",
    "<br> {points:1}\n",
    "\n",
    "Filter the `fish` data set to only keep the Bream (`Species==1`) and Roach (`Species==3`) species, and only keep the `Species` and `Length3` columns. Replace the species code with the name of the species. \n",
    "\n",
    "_Assign your data frame to an object called `bream_roach`. The data frame should contain two columns: `Species` and `Length3`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b798267c70c3ee9fbb44942b89f0f90d",
     "grade": false,
     "grade_id": "cell-efe438fd11bc0703",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# bream_roach <- \n",
    "#     fish %>%\n",
    "#     select(...) %>%\n",
    "#     filter(...) %>%\n",
    "#     mutate(Species = fct_recode(as_factor(Species), Bream='1', Roach='3'))\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(bream_roach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93377ab044d1d5a76a98fcb178a2cbae",
     "grade": true,
     "grade_id": "cell-15dec3e4e4868170",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cba5be6ba459582b5181c6a727794fcf",
     "grade": false,
     "grade_id": "cell-bde2779ff4108d68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 4.3: Observed Test Statistic </b>\n",
    "<br> {points: 1}\n",
    "\n",
    "In this exercise, you need to:\n",
    "\n",
    "1. obtain the sample size of `Bream` and `Roach` species. \n",
    "2. calculate the sample average and standard deviation of `Length3` for `Bream` species.\n",
    "3. calculate the sample average and standard deviation of `Length3` for `Roach` species.\n",
    "4. calculate observed test statistic $\\bar{X}_1 - \\bar{X}_2$, where $\\bar{X}_1$ and $\\bar{X_2}$ are the sample average of `Length3` of `Bream` and `Roach` species, respectively. \n",
    "\n",
    "_Assign your data frame to an object called `bream_roach_summary`. The data frame should contain seven columns: `n_Bream`,\t`n_Roach`, `x_bar_Bream`, `x_bar_Roach`, `sd_Bream`, `sd_Roach`, and `mean_diff`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd1e492d435b41515e2d6656b8a9b4db",
     "grade": false,
     "grade_id": "cell-5ae4939f0d87e8b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# bream_roach_summary <-\n",
    "#     bream_roach %>% \n",
    "#     group_by(...) %>% \n",
    "#     summarise(n = ...,\n",
    "#               x_bar = ...,\n",
    "#               sd = ...,\n",
    "#               `.groups` = \"drop\") %>% \n",
    "#     pivot_wider(names_from = Species, values_from = c(n, x_bar, sd)) %>% \n",
    "#     mutate(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "bream_roach_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ddb456812a7031c20357a9c92940afa",
     "grade": true,
     "grade_id": "cell-9099e2ce70e5014c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "435c6a31e7f3afc1fde23ac0f40fe274",
     "grade": false,
     "grade_id": "cell-7fec4fe844c5562f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 4.4: Standard deviation of the test statistic </b>\n",
    "<br> {points:1}\n",
    "\n",
    "Add another column to `bream_roach_summary`, named `null_std_error`, with the standard error of the test statistics $\\bar{X}_1 - \\bar{X}_2$ under the null model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1b71e1411527b7fa43c15c24dc0f36d",
     "grade": false,
     "grade_id": "cell-7d1c51f760a4b5ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "bream_roach_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f17cc7c5e7c96379bb9dc266b8f4cfe",
     "grade": true,
     "grade_id": "cell-d96caf3d80d08480",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f37ee80e2880bdf08161847d09ad6df",
     "grade": false,
     "grade_id": "cell-383b076ebbbd623a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 4.5: Obtaining p-value </b>\n",
    "<br> {points:1}\n",
    "\n",
    "Add another column to `bream_roach_summary`, named `p_value`, with the test's p-value using the t-distribution. To help you, we calculated the approximate degrees of freedom for you: 40.7105 (for details on how to obtain this value, see Question 3.3.4 from Worksheet_08). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd861170d2be8cfe69b24cc3fb1dd10c",
     "grade": false,
     "grade_id": "cell-25a19360d259a5f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "bream_roach_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f09ce78e265364d2e0026b5b44d6938",
     "grade": true,
     "grade_id": "cell-0da44e46c587a6d5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5d3740338490bf3c42e35e43f2ae7e0",
     "grade": false,
     "grade_id": "cell-2eb2f8bacd5cc983",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 4.6** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use R's `t.test` function to test the hypothesis. Make sure to use `broom::tidy()` to get a more organized result.\n",
    "\n",
    "_Assign your data frame to an object called `bream_roach_t_test`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "333f87b0fed54f84da0887b129b9249c",
     "grade": false,
     "grade_id": "cell-e7af0c2c6e325b85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# bream_roach_t_test <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "bream_roach_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb6355e0ebcb5ec69103c459166c953c",
     "grade": true,
     "grade_id": "cell-b54b22e8936ed299",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_4.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90b0c093971c42101d798a7ec3515ab7",
     "grade": false,
     "grade_id": "cell-a9770cbe93b71f71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 4.7: Conclusion of the test</b>\n",
    "<br>{points: 1}\n",
    "\n",
    "It would be unlikely to observe a difference in the average length of 13.38 if both species had the same mean length. Therefore, we reject $H_0$ at the following significance levels:\n",
    "\n",
    "A. 10%\n",
    "\n",
    "B. 5%\n",
    "\n",
    "C. 1%\n",
    " \n",
    "D. 0.01%\n",
    "\n",
    "E. All the above.\n",
    "\n",
    "_Assign your answer to an object called `answer4.7`. Your answer should be a single character surrounded by quotes._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7d2eff9f40ee8c8e704398df3b1cdc9",
     "grade": false,
     "grade_id": "cell-955096caa6841343",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer4.7 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1786d4efc19dc86785eda1928f2b2abe",
     "grade": true,
     "grade_id": "cell-7c3499054494fd09",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer4.7\"', {\n",
    "  expect_true(exists(\"answer4.7\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", \"D\", or \"E\")', {\n",
    "  expect_match(answer4.7, \"a|b|c|d|e\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de7f9a0dfefbb8870e0b2037091a712d",
     "grade": false,
     "grade_id": "cell-4772b89b35af0c64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5. Soybean: stress vs non-stress\n",
    "\n",
    "For this question, we will use the `soybean` dataset. First, let's load and preview the data. Since the dataset is small, we can examine the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5392d985dba06320a0a0311919a888e9",
     "grade": false,
     "grade_id": "cell-9e6e756eaddff316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "soybean <- read_csv(\"data/soybean.csv\")\n",
    "soybean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a92113ec33a58ae6d0f300de82371893",
     "grade": false,
     "grade_id": "cell-0c431799009b7159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here's the description of the data set taken directly from the package `isdals`' documentation:\n",
    "\n",
    ">An experiment was carried out with 26 soybean plants. The plants were pairwise genetically identical, so there were 13 pairs in total. For each pair, one of the plants was 'stressed' by being shaken daily, whereas the other plant was not shaken. After a period the plants were harvested and the total leaf area was measured for each plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a60dfab8608b0dc31ba6245df0d0228",
     "grade": false,
     "grade_id": "cell-2509e9345878c011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&emsp; We would like to investigate whether the stress induced by daily shaking the plants affects the total leaf area. Let $\\mu_1$ be the average of the total leaf area of stressed plants, and let $\\mu_0$ be the average of the total leaf area of unstressed plants. We would like to do hypothesis testing on $\\mu_1-\\mu_0$ at a 5% significance level and suppose that the null hypothesis is $\\mu_1=\\mu_0$. We would like to test the difference in paired means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "236c7028215fd8baadd4367b4cff9730",
     "grade": false,
     "grade_id": "cell-93b6b66998918b1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b>Question 5.1: Mean and standard deviation</b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Lets create the summary data frame for `soybean` data set. Your job is to:\n",
    "\n",
    "1. calculate the difference between the pairs, save it in a column named `d;\n",
    "2. calculate the mean and standard deviation of the differences, stored in columns `d_bar` and `sd`, respectively; \n",
    "3. calculate the standard error of the mean difference and store it in a column `std_error`;\n",
    "4. finally, store the sample size as well in a column called n.\n",
    "\n",
    "_Assign your data frame to an object called `soybean_summary`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ab8937c9785a8228b927ddf14a3f4e6",
     "grade": false,
     "grade_id": "cell-818e72f8d3e1921b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# soybean_summary <-\n",
    "#     soybean_original %>% \n",
    "#     mutate(...) %>% \n",
    "#     summarise(n = n(), \n",
    "#               d_bar = ..., \n",
    "#               sd =...,\n",
    "#               std_error = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "soybean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20ddb0fae771a71a2fe4520e75aaf55e",
     "grade": true,
     "grade_id": "cell-b163f0db45fb1aff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_5.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a6188785724560d4235223ea5943ba6",
     "grade": false,
     "grade_id": "cell-09c0111f91da4053",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<b> Question 5.2: P-value </b>\n",
    "<br> {points: 1}\n",
    "\n",
    "Add another column to `soybean_summary`, named `p_value`, with the p-value associated with the observed test statistic `d_bar`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84a7f0efba2261a31d8acd3962491b2e",
     "grade": false,
     "grade_id": "cell-19d96c09c88e2934",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "soybean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf66e89f498575ba564c7bb6ff409cd8",
     "grade": true,
     "grade_id": "cell-ccbc186116158585",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "  test_that('Did not assign answer to an object called \"soybean_summary\"', {\n",
    "    expect_true(exists(\"soybean_summary\"))\n",
    "  })\n",
    "\n",
    "  test_that(\"Solution should be a data frame\", {\n",
    "    expect_true(\"data.frame\" %in% class(soybean_summary))\n",
    "  })\n",
    "\n",
    "  expected_colnames <- c(\"n\", \"d_bar\", \"sd\", \"std_error\", \"p_value\")\n",
    "  given_colnames <- colnames(soybean_summary)\n",
    "  test_that(\"Data frame does not have the correct columns\", {\n",
    "    expect_equal(length(setdiff(\n",
    "      union(expected_colnames, given_colnames),\n",
    "      intersect(expected_colnames, given_colnames)\n",
    "    )), 0)\n",
    "  })\n",
    "  test_that(\"Data frame does not contain the correct number of rows\", {\n",
    "    expect_equal(digest(as.integer(nrow(soybean_summary))), \"4b5630ee914e848e8d07221556b0a2fb\")\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd27815015d2522cace450cd65393d66",
     "grade": false,
     "grade_id": "cell-04dcb4e650c5a14f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 5.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use R's `t.test` function to test the hypotheses. Make sure to use `broom::tidy()` to get a more organized result.\n",
    "\n",
    "_Assign your data frame to an object called `soybean_t_test`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "231adb628c7c10fc18aed74aa1b25d76",
     "grade": false,
     "grade_id": "cell-2a6e41fda667b8b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "soybean_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7775c89c54c54f45aaff9181fe7aec3f",
     "grade": true,
     "grade_id": "cell-773d4f54070c07de",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_5.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3cc130388d73dfa1a7b4cf892185a74",
     "grade": false,
     "grade_id": "cell-352598e6e338e7fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 5.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "We reject at 5% significance the null hypothesis that the mean total leaf area is the same for stressed and no-stressed soybeans. \n",
    "\n",
    "_Assign your answer to an object called `answer5.4`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13f96199569f07285aa41a8f004eed41",
     "grade": false,
     "grade_id": "cell-c53a24ccc64645e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer5.4 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a1351f0875f40aa822b7b56c62665c6",
     "grade": true,
     "grade_id": "cell-6c8f47dafd6af2ef",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer5.4\"', {\n",
    "  expect_true(exists(\"answer5.4\"))\n",
    "})\n",
    "test_that('Answer should be \"true\" or \"false\"', {\n",
    "  expect_match(answer5.4, \"true|false\", ignore.case = TRUE)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
