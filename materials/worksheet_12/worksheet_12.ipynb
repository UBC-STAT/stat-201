{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34979d8644490027157f2d7058412bc6",
     "grade": false,
     "grade_id": "cell-a02bfa12010e4d4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 12: A/B Testing and principled peeking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae65a1f6be90c5a0ac9866d089f0568e",
     "grade": false,
     "grade_id": "cell-5bf3eac0664df934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Learning Objectives \n",
    "\n",
    "After completing this week's worksheet and tutorial work, you will be able to:\n",
    "\n",
    "1. Explain sequential testing and principled peeking and how it can be used for early stopping of an experiment (e.g., A/B testing).\n",
    "2. Write a computer script to perform A/B testing optimization with and without using principled peeking.\n",
    "3. Discuss the tradeoff between stopping earlier and certainty of significance, and thereal world implications (e.g., what does the FDA require for early stopping of clinical trials versus Facebook ads optimization?).\n",
    "4. List other questions related to A/B testing optimization that may be relevant in a real data application (e.g., what features cause a Facebook ad to perform best?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a7d8be3a5ee43163f24092c2b693a0",
     "grade": false,
     "grade_id": "cell-aeb5ce9a4b99cc68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dee03a497236dfc38f773137f7f1767a",
     "grade": false,
     "grade_id": "cell-e27b96fe9888ea42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(infer)\n",
    "library(broom)\n",
    "library(gsDesign)\n",
    "\n",
    "source(\"tests_worksheet_12.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c65cb8520f6d6331ceffbb69311fbc89",
     "grade": false,
     "grade_id": "cell-c1081d96a47b5814",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b04a0d804886e5cec4f0a1803a6868d",
     "grade": false,
     "grade_id": "cell-3a017e5bee55fcfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. A/B Testing Optimization\n",
    "\n",
    "**A/B testing** refers to an experiment in which users are randomly assigned to one of two variations of a product or service: control (A) and variation (B) to see if variation B should be used for improvement.\n",
    "\n",
    "> A/B testing became very popular for updating and improving websites. However, it can also be used to monitor and update products and/or services in many other contexts.\n",
    "\n",
    "A key factor in A/B testing is deciding which statistical tool will be used to analyze the data collected. \n",
    "For example, a classical ùë°-test can be used to compare differences in population means. In this worksheet, we will review some fundamental concepts of hypothesis testing in the context of A/B testing problems.\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For the questions in this section, suppose that you are designing an A/B test to determine whether a new website used to collect donations for a political campaign increases donation sizes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "458af65583fbf4ecbfc8cdf21b359af4",
     "grade": false,
     "grade_id": "cell-6cee65fd8f6124c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Before analyzing the collected data, it is essential to decide the significance level of the test (i.e., Type I error rate). This quantity is interpreted as:\n",
    "\n",
    "**A.** the probability of finding a significant difference between the donation sizes collected from two variations of the website when the new website indeed attracts, on average, larger donations.\n",
    "\n",
    "**B.** the probability of *not* finding a significant difference between the donation sizes collected from two variations of the website when the new website indeed attracts, on average, larger donations.\n",
    "\n",
    "**C.** the probability of finding a significant difference between the donation sizes collected from two variations of the website when the mean of the size of the donations of both websites are equal.\n",
    "\n",
    "**D.** the probability that the new website indeed attracts larger donations.\n",
    "\n",
    "*Assign your answer to an object called `answer1.0`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8826f1f8b79f1a67c26027d6d409eff",
     "grade": false,
     "grade_id": "cell-1995b40417991d4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dbc59f877e1b2896551b7b859b2c942",
     "grade": true,
     "grade_id": "cell-6dd3efdd0b5f8be8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f0365c4f92f0caeff7ae2587d68ee1c",
     "grade": false,
     "grade_id": "cell-fde3bc40bf7b213a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "The designers of the experiment also need to decide how large the experiment will be since there are large costs (including opportunity costs) related to the experiment. \n",
    "\n",
    "Thus, for the statistical test planned, they decide to conduct a **power analysis** to:\n",
    "\n",
    "**A.** estimate the minimum sample size required, given a desired significance level, expected difference in mean donations, and statistical power.\n",
    "\n",
    "**B.** maximize the probability of finding a significant difference between the donation sizes collected from two variations of the website.\n",
    "\n",
    "**C.** minimize the probability of not finding a significant difference between the donation sizes collected from two variations of the website.\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer1.1`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6163eb258ca2f22579aa7e773d2a05c",
     "grade": false,
     "grade_id": "cell-9f84185e30e2353a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2227cf832660b1107647d51eaa49bfa4",
     "grade": true,
     "grade_id": "cell-1bf75eb9cdbe85fb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "177765e1131d1cdd0470bfb4bdf41b61",
     "grade": false,
     "grade_id": "cell-f3908eb5114147b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Consider the following scenario:\n",
    "\n",
    "After deciding on the sample size required and *randomly* assigning visitors to each variation of the website, the company will start analyzing the size of the donations made by visitors. \n",
    "\n",
    "Assuming the planned sample size is large enough, the analysts will conduct CLT-based statistical inference, i.e., compute $p$-values and confidence intervals based on the CLT results.\n",
    "\n",
    "Considering the opportunity costs involved in this experiment, the analysts will monitor the size of the donations closely and stop the experiment earlier if they find (using a standard two-sample $t$-test) that the new website attracts higher donations. \n",
    "\n",
    "However, computing non-adjusted $p$-values before collecting all the data in the experiment and stopping the experiment based on preliminary findings can result in a false discovery, which can lead to an unnecessary change to a new website variation and an increase in expenditure due to the costs associated with such a change.\n",
    "\n",
    "Is the reasoning above *true* (correct) or *false* (incorrect)?\n",
    "\n",
    "*Assign your answer to an object called answer1.2 Your answer should be either \"true\" or \"false\", surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99bf05d18a74cf6028c1510b6897f8ce",
     "grade": false,
     "grade_id": "cell-26a62021df5e0239",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52ac9cf1a9bf42864f598bb26cfbe929",
     "grade": true,
     "grade_id": "cell-d74e84bf990ca0e4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b2547696d1ee33017c2a199b2ef9e42",
     "grade": false,
     "grade_id": "cell-0e6dc2486456debb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2. Early Stopping in A/B Testing\n",
    "\n",
    "In this section you will analyze data from an A/A experiment to examine the problem of <u>early stopping</u>:\n",
    "\n",
    "> *Can we stop or re-design the experiment earlier if we have supporting evidence to do so?*\n",
    "\n",
    "Note that in A/A testing, we know that $H_0$ is true (i.e., there is no effect); that's the whole purpose of A/A testing. For example, we can think of a scenario where both groups are exposed to the same website. In A/A testing, we know that claiming a significant result is a false discovery\n",
    "  \n",
    "Although this procedure seems artificial, it is a widely used technique to test experiments and platforms because it allows you to estimate the error rates associated with your experiment by repeating it multiple times.\n",
    "\n",
    "![img](img/aa-Obama.png)\n",
    "<font color=grey>Figure by [R. Lourenzutti](https://lourenzutti.github.io) </font>\n",
    "\n",
    "Each simulated dataset will be analyzed according to the following steps:\n",
    "\n",
    "1. run a balanced experiment with a *pre-set* sample size of $n$ visitors per variation \n",
    "\n",
    "2. sequentially collect the data in batches of visitors per group\n",
    "\n",
    "3. sequentially analyze the data using two-sample $t$-tests\n",
    "\n",
    "4. sequentially compute and monitor* the $p$-values (non-adjusted) \n",
    "\n",
    "5. stop the experiment once a significant result is found "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ca251c8a579be7f1727e80bcb7729d9",
     "grade": false,
     "grade_id": "cell-c75f59a0dcf09528",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Simulation function\n",
    "\n",
    "We have prepared a function for you that: \n",
    "\n",
    "- generates two samples, each of size `n`, from two (known) Normal distributions, the control and the variation. Note that in real data analysis, we collect data from an *unknown* distribution (i.e., not necessarily Normal). \n",
    "\n",
    "- analyzes the data in an incremental way by `sample_increase_step` until all `n` samples in each treatment group are analyzed. For example, we compare donations by batches of visitors of each website variation.\n",
    "\n",
    "- returns the $t$-statistic and $p$-value (computed by a two-sample $t$-test) for every batch of collected data.\n",
    "\n",
    "For example, if `sample_increase_step` is 20, and `n=500`, the function will:\n",
    "1. draw the first 20 experimental units from each group;\n",
    "\n",
    "2. perform the two-sample $t$-test and return the associated $t$-statistic and $p$-value;\n",
    "\n",
    "3. draw 20 more experimental units for each group \n",
    "\n",
    "4. perform the two-sample $t$-test (now based on 40 experimental units per group) and return the associated $t$-statistic and $p$-value  \n",
    "\n",
    "5. draw another 20 experimental units for each group \n",
    "\n",
    "6. perform the two-sample $t$-test (now based on 60 experimental units per group) and return the associated $t$-statistic and $p$-value \n",
    "$$\n",
    "\\vdots\\hspace{18cm}\n",
    "$$\n",
    "and so on, until the total sample size in each group is 500 (as originally planned).\n",
    "\n",
    "The function returns a tibble that has three columns:\n",
    "\n",
    "- `inc_sample_size`: the sample size of the set of data analyzed \n",
    "- `statistic`: $t$-statistic calculated by the `t.test()` function\n",
    "- `p_value`: $p$-value calculated by the `t.test()` function\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "_<u>Note: You don't need to understand the code for this function; it's enough to understand what the function is doing (as explained above) and the function's arguments as detailed in the comments of the code block below.</u>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84cb64cd0fa0dcbf53832dcc87293c98",
     "grade": false,
     "grade_id": "cell-a1fc35871231916c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Two-sample t-test with tracking sequential statistic and p-values \n",
    "# by incremental sample sizes until getting to n in each group.\n",
    "\n",
    "# @param n (numeric): Initially planned sample size for each group (for simplicity,\n",
    "#                     n needs to be a multiple of sample_increase_step).\n",
    "# @param d_0 (numeric): effect size.\n",
    "# @param mean_current (numeric): Population mean for control variation.\n",
    "# @param sd_current (numeric): Population standard deviation for current variation.\n",
    "# @param sd_new (numeric): Population standard deviation for new variation.\n",
    "# @param sample_increase_step (numeric): Sample size increment.\n",
    "\n",
    "# @return p.value.df: A tibble that has 3 columns:\n",
    "# inc_sample_size, statistic, and p_value \n",
    "\n",
    "incremental_t_test <- function(n, d_0, mean_current, sd_current, sd_new, sample_increase_step) {\n",
    "  sample_current <- rnorm(n, mean = mean_current, sd = sd_current)\n",
    "  sample_new <- rnorm(n, mean = mean_current + d_0, sd = sd_new)\n",
    "\n",
    "  p.value.df <- tibble(\n",
    "    inc_sample_size = rep(0, n / sample_increase_step),\n",
    "    statistic = rep(0, n / sample_increase_step),\n",
    "    p_value = rep(0, n / sample_increase_step)\n",
    "  )\n",
    "\n",
    "  current_sample_size <- sample_increase_step\n",
    "  \n",
    "  for (i in 1:nrow(p.value.df))\n",
    "  {\n",
    "    t_test_results <- t.test(sample_new[1:current_sample_size], sample_current[1:current_sample_size],\n",
    "      var.equal = TRUE,\n",
    "      alternative = \"greater\"                      \n",
    "    )\n",
    "    p.value.df[i, \"statistic\"] <- as_tibble(t_test_results$statistic)\n",
    "    p.value.df[i, \"p_value\"] <- as_tibble(t_test_results$p.value)\n",
    "    p.value.df[i, \"inc_sample_size\"] <- current_sample_size\n",
    "    current_sample_size <- current_sample_size + sample_increase_step\n",
    "  }\n",
    "\n",
    "  return(p.value.df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ $$\n",
    "\n",
    "_For the questions in this section, suppose that before running an A/B test to compare the donation sizes from 2 variations of websites in a political campaign, you design an A/A testing to examine the early stopping problem._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39814d6e19d004999a7699f4f60dc9f3",
     "grade": false,
     "grade_id": "cell-665284db692677cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "In a simulation study, we know the true population distributions! The function given to you to simulate the data assumes:\n",
    "\n",
    "**A.** the sample distributions are $\\mathcal{N}(0,1)$\n",
    "\n",
    "**B.** the population distribution of the donation sizes of visitors of the current website is $\\mathcal{N}(\\mu_0,\\sigma_0^2)$, where $\\mu_0$ = mean_current and $\\sigma_0$ = sd_current\n",
    "\n",
    "**C.** the sample distribution of the donation sizes of visitors of the current website is $\\mathcal{N}(\\mu_0,\\sigma_0^2)$, where $\\mu_0$ = mean_current and $\\sigma_0$ = sd_current\n",
    "\n",
    "*Assign your answer to an object called `answer2.0`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1696ed27c4be40fd391e361a52afa95b",
     "grade": false,
     "grade_id": "cell-559e3a0d7e979412",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d29a5e2f3e15862259f9824162826f09",
     "grade": true,
     "grade_id": "cell-ff35930d17aa5189",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd939de4b6b5ec4663f3f78bce78a7a6",
     "grade": false,
     "grade_id": "cell-b13993a85177eb2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Simulate data for an A/A testing from populations with the same expected size of the donations (e.g., assuming all visitors are exposed to the same website). \n",
    "\n",
    "Suppose that the compaign organizers want to analyze the data in batches of 50 visitors per group until a total of $n = 1000$ visitors have watched each website.\n",
    "\n",
    "Use the `incremental_t_test` function to conduct the company's experiment. \n",
    "\n",
    "*Save the result in an object called `answer2.1`. Your answer should be a tibble with three columns: `inc_sample_size`, `statistic` and `p_value`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25f3e95fde459b25a5e602a37e9ff2e5",
     "grade": false,
     "grade_id": "cell-d35500ae42606372",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(301) # do not change this.\n",
    "\n",
    "#answer2.1 <- \n",
    "#    incremental_t_test(n = ..., d_0 = ..., sample_increase_step = ..., mean_current = 200, sd_current = 50, sd_new = 50)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56c5d7f6ea031820f8d8d41803b24f67",
     "grade": true,
     "grade_id": "cell-10bc0e2c6b493c38",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eafe6a9235752e6cabaf4b445cb0297",
     "grade": false,
     "grade_id": "cell-9048254aa38b5ce0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the data stored in `answer2.1`, plot the $p$-value sequence as a **line** with the incremental sample size on the $x$-axis and $p$-value on the $y$-axis. Add a dashed horizontal red line that indicates a threshold of the significance level $\\alpha = 0.05$. The `ggplot()` object's name will be `sequential_pvalue`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5524f755a2eead8d6d0ede88685eeded",
     "grade": false,
     "grade_id": "cell-fc5c07b5db1c2072",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 9) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "# sequential_pvalue <- \n",
    "#   answer2.1 %>%\n",
    "#   ggplot(aes(x = ..., y = ...)) +\n",
    "#   geom_point(size = 3) +  \n",
    "#   geom_line() +\n",
    "#   geom_hline(\n",
    "#     yintercept = ...,\n",
    "#     colour = \"red\",\n",
    "#     linetype = \"twodash\"\n",
    "#   ) +  \n",
    "#   ggtitle(\"Evolution of p-values in Experiment 1\") +\n",
    "#   ylab(\"p-value\") +\n",
    "#   xlab(\"Sample Size\") +\n",
    "#   coord_cartesian(ylim = c(0, 1)) +\n",
    "#   scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +\n",
    "#   theme(\n",
    "#     text = element_text(size = 18),\n",
    "#     plot.title = element_text(face = \"bold\"),\n",
    "#     axis.title = element_text(face = \"bold\")) \n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "sequential_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6becd76bc198214bf16bfd6fc8dafde3",
     "grade": true,
     "grade_id": "cell-40525ca9d0396d4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e7d13ae8b5fa91fb1a5a6abc6ac13af",
     "grade": false,
     "grade_id": "cell-d4f7748de806529f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "Suppose the campaign organizers want to implement an early stopping (before reaching the maximum sample size of `n = 1000` visitors per website) to save time and resources allocated for the experiment. They have decided to stop the experiment as soon as they find a significant result. \n",
    "\n",
    "Given the results in the previous question and a significance level $\\alpha = 0.05$, the compaign organizers would stop the experiment \n",
    "\n",
    "**A.** once they finish collecting and analyzing all the data\n",
    "\n",
    "**B.** after 100 visitors have entered each website since the $p$-value is below the specified significance level\n",
    "\n",
    "**C.** after 150 visitors have entered each website since results are getting worse after that point.\n",
    "\n",
    "*Assign your answer to an object called `answer2.3`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bbfcc5760f53327c61e265666f03eaa",
     "grade": false,
     "grade_id": "cell-e1144dfce0fb0091",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.3 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a9f8417448d064cc270b5b7156b0475",
     "grade": true,
     "grade_id": "cell-78a961a44fb63cee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1de4a5a2b3ff53529246781e2e6f41fb",
     "grade": false,
     "grade_id": "cell-120d8b0bb182bdc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Since this is an **A/A testing** design, what error, if any, are the campaign organizers making by stopping the experiment, as noted in the previous question?\n",
    "\n",
    "**A.** No error.\n",
    "\n",
    "**B.** Type I Error.\n",
    "\n",
    "**C.** Type II Error.\n",
    "\n",
    "*Assign your answer to an object called `answer2.4`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df796f924d1818e89a29f5f41a209918",
     "grade": false,
     "grade_id": "cell-73ae270a2acc9896",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.4 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f29b542ab838195d57451c05d96ae2d7",
     "grade": true,
     "grade_id": "cell-b8669caaf5a8c2a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type I Error Rate\n",
    "\n",
    "In the experiment analyzed in the previous questions, you noticed that the campaign organizers made a mistake in declaring one variation more effective than the other based on data from 100 visitors in each group. However, the hypothesis test was designed with a $5\\%$ probability of falsely rejecting $H_0$ and considering the new website more effective, even when it was *identical* to the alternative variation. \n",
    "\n",
    "> If you repeat the experiment *many* times, do you expect to *always* make a mistake? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 2.5.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "If you repeat this A/A testing *many* times, at a significance level of $5\\%$, how often do you expect to find differences between the two groups?  \n",
    "\n",
    "_Assign your answer to an object called `answer2.5.1`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42ad755cb04bde87936f635d9087f909",
     "grade": false,
     "grade_id": "cell-73ae270a2acc9897",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.5.1 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.5.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "The probability of Type I Error was specified to be $\\alpha$. However, $\\alpha$ is the Type I Error probability for **one** test. In this case, the campaign monitors the data as they come and tests the hypothesis each time more data is available. Therefore, the campaign is actually conducting multiple hypotheses testing. \n",
    "\n",
    "Let us now investigate the impact of the campaign's online p-value monitoring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e6fc0173b09170dafecc662c81cb9f5",
     "grade": false,
     "grade_id": "cell-74eb8ff6f774a3d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "In this question\n",
    "\n",
    "- perform the **A/A testing** experiment 100 times \n",
    "\n",
    "- count how many times you would wrongly reject $H_0$ with the previous strategy, and\n",
    "\n",
    "- compare it with the expected number of rejections given the significance level $\\alpha = 0.05$\n",
    "\n",
    "We wrote a code to perform the first step in the cell below. \n",
    "\n",
    "Now, you need to work on the rest!\n",
    "\n",
    "Your answer will be a tibble with two columns: `n_rejections` and `expected_n_rejections`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ba985f160d883148e120b533cd3a4c4",
     "grade": false,
     "grade_id": "cell-16df4d1d8d3d08e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "\n",
    "### Run this before continuing\n",
    "multiple_times_sequential_tests <- \n",
    "    tibble(experiment = 1:100) %>% \n",
    "    mutate(seq_test = map(.x = experiment, \n",
    "                          .f = function(x) incremental_t_test(n = 1000, d_0 = 0, sample_increase_step = 50, \n",
    "                              mean_current = 200, sd_current = 50, sd_new = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d3e68c78dc23397120214064658730b",
     "grade": false,
     "grade_id": "cell-42e304128c6172ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#answer2.5 <- multiple_times_sequential_tests %>% \n",
    "#    mutate(reject = map_dbl(.x = seq_test, .f = function(x) sum(x$p_value< ...) > 0)) %>% \n",
    "#    summarise(n_rejections = ...(reject),\n",
    "#              expected_n_rejections = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebf7f4997cace4677e933045edeaaae5",
     "grade": true,
     "grade_id": "cell-d1cd640149ad9173",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.5.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e51dd8fd81b3eabefbaf976f518e17d",
     "grade": false,
     "grade_id": "cell-975e8ae738046922",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "Select the right option to complete the sentence below:\n",
    "\n",
    "> *With the strategy used by the company, the probability of Type I error is approximately ... the specified one.* \n",
    "\n",
    "**A.** equal to\n",
    "\n",
    "**B.** 3 times lower than\n",
    "\n",
    "**C.** 5 times lower than\n",
    "\n",
    "**D.** 3 times higher than\n",
    "\n",
    "**E.** 5 times higher than\n",
    "\n",
    "*Assign your answer to an object called `answer2.6`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, `\"D\"`,  or `\"E\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "025298edb5a1f2f8103bbbc58d693153",
     "grade": false,
     "grade_id": "cell-79c91d3bee9b8207",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#answer2.6 <- \"\"\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b3c59900da65fb62b96c94255e0310f",
     "grade": true,
     "grade_id": "cell-cbd492b554a7a745",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01265655da60222ab5f49132b799aecb",
     "grade": false,
     "grade_id": "cell-8571d0cc926c0cf8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Note**: not only the type I error rate is affected by this problem, but also the estimates themselves! If we analyze samples until the means of both groups are significantly far apart, we would also overestimate the effect size (difference between means)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "220ac75bac19a6301c358b37908f888c",
     "grade": false,
     "grade_id": "cell-79540772deb2318e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<font color=blue> In *classical hypothesis testing*, monitoring results in a dashboard and *stopping experiments earlier* than planned will increase the probability of *incorrectly* rejecting the null hypothesis (i.e., when there is no real effect). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and conclusions:\n",
    "\n",
    "- One may be (understandably) tempted to peek at the results of A/B tests as data are being collected.\n",
    "\n",
    "- Stopping an experiment and rejecting $H_0$ as soon as the $p$-value is below the specified significance level can drastically inflate the type I error rate\n",
    "\n",
    "- Controlling the risk of wrongly rejecting the null hypothesis is not an easy task in A/B testing if peeking and early stops are allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "995bd3e75f7297ddf3bb6008568bfdf4",
     "grade": false,
     "grade_id": "cell-ed7ca88cfe3e3e04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09b59ab555df48bd2178572517b61916",
     "grade": false,
     "grade_id": "cell-d650bbcceaf44efc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3. Sequential testing \n",
    "\n",
    "**Sequential tests** are decision rules that allow users to test data sequentially as data come in. \n",
    "\n",
    "- Users *are* monitoring results as they collect and analyze data and are making decisions accordingly.\n",
    "\n",
    "- Users need to adaptively determine the sample size of the experiments since there are large opportunity costs associated with longer experiments. \n",
    "\n",
    "- When done correctly, stopping an experiment earlier (or re-designing it) can be beneficial in many contexts. \n",
    "\n",
    "In this second part we will examine how to address the problem of *multiple testing* when sequential tests are performed in an A/B testing experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4368ef769b19f124fd29e1f2b394a4f9",
     "grade": false,
     "grade_id": "cell-bf767b35df5480d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### 3.1 Bonferroni's method\n",
    "\n",
    "The Bonferroni's method has been proposed to control the overall Type I error rate when multiple tests are performed. It can be thought as: \n",
    "\n",
    "- an adjustment of the $p$-values, multiplying them by the number of comparisons, and keeping the significance level at a desired threshold, or \n",
    "\n",
    "- an adjustment of the significance threshold $\\alpha$, dividing it by the number of comparisons, or\n",
    "\n",
    "- an adjustment of the critical value, computed with a sampling distribution, corresponding to the adjusted significance threshold\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<u>In this section, you are going to investigate if a Bonferroni correction controls the type I error rate in A/B testing using data from the **A/A testing** of the political campaign generated in previous questions.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d139178df1215eaf9eeb9976dcddac2c",
     "grade": false,
     "grade_id": "cell-a9faf86e9df5475b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Since the campaign organizers have decided to monitor the data every 50 visitors per website, up to 1000, they will perform 20 sequential tests. \n",
    "\n",
    "Suppose that after each interim analysis, they will use a Bonferroni correction to control the type I error rate at $5\\%$. Thus, using a classical two-sample $t$ test, they we will **reject $H_0$** if the raw $p$-value is: \n",
    "\n",
    "**A.** smaller than 0.05\n",
    "\n",
    "**B.** smaller than 0.0025 (adjusted threshold)\n",
    "\n",
    "**C.** greater than a 0.0025 (adjusted threshold)\n",
    "\n",
    "**D.** greater than 0.05 when multiplied by 4\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.0`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "861c671cdc2140c595e3c326295ca9bb",
     "grade": false,
     "grade_id": "cell-3cb122e7e6d294f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer3.1.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa99edfbd813b80f79880daa4cebc194",
     "grade": true,
     "grade_id": "cell-bd42f162ef58b0c1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4228ce53a1e33747135fea7536849b5",
     "grade": false,
     "grade_id": "cell-e7d7b809d09fe3b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Continuing with the problem stated in **Question 3.1.0**, the campaign organizers can also **reject $H_0$** if the observed $t$-statistic is:\n",
    "\n",
    "**A.** greater than `qt(1 - 0.05,1998) = 1.65` \n",
    "\n",
    "**B.** greater than `qt(1 - 0.025,1998) = 1.96`\n",
    "\n",
    "**C.** greater than `qt(1 - 0.0025,1998) = 2.81` \n",
    "\n",
    "**D.** greater than 0.05\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.1`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "426e5657cb434697ede185dfb760a568",
     "grade": false,
     "grade_id": "cell-6f51027c4750089d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer3.1.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66eeb71b5ca6778f87f001281c6cdd04",
     "grade": true,
     "grade_id": "cell-88f11c2bbe9b3242",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8508662ce758acc39b140d670fb7291",
     "grade": false,
     "grade_id": "cell-08411ec27d5e8325",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "In *Question 2.1*, you performed 20 interim analyses of simulated data for an A/A design. Modify the code of *Question 2.5.2* to implement a Bonferroni correction as specified in *Question 3.1.0* in 100 experiments.\n",
    "\n",
    "Then, compare the estimated type I error rate when a Bonferroni correction is used with the expected type I error rate value.\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.2`. Your answer should be a tibble with two columns: `n_rejections_Bonf` and `expected_n_rejections`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d5080d61539d1f78ef41c4b9724456",
     "grade": false,
     "grade_id": "cell-c77e00f407e9b61d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#answer3.1.2 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer3.1.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caf2a81dc6e505d7ff1b3b954dec6571",
     "grade": true,
     "grade_id": "cell-64cca985a6e4b549",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3eea4c6b480a16637ee928b4081737f",
     "grade": false,
     "grade_id": "cell-bf09c89e531d91af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "Using a Bonferroni correction, the data can be sequentially analyzed and the experiment can be stopped earlier while controlling the <u>type I error rate</u>. For the simulated experiments in the example above, the type I error rate was approximately 2%, which is now below the planned 5% value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bonferroni's correction in sequential analysis is very conservative and can affect the power of the test (i.e., we are more vulnerable to the <u>type II error</u>)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1cfa35e07b853766367e40092c4b039",
     "grade": false,
     "grade_id": "cell-76077581b4638618",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Pocock boundaries\n",
    "\n",
    "As we recalled in **Question 3.1.1**, the Bonferroni correction can be implemented by adjusting the critical value to `qt(1 - 0.0025, 1998) = 2.81`. In this section we will examine the **Pocock method** to compute alternative critical values to evaluate interim analyses in sequential A/B testing.\n",
    "\n",
    "Similarly to Bonferroni's method, the **Pocock method** computes a *common* critical value for all interim analyses. However, the Pocock's boundary is not an adjustment of the quantile of a $t$-distribution.\n",
    "\n",
    "We can easily get the critical values for this design using `gsDesign::gsDesign()`.\n",
    "\n",
    "**Note 1**: `gsDesign()` outputs a full sequential design, not just the critical values to control a desired type I error rate!! You can read more about this package [here](https://keaven.github.io/gsDesign/reference/gsDesign.html)\n",
    "\n",
    "**Note 2**: a caveat about this package is that two-sample tests are based on $z$-statistics, i.e., a case for which we assume that samples are drawn from Normal distributions with known SD. While this is usually an unrealistic assumption and in practice we use a $t$-test to compare means of two populations, results are nearly equivalent to a $z$-test. More can be read [here](https://keaven.github.io/gsDesign/articles/nNormal.html)  \n",
    "\n",
    "In the following exercises we will examine if the critical values of the Pocock design can be used to control the type I error rate. \n",
    "\n",
    "Let's start computing a Pocock design. Save the output in the object `design_pocock`. Extract the Pocock's critical values for each interim analyses and save them in an object called `crit_pocock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50d062241681e8a3479cb498fb7cacc8",
     "grade": false,
     "grade_id": "cell-b20f739b98c5f734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to get a Pocock design!\n",
    "\n",
    "design_pocock <- gsDesign(k = 20, #number of interim analysis planned\n",
    "                          test.type = 1, # for one-sided tests\n",
    "                          delta = 0, # default effect size\n",
    "                          alpha = 0.05, #type I error rate\n",
    "                          beta = 0.2, # type II error rate\n",
    "                          sfu = 'Pocock')\n",
    "                          \n",
    "crit_pocock <- design_pocock$upper$bound\n",
    "crit_pocock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40d3259e0d98d0f03513aa0a6b97d407",
     "grade": false,
     "grade_id": "cell-c01bc9ca566a644a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "As we know, when performing a hypothesis test, we can either compare the $p$-value to a pre-specified significance level $\\alpha$ *or* we can compare the observered statistic to a critical value. \n",
    "\n",
    "Based on the adjusted critical values computed with Bonferroni's method (Question 3.1.1) and Pocock's method (cell above), the Pocock method is more conservative than the Bonferroni correction. **True or False?**\n",
    "\n",
    "*Assign your answer to an object called answer3.2.0. Your answer should be either \"true\" or \"false\", surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a4f19fab05b7050c4fbb9e78b98ce8f",
     "grade": false,
     "grade_id": "cell-579d0fb205efe17f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#answer3.2.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32472b01c9b026efb9beda1a2a606ee3",
     "grade": true,
     "grade_id": "cell-f13cecff81f199a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5840558aeb1e552c8376266d564710d",
     "grade": false,
     "grade_id": "cell-25450c2ce8317643",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the data stored in `answer2.1`, plot the sequence of observed statistics for each interim analysis as a **line** with the incremental sample size on the $x$-axis and the value of the observed statistic on the $y$-axis. \n",
    "\n",
    "Add 3 dashed horizontal lines that indicate the following 3 boundaries (critical values): \n",
    "\n",
    "- a red line for the Pocock's critical values\n",
    "\n",
    "- a blue line for the Bonferroni's critical values\n",
    "\n",
    "- a black line for the unadjusted critical values\n",
    "\n",
    "The `ggplot()` object's name will be `sequential_stat`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f16d5c24fa74394e83ae63e03cb941",
     "grade": false,
     "grade_id": "cell-5ef9722f4fe9480d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 9) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "#crit_unadj <- qt(1 - ..., ...)\n",
    "#crit_bonferroni <- ...(1 - ..., ...)\n",
    "\n",
    "#sequential_stat <- \n",
    "#  answer2.1 %>%\n",
    "#  ggplot() +\n",
    "#  geom_line(aes(x = inc_sample_size, y = statistic)) +\n",
    "#  geom_point(aes(x = ..., y = ...)) +\n",
    "#  geom_hline(yintercept = ..., colour = \"red\", linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = ...), colour = \"red\") +\n",
    "#  geom_text(x=850, y=crit_pocock + 0.15, size=6, label=\"Pocock\",colour = \"red\") +\n",
    "#  geom_hline(yintercept = ..., colour = \"blue\", linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = rep(crit_bonferroni, 20)), colour = \"blue\") +\n",
    "#  geom_text(x=850, y=crit_bonferroni + 0.15, size=6, label=\"Bonferroni\",colour = \"blue\") +\n",
    "#  geom_hline(yintercept = ..., linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = rep(..., 20))) +\n",
    "#  geom_text(x=850, y=crit_unadj + 0.15, size=6, label=\"Unadjusted\") +\n",
    "#  theme(\n",
    "#    text = element_text(size = 18),\n",
    "#    plot.title = element_text(face = \"bold\"),\n",
    "#    axis.title = element_text(face = \"bold\")\n",
    "#  ) +\n",
    "#  ggtitle(\"Critical values in Sequential Designs\") +\n",
    "#  ylab(\"Statistic\") +\n",
    "#  xlab(\"Sample Size\") +\n",
    "#  coord_cartesian(ylim = c(-1, 3)) +\n",
    "#  scale_y_continuous(breaks = seq(-1, 3, by = 0.5))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "sequential_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a25e01b46f6398ca54f44f025eadbf34",
     "grade": true,
     "grade_id": "cell-01e7452acb878966",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0414b0c1153e99f647fd8fc7756a8eb4",
     "grade": false,
     "grade_id": "cell-b2ca8eabb168eb3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "The compaign organizers have decided to monitor the data every 50 visitors per website and stop the experiment earlier if there's evidence of a difference between the group means. According to the data plotted **Question 3.2.1**, which of the following statement is correct?? \n",
    "\n",
    "**A.** The compaign organizers would never stop the experiment, regardless of the boundary used\n",
    "\n",
    "**B.** The compaign organizers would erroneously stop the experiment after the analysis of the second test, regardless of the boundary used\n",
    "\n",
    "**C.** The compaign organizers would erroneously stop the experiment after the analysis of the second test, only if they correct the critical values using a Bonferroni's method to control the type I error rate\n",
    "\n",
    "**D.** The compaign organizers would erroneously stop the experiment after the analysis of the second test only if they use undadjusted $t$ critical values \n",
    "\n",
    "*Assign your answer to an object called `answer3.2.2`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af1706741cd480bef6fd553c930fd93a",
     "grade": false,
     "grade_id": "cell-409ecf169b052d92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.2.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d39979033bbffd1a6306537b5012c81c",
     "grade": true,
     "grade_id": "cell-2f1245af7c571bba",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "719d9015928973235ff89e3b644fc5cd",
     "grade": false,
     "grade_id": "cell-05dd6e2301bfa24c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "In *Question 2.1* you performed 20 interim analyses of simulated data for an A/A design. Modify the code of *Question 2.5* to implement a sequential analyses using Pocock's boundary to control the type I error in 100 experiments.\n",
    "\n",
    "Then compare the estimated type I error rate when the Pocock's method is used with the expected type I error rate value.\n",
    "\n",
    "*Assign your answer to an object called `answer3.2.3`. Your answer should be a tibble with two columns: `n_rejections_Pocock` and `expected_n_rejections`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "456f00e51d87a3f12ee8dcf0d8d4e12f",
     "grade": false,
     "grade_id": "cell-549d0aab861a20f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#answer3.2.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer3.2.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bf06d9e201420bf84ce7063ea8623db",
     "grade": true,
     "grade_id": "cell-ce2f87ff4dbcd7bc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02e4dc6654b655fbaf139f258dfc63bf",
     "grade": false,
     "grade_id": "cell-c15252b8e2a0e330",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### <font color=blue> Using the Pocock's method, the data can be sequentially analyzed and the experiment can be stopped earlier while controlling the type I error rate. </font>\n",
    "- For the simulated experiments in the example above, the type I error rate was 7%, which close to the planned 5% value\n",
    "\n",
    "- As expected, this method is less conservative than the Bonferroni's correction\n",
    "\n",
    "In Tutorial 2, you will implement another sequential test method available in `gsDesign` package, called the **O‚ÄôBrien-Fleming method**, which has conservative critical values for earlier interim analysis and less conservative values (closer to the unadjusted critical values) as more data are collected. In other words, bounds are not uniform. \n",
    "\n",
    "There are many other methods to implement principled peeking strategies in A/B testing. \n",
    "- A very popular and flexible method, implemented by [Optimizely](https://www.optimizely.com), computes a mixture sequential probability ratio test (mSPRT) tests and *always valid* $p$-values. The metholology and implementation are beyond the scope of this course but here's a nice [video](https://www.youtube.com/watch?v=AJX4W3MwKzU) that explains its key points without too many technical details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da490253d46ac9907507c3d17b872383",
     "grade": false,
     "grade_id": "cell-a3ee7bcb3608e036",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Summary and key concepts learned\n",
    "\n",
    "1. A/B testing refers to an experiment in which users are randomly assigned to one of two variations of a product or service: control (A) and variation (B) to see if variation B should be used for improvement.\n",
    "\n",
    "\n",
    "2. The statistic used to test a hypothesis, the sample size calculation, the type I error rate specification, and the desired power are all important and interconnected pieces of the experimental design! \n",
    "\n",
    "\n",
    "3. In classical hypothesis testing theory, the sample size must be fixed in advance when the experiment is designed!!\n",
    "\n",
    "\n",
    "4. Modern platforms allow users to continuously monitor their tests' p-values and confidence intervals as data are collected (peeking) to dynamically re-adjust their experiments. \n",
    "\n",
    "\n",
    "5. In particular, users would like to stop their experiments earlier depending on the results of interim analyses\n",
    "\n",
    "\n",
    "6. Naively stopping experiments earlier than planned will increase the probability of *incorrectly* rejecting the null hypothesis (i.e., when there is no real effect). Stops must be part of the experimental design and appropriate testing methods must be used!\n",
    "\n",
    "\n",
    "7. Sequential testing triggers a multiple comparison problem. If you make many comparisons but don't correct them, error rates are inflated!! A particular characteristic of this setting is that tests are nested and not independent.\n",
    "\n",
    "\n",
    "8. A possible way to control the type I error rated is to use a Bonferroni adjustment of the $p$-values (or equivalently, the significance level or critical values). As with other multiple comparison problems, Bonferroni's correction in sequential analysis is very conservative and can affect the power of the test!!\n",
    "\n",
    "\n",
    "9. The Pocock's method offers a less conservative way of controlling the type I error rate in sequential testing with early stops.\n",
    "\n",
    "\n",
    "10. *Principled* peeking is ok and even beneficial in A/B testing.\n",
    "\n",
    "> The experimental design is a very important piece of any statistical analysis! "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
