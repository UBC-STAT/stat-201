{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56cd85e38fd4d800970e38fcf8b79d0a",
     "grade": false,
     "grade_id": "cell-c386201f5323a017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 6: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e9666b868267e66cb284b7acd67321c",
     "grade": false,
     "grade_id": "cell-63551cb2c79b3c82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Lecture and Tutorial Learning Goals\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "1. Give an example of a question you could answer with a hypothesis test.\n",
    "2. Differentiate composite vs. simple hypotheses.\n",
    "3. Given an inferential question, formulate null and alternative hypotheses to be used in a hypothesis test.\n",
    "4. Identify the steps and components of a basic hypothesis test (\"there is only one hypothesis test\").\n",
    "5. Write computer scripts to perform hypothesis testing via simulation, randomization and bootstrapping approaches, as well as interpret the output.\n",
    "6. Describe the relationship between confidence intervals and hypothesis testing.\n",
    "7. Discuss the potential limitations of this simulation approach to hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ea741d00f82a7c8c4f2489b97318e54",
     "grade": false,
     "grade_id": "cell-e4ddf503dcc46d63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(cowplot)\n",
    "library(digest)\n",
    "library(gridExtra)\n",
    "library(infer)\n",
    "library(repr)\n",
    "library(tidyverse)\n",
    "library(datateachr)\n",
    "source(\"tests_worksheet_06.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a95d2f88b97fe2b4e9015b6fbd10654d",
     "grade": false,
     "grade_id": "cell-6d14c502fafa7a1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Short Recap & Warm-Up Question\n",
    "\n",
    "The hypothesis testing problem is very similar to the confidence intervals problem you learned in Week 4.  There is just a shift in focus. For confidence intervals, we want to find plausible values for the parameter given a sample. In hypothesis testing, we want to find  \"plausible\" values for a statistic given a fixed value for the parameter. For example,  given a sample average $\\bar{x}=2$, confidence intervals aim to find plausible values for the populational mean $\\mu$. On the other hand, hypothesis tests assume a population parameter, say $\\mu=2$, and aims to check if the obtained $\\bar{x}$ is \"compatible\" with that value.\n",
    "\n",
    "Before we start, let us refresh our memory on confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71c16e8c50907230b4005c6256ac7f25",
     "grade": false,
     "grade_id": "cell-14b123c1602669dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "When calculating a confidence interval, we are looking to find plausible values for a:\n",
    "\n",
    "A. statistic;\n",
    "\n",
    "B. parameter;\n",
    "\n",
    "C. observations in the sample;\n",
    "\n",
    "D. observations in the population;\n",
    "\n",
    "_Assign your answer to an object called `answer1.1`. Your response should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a119b5bb14ac40b29c509f956372643e",
     "grade": false,
     "grade_id": "cell-3bb33029a7df43f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.1 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f1f4d61fa3e9b34653215451bf6822e",
     "grade": true,
     "grade_id": "cell-43a9de8cf24eae44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc64595af704cd06a2cdbf2a6f11b2d9",
     "grade": false,
     "grade_id": "cell-710e857eb0dc8ddc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Consider the population of all UBC students in a given year. We want the proportion of students that have at least one car. \n",
    "\n",
    "Complete the sentences below using one of the following two options:\n",
    "\n",
    "- `A` constant\n",
    "- `B` random\n",
    "\n",
    "--------------------\n",
    "\n",
    "Before we take a sample:\n",
    "\n",
    "1. The elements of the sample are ...\n",
    "2. The sample proportion is ...\n",
    "3. The sample standard error is ...\n",
    "4. The boundaries of a confidence interval are ...\n",
    "5. The parameter $p$ is ...\n",
    "\n",
    "After we take the sample:\n",
    "\n",
    "6. The elements of the sample are ...\n",
    "7. The sample proportion is ...\n",
    "8. The sample standard error is ...\n",
    "9. The boundaries of a confidence interval are ...\n",
    "10. The parameter $p$ is ...\n",
    "11. The elements of bootstrap samples are ...\n",
    "\n",
    "\n",
    "\n",
    "Your answer should be a string containing the letters associated with the terms in the same order as the sentences they complete. For example, one potential solution is \"AAABBAAABB\".\n",
    "\n",
    "_Assign your answer to an object called `answer1.2`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d41d3050c35a34f204b831f42a1e01d",
     "grade": false,
     "grade_id": "cell-463a78463ef1620a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "284502e0e3eef5a3c75468ce95d96b20",
     "grade": true,
     "grade_id": "cell-5a41cab3328cd70e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "120f5ddec97ad1ee867dab5674c9e7ee",
     "grade": false,
     "grade_id": "cell-8d19530a56cce591",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Introduction to Hypothesis Testing\n",
    "\n",
    "To introduce the idea of hypothesis testing, let us consider the Hepatitis C Virus (HCV) dataset. HCV is a virus that damages the liver. The HCV dataset contains several measurements obtained from blood tests at different stages of the disease, which are, in increasing order of severity: (1) No-Fibrosis; (2) Fibrosis; and (3) Cirrhosis. Let us take a look at the dataset first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f7e15eabf398c8a4d093fcbf45aea87",
     "grade": false,
     "grade_id": "cell-0a7267736a03a363",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hcv_dataset <-\n",
    "    read_csv(\"data/hcv-data-set.csv\") %>% \n",
    "    mutate(category = fct_recode(category, \"No-Fibrosis\" = \"Hepatitis\")) %>% \n",
    "    filter(category != \"Blood Donor\") %>% \n",
    "    mutate(category = fct_drop(category))\n",
    "\n",
    "head(hcv_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea9548745c618713a01a7a0753042839",
     "grade": false,
     "grade_id": "cell-f0f472705a72b9af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Albumin is a protein produced by the liver. Since Hepatitis C causes liver damage, one might suspect that people with hepatitis C would have lower albumin levels than healthy people. Although this is quite reasonable, is there enough evidence to support this claim? The difference in albumin levels might be so big (or so small) that we could easily answer this question with a simple plot. In other cases, however, the answer is not entirely clear. \n",
    "\n",
    "The medical community has established that the average level of albumin in people with a healthy liver is `44g/L`.\n",
    "In the next exercise, you will start investigating the level of albumin in patients carrying HCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f289c6017fcc03370fe9d88de792267",
     "grade": false,
     "grade_id": "cell-981e17ae7a6a3d1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Plot the boxplots of the `albumin` level for each stage of the disease by filling in the scaffolding below. Let us also add a line to represent the level of albumin in people with a healthy liver.\n",
    "\n",
    "_Assign your plot to an object called `boxplots`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "064ecf7b21c727696768dbab5ea9a9d8",
     "grade": false,
     "grade_id": "cell-4cdcaa7f5d2844a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#boxplots <- \n",
    "#    ... %>%  \n",
    "#    ggplot(aes(x = ..., y = albumin)) + \n",
    "#    geom_...() + \n",
    "#    ylab(\"albumin g/L\") +\n",
    "#    ...(...) +\n",
    "#    theme(text = element_text(size=25)) +\n",
    "#    geom_hline(yintercept=..., color=\"blue\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8868cd14f048ea08d7ea5e8fa200a6a0",
     "grade": true,
     "grade_id": "cell-142cda7b731649b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db5e7189c107944c98763f5ba9694e3f",
     "grade": false,
     "grade_id": "cell-40cf0af5f074419f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Compare the boxplots of albumin levels in each group against the mean albumin level of people with healthy livers. Then, for each category, please select the statement you think is most suitable. \n",
    "\n",
    "Statements: \n",
    "\n",
    "a. The boxplot shows a sample distribution that is not compatible with a mean level of albumin of 44g/L. In other words, it would be very surprising (or unlucky!) to obtain such a sample distribution from a population with a mean level of albumin of 44g/L.\n",
    "\n",
    "b. The boxplot shows a sample distribution that is compatible with a mean level of albumin of 44g/L. \n",
    "\n",
    "c. The boxplot shows some indications that the sample does not come from a population with a mean albumin level of 44g/L. However, it is hard to tell if the distinction is due to the sampling variability or a real difference in the mean albumin level.\n",
    "\n",
    "_Assign the letter of the statement `\"a\"`, `\"b\"`, or `\"c\"`, for each of the groups in object `answer2.2`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2c625eff063dccb05c062e08072dbf5",
     "grade": false,
     "grade_id": "cell-dd814fa3f33bc284",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2.2 <- NULL\n",
    "#answer2.2['No-Fibrosis'] <- \n",
    "#answer2.2['Fibrosis'] <- \n",
    "#answer2.2['Cirrhosis'] <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38f3d8323869d7c006de1035ecde441c",
     "grade": true,
     "grade_id": "cell-ed48f83d6e0a09ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "093842c13645e9c039b2e3d6916e4a96",
     "grade": false,
     "grade_id": "cell-a30f3c627bfe96a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that we are not trying to find the plausible values for the true mean of the albumin level for each category based on our sample (which would be a confidence interval). Instead, we are trying to see if the sample we have is compatible with a hypothetical scenario of interest: the categories have the same mean level of albumin as people with a healthy liver. In other words, would it be plausible to obtain the sample we got if the hypothetical scenario of interest was real? \n",
    "\n",
    "Hypothesis testing is like a counter-proof. We are not trying to prove that a hypothetical scenario is real. We are checking if there is enough evidence in our sample to contradict the hypothesis (i.e., our sample is \"too incompatible\" with such a hypothetical scenario).\n",
    "\n",
    "But what is a hypothesis precisely? A hypothesis is a statement about the population. Some examples of hypotheses:\n",
    "\n",
    "1. The population is normally distributed.\n",
    "2. The population mean, $\\mu$, is equal to a specified value $\\mu_0$.\n",
    "3. The population proportion, $p$, is higher than a specified value of $p_0$. \n",
    "\n",
    "Although a hypothesis can be more general (like Example 1 above), hypotheses frequently refer to a population parameter such as mean, proportion, or variance. A hypothesis testing consists of two competing hypotheses: (1) $H_0$, the _null hypothesis_; and (2) $H_A$ (or $H_1$), the alternative hypothesis. The null hypothesis is generally the status quo, i.e., the hypothesis that no change has happened. It is assumed that $H_0$ and $H_A$ cover all the possible scenarios. (this means that either $H_0$ or $H_A$ is true -- but we do not know which). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7f501099596a8e97a1b532a575d83ab",
     "grade": false,
     "grade_id": "cell-adaf773afe499f58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "In HCV dataset, we are investigating if the liver damage caused by the Hepatitis C Virus will reduce the albumin level compared to people with a healthy liver. What is the _null hypothesis_ we are testing? Where $\\mu$ = true mean albumin level of people with Hepatitis C. \n",
    "\n",
    "A. $H_0: \\mu<44g/L$\n",
    "\n",
    "B. $H_0: \\mu=44g/L$\n",
    "\n",
    "C. $H_0: \\mu>44g/L$\n",
    "\n",
    "D. $H_0: \\mu\\neq44g/L$\n",
    "\n",
    "\n",
    "_Assign your answer to an object called `answer2.3`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05a2f4c5b1205efdb43a6fdc767e6532",
     "grade": false,
     "grade_id": "cell-50c85bb29980ef39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.3 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c52f3450cafe144623e66445901fe043",
     "grade": true,
     "grade_id": "cell-720a6790dabd7f53",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3fea7105f60005ea49470870c740ceb",
     "grade": false,
     "grade_id": "cell-f53bf5feaaa303da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "In HCV dataset, we are investigating if the liver damage caused by the Hepatitis C Virus will reduce the albumin level compared to people with a healthy liver. What is the _alternative hypothesis_? Where $\\mu$ = true mean albumin level of people with Hepatitis C. \n",
    "\n",
    "A. $H_A: \\mu<44g/L$\n",
    "\n",
    "B. $H_A: \\mu=44g/L$\n",
    "\n",
    "C. $H_A: \\mu>44g/L$\n",
    "\n",
    "D. $H_A: \\mu\\neq44g/L$\n",
    "\n",
    "\n",
    "_Assign your answer to an object called `answer2.4`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73e209498abc6e1e329fdef80f30674d",
     "grade": false,
     "grade_id": "cell-36a6bff87314be9c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.4 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bc95c6816fd5a583425fde7ab58caf8",
     "grade": true,
     "grade_id": "cell-88ba1a92407fbf91",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5839708c00c29bdd76a72583d203c08f",
     "grade": false,
     "grade_id": "cell-4eb9be4b25659fa5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have your _null hypothesis_ and _alternative hypothesis_ defined, it is time to conduct the hypothesis test, i.e., to check if there is enough evidence in your data to say that the _null hypothesis_ is false. But first, we need to understand what is meant by \"enough evidence\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c4608b9fc111a27f9d9de10d3b5dac6",
     "grade": false,
     "grade_id": "cell-b107f2eb2a6a1d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5**\n",
    "<br>{points: 3}\n",
    "\n",
    "For now, assume that the `hcv_dataset` contains the entire population of patients with `Fibrosis`. Your job is to do three things: \n",
    "\n",
    "A. Fill in the code below to get the mean albumin level of patients with `Fibrosis`. \n",
    "_Assign the result to an object called `answer2.5_A`_.\n",
    "\n",
    "B. Is the albumin level of patients with `Fibrosis` the same, lower, or higher than the albumin level of patients with healthy liver? _Assign the string \"lower\", \"same\", or \"higher\", to an object called `answer2.5_B`_.\n",
    "\n",
    "C. True or false: we can conclude with absolute certainty, just based on the mean value obtained in `Item A`, that the mean albumin level of patients with `Fibrosis` is lower than that of patients with a healthy liver. _Assign \"TRUE\" or \"FALSE\" to an object called `answer2.5_C`_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3ea2913794212dea1851013d4ee7043",
     "grade": false,
     "grade_id": "cell-400fb89f00feab05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.5_A <- \n",
    "#    hcv_dataset %>% \n",
    "#    filter(category == ...) %>% \n",
    "#    summarise(mean_albumin = ...)\n",
    "\n",
    "#answer2.5_B <- ...\n",
    "#answer2.5_C <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.5_A\n",
    "answer2.5_B \n",
    "answer2.5_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaa7731a8f97f8f8a493ce789f949874",
     "grade": true,
     "grade_id": "cell-ca750fa0213a3a9c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.5_A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35014870b86eb04016d4aa2de8302d5c",
     "grade": true,
     "grade_id": "cell-b251443d674f48d8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.5_B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5ae293b3b850f6f006848273acb8c86",
     "grade": true,
     "grade_id": "cell-598a5727cd1cd67f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.5_C()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85fa1012f3702cb0a0ab10882e16eaa6",
     "grade": false,
     "grade_id": "cell-44834540512a6784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "However, contrary to the previous question's assumption, `hcv_dataset` does not contain the entire population of patients with `Fibrosis`. We do not have access to the entire population, so we cannot calculate the parameter of interest and compare it with the hypothesized value. The decision to reject or not reject $H_0$ will be based on a sample. The first thing we need to decide is the sample statistic that we will use to test the _null hypothesis_. This statistic is known as _test statistic_. A test statistic is a point estimate/sample statistic formula used for hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a857cc2abee42366c341a42f21bad4e",
     "grade": false,
     "grade_id": "cell-4ccb5e1f2ff272fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br>{points: 3}\n",
    "\n",
    "Considering the two hypotheses defined in Questions 2.3 and 2.4, which of the statistics below is adequate to be used as the test statistic?\n",
    "\n",
    "A. the sample median $Q_2$.\n",
    "\n",
    "B. the sample mean $\\bar{x}$.\n",
    "\n",
    "C. the sample standard deviation: $s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}$\n",
    "\n",
    "D. the constant $\\mu_0 = 44$\n",
    "\n",
    "_Assign your answer to an object called `answer2.6`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75b26a2bd156d219b700f10a6c16083c",
     "grade": false,
     "grade_id": "cell-aa173f406c5f76bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea802c9f6e9da6c107478490092f61b9",
     "grade": true,
     "grade_id": "cell-99a05ff3bf3d3010",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "757aa6da76296cba0b93e8159c545008",
     "grade": false,
     "grade_id": "cell-3eabc3b367db3a2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.7**\n",
    "<br>{points: 3}\n",
    "\n",
    "A difficulty that arises is that the test statistic is dependent on the sample. Different samples provide different values for the test statistic. Therefore, we cannot just compare the test statistic's value with the hypothesized value of 44 g/L of albumin.\n",
    "\n",
    "In this exercise, you will obtain the bootstrapped sampling distribution of your test statistic using 10,000 replications. \n",
    "\n",
    "_Assign your answer to an object called `samp_dist_mean_albumin`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe6542c9c8faadc6d4ee7e48d7321d5",
     "grade": false,
     "grade_id": "cell-2b596aa28283a4b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(7) # Do not change this!\n",
    "\n",
    "fibrosis <-                         \n",
    "    hcv_dataset %>%                 \n",
    "    filter(category == \"Fibrosis\") \n",
    "\n",
    "#samp_dist_mean_albumin <- \n",
    "#     fibrosis %>% \n",
    "#     specify(response = ...) %>% \n",
    "#     generate(type = ..., reps = ...) %>% \n",
    "#     calculate(stat = ...)\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(samp_dist_mean_albumin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4419387a82f692fc070c387b685714d",
     "grade": true,
     "grade_id": "cell-e517af59db67cd28",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0d7dff9415d16a507579a159c5366df",
     "grade": false,
     "grade_id": "cell-534fe94c5ad08e89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.8**\n",
    "<br>{points: 1}\n",
    "\n",
    "Fill in the code below to obtain the observed test statistic.\n",
    "\n",
    "_Assign your answer to an object named `obs_test_stat`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71295f32981777381dc949f706c72bde",
     "grade": false,
     "grade_id": "cell-0e2236a9137d0c08",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#obs_test_stat <- ...(fibrosis$albumin)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "obs_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168c7b3ca223611a0a74f250bc44fa1a",
     "grade": true,
     "grade_id": "cell-4cfc9bf55e3007fe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85f208fb2bc7a9d25026e0b6b8fa3d91",
     "grade": false,
     "grade_id": "cell-5c7d1b43c64e2140",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.9**\n",
    "<br>{points: 3}\n",
    "\n",
    "Fill in the code below to plot the bootstrap sampling distribution you obtained in Question 2.7.\n",
    "\n",
    "_Assign your answer to an object called `samp_dist_mean_albumin_plot`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edf77f759bd3d00423a437d3aa72c59e",
     "grade": false,
     "grade_id": "cell-ad2ae437dc251c1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#samp_dist_mean_albumin_plot <- \n",
    "#     ... %>% \n",
    "#     ggplot() + \n",
    "#     geom_...(aes(..), bins = 15, color=\"white\") +\n",
    "#     geom_vline(xintercept = obs_test_stat, color = \"red\", alpha=.3, lwd=2) + \n",
    "#     xlab(...) + \n",
    "#     theme(text = element_text(size=25)) + \n",
    "#     ggtitle(\"Bootstrapped sampling dist.\", subtitle = \"Mean albumin level \") +\n",
    "#     annotate(\"text\", x = 43.6, y = 2150, label = \"Observed test statistic\", color=\"red\", size=7)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "samp_dist_mean_albumin_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2d2059290c04714b48e57d791bedad1",
     "grade": true,
     "grade_id": "cell-aa367db5ce3307ea",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e104ac7f1e1d74f4b882b6ce2321ff7",
     "grade": false,
     "grade_id": "cell-9b286f02e09aef4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.10: the Null model**\n",
    "<br>{points: 3}\n",
    "\n",
    "The test statistic's sampling distribution under the _null hypothesis_ ($H_0$) is called _null model_ or _null distribution_. Up to now, you have been studying the sampling distribution of a statistic using bootstrap simulation. This time you will use bootstrap to examine how the sampling distribution of your test statistic would look like if $H_0$ were true. \n",
    "\n",
    "The _null hypothesis_ states that the population mean is 44 g/L, which implies that, under $H_0$, the mean of the test statistic's sampling distribution is 44 g/L. Your job here is to obtain the _null model_ by recentering the sampling distribution stored in `samp_dist_mean_albumin` to 44 g/L.\n",
    "\n",
    "_Assign your answer to an object named `null_model`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe82ca800065832a333ca888e04896c5",
     "grade": false,
     "grade_id": "cell-4f5a2f488ea65f69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#null_model <- \n",
    "    #samp_dist_mean_albumin %>% \n",
    "    #mutate(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(null_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042b65cfdf821efcf38b80a11756db5e",
     "grade": true,
     "grade_id": "cell-3b4192310ddeb76c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee136607aec214b13c3bce6629898045",
     "grade": false,
     "grade_id": "cell-0d4feaa2be943a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.11: the Null model**\n",
    "<br>{points: 3}\n",
    "\n",
    "Fill in the code below to plot the _null model_ you obtained in the previous question. Also, add a vertical line to the plot at the observed value of the test statistic. \n",
    "\n",
    "_Assign your answer to an object called `null_model_plot`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aaf7fc8da268d20a14ed525987a6eaa",
     "grade": false,
     "grade_id": "cell-0399578e172109d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#null_model_plot <-\n",
    "#     null_model %>% \n",
    "#     ggplot() +\n",
    "#     geom_...(..., bins = 15, color=\"white\") +\n",
    "#     geom_vline(xintercept = obs_test_stat, color = \"red\", alpha=.3, lwd=2) + \n",
    "#     xlab(\"Mean albumin level (g/L)\") + \n",
    "#     theme(text = element_text(size=25)) + \n",
    "#     ggtitle(\"Simulated null distribution\", subtitle = \"Mean albumin level\") +\n",
    "#     annotate(\"text\", x = 43.6, y = 2200, label = \"Observed test statistic\", color=\"red\", size=7)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "null_model_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9ec21cceb2e91507861821a6fddf941",
     "grade": true,
     "grade_id": "cell-facc05c4de74cf40",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ac96035bef676f9e1e57de8aed82a44",
     "grade": false,
     "grade_id": "cell-2c1cb5c383d5a16d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.12: p-value**\n",
    "<br>{points: 3}\n",
    "\n",
    "Is the observed value of the test statistic a plausible value to be obtained if $H_0$ were true? To answer this question, you will calculate the probability of getting a value more \"extreme\" than the observed test statistic under the null distribution. This probability is called _p-value_. \n",
    "\n",
    "_Assign your answer to an object called p_value_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bbd500649d7695582bcb744cc8297e2",
     "grade": false,
     "grade_id": "cell-09c7dc2a6bccdfcd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#p_value <- mean(null_model$stat < ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "458568dfac5fa9344145213611cdb1c5",
     "grade": true,
     "grade_id": "cell-155a227436cbec99",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.12()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64322ca009f49a8d3e11bc13b847d134",
     "grade": false,
     "grade_id": "cell-639f0185ddda5751",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.13: Decision**\n",
    "<br>{points: 3}\n",
    "\n",
    "Based on the _p-value_ you got in the previous question, which of the following do you think better describes the situation?\n",
    "\n",
    "A. The low value of the p-value shows that it is entirely plausible to obtain the observed test statistic if $H_0$ were true. Therefore, $H_0$ should not be rejected.\n",
    "\n",
    "B. The low value of the p-value shows that it is quite unlikely to get the observed test statistic if $H_0$ were true, which _certainly_ shows that $H_0$ is false. Therefore, $H_0$ should be rejected. \n",
    "\n",
    "C. The low value of the p-value shows that it is quite unlikely to get the observed test statistic if $H_0$ were true, which _suggests_ that $H_0$ is false. Therefore, $H_0$ should be rejected. \n",
    "\n",
    "D. The _p-value_ is quite low, and since the _p-value_ is the probability that $H_0$ is true, we should reject $H_0$. \n",
    "\n",
    "_Assign your answer to an object called `answer2.13`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba237dd158c20ff3055577fc46b331be",
     "grade": false,
     "grade_id": "cell-20732de06b1c49f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.13 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3a269856dd85d7a1391676b61022525",
     "grade": true,
     "grade_id": "cell-326c1016109197da",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.13()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5352dc984e2236cb3434e295f93bbabd",
     "grade": false,
     "grade_id": "cell-e98cd4facee6b769",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.14: Types of Error**\n",
    "<br>{points: 3}\n",
    "\n",
    "There are two possible errors we could make in hypothesis testing:\n",
    "\n",
    "1. Type I Error: happens when we wrongly reject $H_0$ (i.e., we reject $H_0$ when $H_0$ is true);\n",
    "2. Type II Error: happens when we wrongly do not reject $H_0$ (i.e., we do not reject $H_0$ when $H_0$ is False);\n",
    "![](imgs/errors_table.png)\n",
    "\n",
    "Considering the decision you made in Question 2.13, which type of error are you at risk of making? \n",
    "\n",
    "A. Type I Error\n",
    "\n",
    "B. Type II Error\n",
    "\n",
    "_Assign your answer to an object called `answer2.14`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7922cdcfe05c5018a5aef32824611f6e",
     "grade": false,
     "grade_id": "cell-dfac9b69c95ae6c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.14 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "420f99336df7ca5bd284c515f61ab21e",
     "grade": true,
     "grade_id": "cell-d7f3be238ddfef27",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.14()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "042f165bd70b22f933eb1a9a663811be",
     "grade": false,
     "grade_id": "cell-3ba3a59fbc0569b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.15: Significance level**\n",
    "<br>{points: 3}\n",
    "\n",
    "We know that a low _p-value_ is evidence against $H_0$. But how low must the _p-value_ be for us to decide to reject $H_0$? \n",
    "\n",
    "When performing hypothesis testing, we must set the so-called _significance level_. The significance level, $\\alpha$, is the probability of _Type I Error_. We will reject $H_0$ if the p-value is smaller than the significance level we chose. Typical values of $\\alpha$ are $10\\%, 5\\%$, and $1\\%$. It is important that you specify the $\\alpha$ level before conducting the hypothesis testing and obtaining the p-value. \n",
    "\n",
    "For this question, you must select all the significance level below for which we would reject $H_0$:\n",
    "\n",
    "A. $10\\%$\n",
    "\n",
    "B. $5\\%$\n",
    "\n",
    "C. $1\\%$\n",
    "\n",
    "D. $0.1\\%$\n",
    "\n",
    "E. None of the above.\n",
    "\n",
    "Your answer should be a string containing the letters associated with the items you selected in the same order as the items appear. For example, if you want to select `B` and `D`, you should use `\"BD\"`,  not `\"DB\"`. \n",
    "\n",
    "_Assign your answer to an object called `answer2.15`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23b6598313983a25156216ca528e150",
     "grade": false,
     "grade_id": "cell-f1c0bff98d2e9722",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.15 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f628099b37831f99fde95c4f846a13a3",
     "grade": true,
     "grade_id": "cell-36a4f9055f2c66d9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.15()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05efadc38af1249e959b7c37fd53e8fa",
     "grade": false,
     "grade_id": "cell-025b3df4013a6d61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.16: hypothesis testing with the `infer` package**\n",
    "<br>{points: 3}\n",
    "\n",
    "The `infer` package has a similar [workflow to conduct hypothesis tests](https://moderndive.com/9-hypothesis-testing.html#ht-infer) to the one you have been using for confidence intervals. \n",
    "\n",
    "In this question, you will conduct the same hypothesis test you just did manually, but this time you are going to use the `infer` package. Fill in the code below to generate 10,000 bootstrap samples from the null model using the `infer` workflow. Then, try comparing the first ten rows of the model you manually generated `null_model` with the first ten rows you obtained using `infer`\n",
    "\n",
    "_Assign your answer to an object called `null_model_infer`_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed0ce780ccbf94a405cd3f43cc4ebe2e",
     "grade": false,
     "grade_id": "cell-1dfa0051161db7c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(7) # Do not change this.\n",
    "\n",
    "#null_model_infer <- \n",
    "#    fibrosis %>% \n",
    "#    specify(...) %>% \n",
    "#    hypothesise(...) %>% \n",
    "#    generate(...) %>% \n",
    "#    calculate(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(null_model_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b540ce4f20353ef27cdb93aae6bf9a3",
     "grade": true,
     "grade_id": "cell-532a26a12c781427",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "220dc8d1c2fbbd2c23621103156deb60",
     "grade": false,
     "grade_id": "cell-e9fe9bed81d549c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.17: Visualizing the result of the hypothesis test `infer`**\n",
    "<br>{points: 3}\n",
    "\n",
    "\n",
    "The `infer` package also makes it easy to visualize the result of your hypothesis test with `visualize` and `shade_p_value` functions (see [Section 9.3.1 of Modern Dive](https://moderndive.com/9-hypothesis-testing.html#ht-infer)).\n",
    "\n",
    "Fill in the code below to visualize the result of your hypothesis test. \n",
    "\n",
    "_Assign the answer to an object named `null_model_vis_infer`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fd38ffa47ecc4f4c83f1a48d8f092da",
     "grade": false,
     "grade_id": "cell-602979ab19235af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#null_model_vis_infer <-\n",
    "#    null_model_infer %>% \n",
    "#    visualize(...) + \n",
    "#    shade_p_value(obs_stat = ..., direction = ...) +\n",
    "#    xlab(\"Mean albumin level (g/L)\") + \n",
    "#    theme(text = element_text(size=20))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "null_model_vis_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95a07f3b584065836a17dc3fc9aee2fd",
     "grade": true,
     "grade_id": "cell-a9ca1ae0a796bb53",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.17()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ea5710e547295287691f2f641e8ae79",
     "grade": false,
     "grade_id": "cell-6c878d761af53f37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.18: Getting the p-value with `infer`**\n",
    "<br>{points: 1}\n",
    "\n",
    "To get the p-value with the `infer` package, we use the `get_p_value` function. Obtain the p-value using the `null_model_infer`. \n",
    "\n",
    "_Assign your answer to p_value_infer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "135442a48704995df10a0a1d3606b231",
     "grade": false,
     "grade_id": "cell-d8de10198a9915ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#p_value_infer <- \n",
    "#    null_model_infer %>% \n",
    "#    get_p_value(obs_stat = ..., direction = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "p_value_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c6e32c4fa6ebb713b626a6d0d6e7230",
     "grade": true,
     "grade_id": "cell-878da68d39c876b0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "804016ce8ca9d652cfdcc4fc5a533615",
     "grade": false,
     "grade_id": "cell-ea0a9087eace5aa7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Hypothesis testing with two populations\n",
    "\n",
    "In the previous section, the hypothesis involved only one parameter from one population: the mean level of albumin in patients with `Fibrosis`. \n",
    "\n",
    "In this section, you will work with two populations, and your hypothesis will involve a parameter from each population. Although it seems more complicated, fear not, the process is pretty much the same: \n",
    "\n",
    "1. Specify the variable of interest (`specify()`);\n",
    "2. Define your hypotheses (`hypothesise()`);\n",
    "3. Simulate the observations (`generate()`);\n",
    "4. Generate values from the null model (`caculate()`);\n",
    "5. See how the observed statistic compares with the sampling distribution by checking the p-value.\n",
    "\n",
    "In the following sequence of exercises, we will try to answer the following question: \n",
    "\n",
    "> Is the diameter of the trees in Kitsilano bigger than in Kerrisdale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b931c90bb926263dcc01c49114fa5a29",
     "grade": false,
     "grade_id": "cell-0d0aedd671460715",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1: What are we comparing exactly?**\n",
    "<br>{points: 2}\n",
    "\n",
    "Different trees will have different diameters. We need a summary quantity to summarise each population: (1) all the trees in Kitsilano; and (2) all the trees in Kerrisdale. Which of the following quantities are appropriate to help answer the question (select all that apply):\n",
    "\n",
    "A. Population mean;\n",
    "\n",
    "B. Population variance;\n",
    "\n",
    "C. Population median;\n",
    "\n",
    "D. Population mode; \n",
    "\n",
    "_Assign your answer to an object called `answer3.1`. Your response should be a sequence of characters, e.g., \"ABCD\"._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8c3ad088d3edfac03247f11e313cbf7",
     "grade": false,
     "grade_id": "cell-76fa433852f954db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.1 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbb9d68098890a95176c2dfb34631894",
     "grade": true,
     "grade_id": "cell-ba8c3c631688bd08",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ae106334094d0bc9881f2ceae1c72d0",
     "grade": false,
     "grade_id": "cell-326ab3e29761c7f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2: Setting the hypothesis**\n",
    "<br>{points: 2}\n",
    "\n",
    "If we were to use the median, say $m_1$ is the median diameter of the trees in Kitsilano and $m_2$ the median diameter of the trees in Kerrisdale, what are the appropriate hypotheses?\n",
    "\n",
    "A. $H_0: m_1-m_2 = 0$ vs $H_1: m_1-m_2 < 0$\n",
    "\n",
    "B. $H_0: m_1-m_2 = 0$ vs $H_1: m_1-m_2 > 0$\n",
    "\n",
    "C. $H_0: m_1-m_2 > 0$ vs $H_1: m_1-m_2 < 0$\n",
    "\n",
    "D. $H_0: m_1-m_2 < 0$ vs $H_1: m_1-m_2 = 0$\n",
    "\n",
    "_Assign your answer to an object called `answer3.2`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd53a47e682fe642108fdf35b09ec98f",
     "grade": false,
     "grade_id": "cell-3604ac09f4c211ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.2 <-\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43d9f5dfda8017cb0305ccda9eda79e4",
     "grade": true,
     "grade_id": "cell-512cb2e17bb87a53",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ae67b7b0d53b01abd54e75ab47cccd0",
     "grade": false,
     "grade_id": "cell-f24659bc1cf72fe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3: The truth!**\n",
    "<br>{points: 3}\n",
    "\n",
    "Let us assume that the entire population of trees in Kitsilano and Kerrisdale is stored in the `trees_pop` variable. Let's find out the truth! \n",
    "What is the median diameter of each population of trees? Fill in the code below to find out.\n",
    "\n",
    "_Assign your answer to an object called `answer3.3`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32ff2edffff6ec3c3c2909ccfea27bd8",
     "grade": false,
     "grade_id": "cell-ac532d6c217b508a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this code before continuing\n",
    "trees_pop <-\n",
    "    vancouver_trees %>% \n",
    "    filter(neighbourhood_name %in% c(\"KITSILANO\", \"KERRISDALE\")) %>% \n",
    "    select(neighbourhood_name, diameter)\n",
    "\n",
    "head(trees_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5db397a42ea31153233047aff11f04c",
     "grade": false,
     "grade_id": "cell-0e6359010285ebe4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.3 <- \n",
    "#    trees_pop %>% \n",
    "#    ...(neighbourhood_name) %>% \n",
    "#    ...(median = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98df68bf9e7cda69425016dadc07eac8",
     "grade": true,
     "grade_id": "cell-8321b4d518a311c9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9a72629055139b6c57d7aa8094a5e33",
     "grade": false,
     "grade_id": "cell-9a765025a4ac8c86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.4: Let's take a sample**\n",
    "<br>{points: 3}\n",
    "\n",
    "A sample of 31 trees from Kitsilano and 35 trees from Kerrisdale was taken and stored in the object `sample_trees`. Calculate the observed test statistic as the difference in the median diameter between KITSILANO & KERRISDALE\n",
    "\n",
    "_Assign your answer to an object called `obs_med_diam_diff`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28d9e7aeec06f4880aeb5fdd781212b0",
     "grade": false,
     "grade_id": "cell-b0191856865c1d44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(12) # Do not change this\n",
    "\n",
    "# Run this cell before continuing.\n",
    "sample_trees <- \n",
    "    trees_pop %>% \n",
    "    filter(neighbourhood_name==\"KERRISDALE\") %>% \n",
    "    sample_n(size=35) %>% \n",
    "    bind_rows(\n",
    "        trees_pop %>% \n",
    "            filter(neighbourhood_name==\"KITSILANO\") %>% \n",
    "            sample_n(size=31))\n",
    "\n",
    "head(sample_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "524ce0d9bc8126de716a278bebe9c84f",
     "grade": false,
     "grade_id": "cell-1c5277cac7748862",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# obs_med_diam_diff <- \n",
    "#     sample_trees %>% \n",
    "#     filter(neighbourhood_name %in% c(..., ...)) %>%\n",
    "#     group_by(...) %>% \n",
    "#     summarise(median = ...) %>%\n",
    "#     pivot_wider(names_from = neighbourhood_name, values_from = median) %>%\n",
    "#     transmute(diff = ...) %>%\n",
    "#     pull(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "obs_med_diam_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e01b5f699103dae864f1d55a8ee0017",
     "grade": true,
     "grade_id": "cell-eeb2724c79c477c6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a650a676546959942fccfabacbb5f66e",
     "grade": false,
     "grade_id": "cell-95e24759c31bc5eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.5: Simulating from the null distribution**\n",
    "<br>{points: 3}\n",
    "\n",
    "Fill in the code below to generate 5000 samples from the null distribution.\n",
    "\n",
    "_Assign your answer to an object called `null_model_trees`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cb6da7c48796f558bd534fd0ede7451",
     "grade": false,
     "grade_id": "cell-fe80212fccaf0f1f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(50)\n",
    "\n",
    "#null_model_trees <- \n",
    "#    sample_trees %>% \n",
    "#    specify(formula = ... ~ ...) %>% \n",
    "#    hypothesize(null = ...) %>% \n",
    "#    ...(reps = 5000, type = \"permute\") %>% \n",
    "#    ...(stat=\"diff in medians\", order = c(\"KITSILANO\", \"KERRISDALE\"))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(null_model_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "430e916eb178d575984c53bf9e903f46",
     "grade": true,
     "grade_id": "cell-784331f2e3adbe88",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56464ea9c4bec8597d7ea6cccb50ee56",
     "grade": false,
     "grade_id": "cell-812681a3cd2d2834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.6**\n",
    "<br>{points: 3}\n",
    "\n",
    "Fill in the code below to plot the result of the hypothesis test. \n",
    "\n",
    "_Assign your answer to an object called `trees_result_plot`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d615da6eca63dcca51da04063aaafd5",
     "grade": false,
     "grade_id": "cell-523e9ef063ba782d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#trees_result_plot <- \n",
    "#    null_model_trees %>%\n",
    "#    visualize() + \n",
    "#    shade_p_value(obs_stat = ..., direction = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "trees_result_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37640a8dcda48398fc6628b60649fe58",
     "grade": true,
     "grade_id": "cell-b177015e5b570b86",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b3e2ca87d729b78738d795beeae8122",
     "grade": false,
     "grade_id": "cell-c8e9e6051344a05e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.7**\n",
    "<br>{points: 3}\n",
    "\n",
    "Obtain the p-value from `null_model_trees`.\n",
    "\n",
    "_Assign your answer to an object called `answer3.7`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "914a2f7c711aac912e4af9a6c456c389",
     "grade": false,
     "grade_id": "cell-c4f1639bbbe64d41",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.7 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abb3a2223d934faed270c84726c9fb24",
     "grade": true,
     "grade_id": "cell-ede0354b1285433c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8**\n",
    "<br>{points: 3}\n",
    "\n",
    "What decision should be made at 10% significance level?\n",
    "\n",
    "A. Reject $H_0$ and commit the Type I Error;\n",
    "\n",
    "B. Reject $H_0$ and commit the Type 2 Error;\n",
    "\n",
    "C. Correctly reject $H_0$;\n",
    "\n",
    "D. Not reject $H_0$ and commit the Type 1 Error;\n",
    "\n",
    "E. Not reject $H_0$ and commit the Type 2 Error;\n",
    "\n",
    "F. Correctly not reject $H_0$;\n",
    "\n",
    "_Assign your answer to an object called `answer3.5`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fa99601e48343140a4e1bd300ec6021",
     "grade": false,
     "grade_id": "cell-cb42623aee11340d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.8 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b6dd65634557f32915ee6bcd9b55ef2",
     "grade": true,
     "grade_id": "cell-68c4131a9c491e83",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.8()"
   ]
  }
 ],
 "metadata": {
  "docker": {
   "latest_image_tag": "v0.4.0"
  },
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
