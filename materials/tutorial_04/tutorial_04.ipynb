{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ab39923e859202b3dac23e507ed2a90",
     "grade": false,
     "grade_id": "cell-0a3a16e4560c3222",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tutorial 4: Confidence Intervals via Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af30f6f6426fae8bddd94612c19f7280",
     "grade": false,
     "grade_id": "cell-697926f90dfb6d3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lecture and Tutorial Learning Goals:\n",
    "From this section, students are expected to be able to:\n",
    "\n",
    "1. Define what a confidence interval is, and why we want to generate one.\n",
    "2. Explain how the bootstrap sampling distribution can be used to create confidence intervals.\n",
    "3. Write a computer script to calculate confidence intervals for a population parameter using bootstrapping.\n",
    "4. Effectively visualize point estimates and confidence intervals.\n",
    "5. Interpret and explain results from confidence intervals.\n",
    "6. Discuss the potential limitations of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be68c508ee8bbb19091c1c26490932f",
     "grade": false,
     "grade_id": "cell-9d4ab0c1978d7fc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(cowplot)\n",
    "library(datateachr)\n",
    "library(digest)\n",
    "library(infer)\n",
    "library(repr)\n",
    "library(taxyvr)\n",
    "library(tidyverse)\n",
    "source(\"tests_tutorial_04.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d61511e7aa18bf87dd7c00f4a7313a70",
     "grade": false,
     "grade_id": "cell-8f98efcea21ec2e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Steam Games\n",
    "\n",
    "For the first part of this tutorial, we'll be working with a dataset that contains various attributes, including the name, original price, genre, and description, of over 40,000 different games available on Steam. Steam is a platform where video games (and some other types of applications) are distributed digitally. Essentially, Steam acts as a digital game store and library. Although this particular dataset was compiled in 2019, for this tutorial, we will assume we have data for the entire population for simplicity.\n",
    "\n",
    "\n",
    "<img src=\"https://steamcdn-a.akamaihd.net/store/about/social-og.jpg\" width=500>\n",
    "<div style=\"text-align: center\"><i>Image from <a href=\"https://store.steampowered.com/about/\">store.steampowered.com</i></a></div><br>\n",
    "\n",
    "This data set, like several of the others we have worked with so far, is included in the `datateachr` package under the object name `steam_games`. The original source of the data set can be found in the documentation (`?steam_games`). We are interested in calculating a **90% confidence interval** for the **median of the `original_price`** of the games in the population. Afterwards, we will interpret the confidence interval and, because we are lucky enough to have access to data for the entire finite population, we will calculate the true median and see whether it is captured by our confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "227788338cab9dbc911dc817701eae1c",
     "grade": false,
     "grade_id": "cell-ad245a9f4e1c5358",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "?steam_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f33106681c17504006b884904dfa4b86",
     "grade": false,
     "grade_id": "cell-e3af05128aa353b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0** \n",
    "<br> {points: 1}\n",
    "\n",
    "Filter out all `NA` values from the variable we are interested in (`original_price`), and select only that column.\n",
    "\n",
    "**Note:** the values of `original_price` are in $USD.\n",
    "\n",
    "_Assign your data frame to an object called `steam_pop`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "defe590fe055c73e6f911de6ecb82cea",
     "grade": false,
     "grade_id": "cell-fa279e7c87ba536d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(steam_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43c1d812896a0cb82f8f8f902c736879",
     "grade": true,
     "grade_id": "cell-2328820ae2dd9342",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd266d9ca666ec5392f50a66961f7576",
     "grade": false,
     "grade_id": "cell-6e83465e672d5f4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Take a single random sample of size 40 from `steam_pop` using `rep_sample_n` and a seed of 2078. After taking the sample, ensure that only the `original_price` column is selected. (_Hint: you will need to ungroup before selecting the column_.)\n",
    "\n",
    "_Assign your data frame to an object called `steam_sample`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f79e5880f6b045be9a389312ce82fefe",
     "grade": false,
     "grade_id": "cell-b15be21c9148990e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2078)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(steam_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bbcc2e183f04c22b6c1ec3862c7ef22",
     "grade": true,
     "grade_id": "cell-aa73f2f5d26ec1a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d507dcb0aa7e8203cce2b8427e0a5dc",
     "grade": false,
     "grade_id": "cell-f8d2705dd1f8a738",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Take 1500 bootstrap samples from `steam_sample` using `rep_sample_n` and a seed of 9844. Then, calculate the median of each sample (name this column `bootstrap_median`). Your final data frame should have a `replicate` column and a `bootstrap_median` column.\n",
    "\n",
    "_Assign your data frame to an object called `steam_bootstrapped`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bacf2387f94e5f83185685fbb66d9e33",
     "grade": false,
     "grade_id": "cell-fb44dfe96bbfc3e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(9844)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(steam_bootstrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a936f8824b87b368ec46cf274e24af7",
     "grade": true,
     "grade_id": "cell-ac7825fd6fb09e74",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7f220f713c5a889e7e388537a21feec",
     "grade": false,
     "grade_id": "cell-a81081ee88a8dcbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use the `summarize` and `quantile` functions to calculate a 90% confidence interval for the median. Use the 0.05th and 0.95th quantiles for the lower and upper bounds of the interval, respectively. Name the column containing the lower bound of the interval `ci_lower` and the upper bound `ci_upper`.\n",
    "\n",
    "_Assign your data frame to an object called `steam_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68bc9f6a4e84a69245fb4582e1b86047",
     "grade": false,
     "grade_id": "cell-32b6987424efb99e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(steam_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2337cba0041021ee6be2b882216291cc",
     "grade": true,
     "grade_id": "cell-d5e684abafd5de61",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7b1ef5c45106ddfa3c376c43ddc3bb",
     "grade": false,
     "grade_id": "cell-83b27ff0876de4d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The `infer` package workflow for bootstrapping (and calculating confidence intervals)\n",
    "\n",
    "As you may have seen in [ModernDive](https://moderndive.com/8-confidence-intervals.html#infer-workflow), there is an alternative workflow for generating bootstrap distributions and calculating confidence intervals. The benefits are outlined in [Section 8.4.2](https://moderndive.com/8-confidence-intervals.html#infer-workflow). However, to summarize, the main benefit is that it will allow us to use similar code for inference methods that we will learn about later on, so we can compare and transition from one method to another much easier. The general workflow for bootstrapping with the `infer` workflow is summarized in the chart below:\n",
    "\n",
    "<img src=\"https://d33wubrfki0l68.cloudfront.net/e7a0c87bc2cf1c53724bff5b58ff74e80224aac2/7e5fe/images/flowcharts/infer/calculate.png\n",
    "\" width=400>\n",
    "<div style=\"text-align: center\"><i>Image from <a href=\"https://moderndive.com/8-confidence-intervals.html#infer-workflow\">ModernDive</i></a></div><br>\n",
    "\n",
    "Given a sample, in the `specify` step, you \"specify\" the variable in the sample that you are interested in. With `generate`, you \"generate\" the bootstrap samples (like using `rep_sample_n`). Then, with `calculate`, you \"calculate\" the statistic you are interested in for each re-sample (like using `group_by(replicate)` and then `summarize`).\n",
    "\n",
    "Finally, you can use `get_confidence_interval` to calculate a confidence interval using our bootstrap distribution and quantiles (like using the `summarize` and `quantile` functions).\n",
    "\n",
    "Let's re-do **question 1.2** and **question 1.3** using this new workflow for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79309a4db19c5fb687d20ba011244e74",
     "grade": false,
     "grade_id": "cell-d38884f4b37c73d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2 (with the `infer` workflow!)** \n",
    "<br> {points: 1}\n",
    "\n",
    "Using the `infer` workflow, take 1500 bootstrap samples from `steam_sample` and calculate the **median** of each sample. Use the same seed as you did previously (9844) and the scaffolding provided below as a guide:\n",
    "\n",
    "```r\n",
    "steam_bootstrapped2 <- ... %>% \n",
    "    specify(response = ...) %>% \n",
    "    generate(type = \"bootstrap\", reps = ...) %>% \n",
    "    calculate(stat = \"...\")\n",
    "```\n",
    "\n",
    "_Assign your data frame to an object called `steam_bootstrapped2`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ed3133010cfb9ea0197b258fc04a5b1",
     "grade": false,
     "grade_id": "cell-1f0df6bdbb62604c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(9844) # DO NOT CHANGE\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(steam_bootstrapped2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b1e65ce3b046d0057a4ab82669b0f72",
     "grade": true,
     "grade_id": "cell-b45446b574e94ceb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2_infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de8940b2aa2ca55af5ce334a9f9db0c1",
     "grade": false,
     "grade_id": "cell-2d3f19165602c754",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3 (with the `infer` workflow)** \n",
    "<br> {points: 1}\n",
    "\n",
    "Use the `get_confidence_interval` function with the bootstrap distribution you just generated (`steam_bootstrapped2`) to calculate a 90% confidence interval for the median. Use the scaffolding provided below as a guide:\n",
    "\n",
    "```r\n",
    "steam_ci2 <- steam_bootstrapped2 %>% \n",
    "    get_confidence_interval(level = ..., type = \"percentile\")\n",
    "\n",
    "```\n",
    "\n",
    "**Note:** you can also use the function `get_ci`, which is the same as the function `get_confidence_interval`, but it is much more concise. Try replacing `get_confidence_interval` with `get_ci`, and the result will be the same!\n",
    "\n",
    "_Assign your data frame to an object called `steam_ci2`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb1acd4a13b4c79c4b8c332806278127",
     "grade": false,
     "grade_id": "cell-236e2d720af60c9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "steam_ci2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "057d0b52f21247b5489abcd90fa05b59",
     "grade": true,
     "grade_id": "cell-bcb118f1c903bc0c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3_infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73b102e923f60fed1360a9ad31944c2b",
     "grade": false,
     "grade_id": "cell-787bd139839ff9f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "<br> {points: 1}\n",
    "\n",
    "Visualize the confidence interval (`steam_ci2`) with two `geom_vline` layers on top of the bootstrap distribution (`steam_bootstrapped2`) using `geom_histogram` with bin widths of 5. Use the scaffolding provided below as a guide:\n",
    "\n",
    "```r\n",
    "steam_ci_plot <- steam_bootstrapped2 %>% \n",
    "    ggplot(aes(x = ...)) +\n",
    "    ...(binwidth = ...) +\n",
    "    ...(xintercept = steam_ci[[1]]) +\n",
    "    ...(xintercept = ...)\n",
    "```\n",
    "\n",
    "_Assign your plot to an object called `steam_ci_plot`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f72b52cd3cc106700ac06b8d1cfc2ca2",
     "grade": false,
     "grade_id": "cell-ed597d1944e8d0f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "steam_ci_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac084109fb348bfd0d2c07ea1019cf08",
     "grade": true,
     "grade_id": "cell-33d5d981468b489b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "706486984cdbda00167d37cf4335da02",
     "grade": false,
     "grade_id": "cell-ae991fa30d049a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5** \n",
    "<br> {points: 3}\n",
    "\n",
    "Consider the effectiveness of the plot above. If you think the plot is effective, list **at least** three reasons why. Otherwise, list **at least** three things that you would change about the plot to make it more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2e5749eaf38060acb4fac0382bd343a",
     "grade": true,
     "grade_id": "cell-d8bb30be9c34acae",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83657a8daeca2e0e3765e36459c0e603",
     "grade": false,
     "grade_id": "cell-671f9c9171d201f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.6** \n",
    "<br> {points: 1}\n",
    "\n",
    "Calculate the median of the population `steam_pop`.\n",
    "\n",
    "_Assign your answer to an object called `steam_median`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e9c3809092194522cbdeba00bb96e24",
     "grade": false,
     "grade_id": "cell-bf6e8d2bad6dbfa0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "steam_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "435b0750da8f883296f6f59acec10960",
     "grade": true,
     "grade_id": "cell-54bb7b760cdd994e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15435aaae46548ac208c0d43e9972944",
     "grade": false,
     "grade_id": "cell-479025f4f0b088ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.7**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The confidence interval `steam_ci` captures the parameter of interest.\n",
    "\n",
    "_Assign your answer to an object called `answer1.7`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "082c06c4e4bbf9245a327a68dd6e658d",
     "grade": false,
     "grade_id": "cell-667d895a7bdce38f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.7 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c28b66220bc6de62706de2b54fa689",
     "grade": true,
     "grade_id": "cell-d4ea9b654f5ac678",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e417622f4ce890f4c4393df0a309d421",
     "grade": false,
     "grade_id": "cell-ad40e9e61ba37ed6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.8**\n",
    "<br>{points: 1}\n",
    "\n",
    "Suppose you repeated the process above and took 100 more samples and calculated a 90% cofidence interval for each sample. How many of the 100 intervals would you expect to capture the true median of the population?\n",
    "\n",
    "_Assign your answer to an object called `answer1.8`. Your answer should be a single integer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9990fffac2dfd19de46e1db71c04b23f",
     "grade": false,
     "grade_id": "cell-20d3a4e79a063c02",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.8 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4444d19e6970491a76f6f32bb2533abe",
     "grade": true,
     "grade_id": "cell-8e27b4947d4866fb",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer1.8\"', {\n",
    "  expect_true(exists(\"answer1.8\"))\n",
    "})\n",
    "answer_as_numeric <- as.numeric(answer1.8)\n",
    "test_that(\"Solution should be a number\", {\n",
    "  expect_false(is.na(answer_as_numeric))\n",
    "})\n",
    "test_that(\"Solution should be an integer\", {\n",
    "  expect_true(answer_as_numeric %% 1 == 0)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "579395940a42ea27afeed737af0141df",
     "grade": false,
     "grade_id": "cell-90ccaf35bb6ea089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Breast Cancer Diagnosis\n",
    "\n",
    "In this section, we'll be working with a sample of characteristics of the cell nuclei of various breast masses. The data originates from University of Wisconsin Hospital, where a physician named Dr. William H. Wolberg obtained samples of breast lumps (or tumors) using a fine needle aspiration (FNA) biopsy. Images of the samples were digitized to compute the characteristics of the nuclei that you can find in the sample to work towards Dr. Wolberg's original goal of diagnosing new tumours mathematically using only a single FNA [(he was quite successful!)](https://www.pnas.org/content/87/23/9193.short). In the sample, the nuclei characteristics have been paired with the ultimate diagnosis of the mass (benign or malignant).\n",
    "\n",
    "<img src=\"http://pages.cs.wisc.edu/~street/saves/xcyt1.gif\n",
    "\" width=500>\n",
    "<div style=\"text-align: center\">A screenshot from Xcyt, a program that was developed by Dr. Wolberg for breast mass diagnoses using these data.<br><i>Image from <a href=\"https://moderndive.com/8-confidence-intervals.html#infer-workflow\">pages.cs.wisc.edu</i></a></div><br>\n",
    "\n",
    "This sample is located in the `datateachr` package, and is named `cancer_sample`. We are  interested in estimating the **proportion of the patients from the population whose breast masses are malignant** (`diagnosis == \"M\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0fa0d8449308f971963465b6d98c30c",
     "grade": false,
     "grade_id": "cell-97d69e73d0674bea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "head(cancer_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9ba371b2fa8d81b257c2eb47df58499",
     "grade": false,
     "grade_id": "cell-40898ae24f137226",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0**\n",
    "<br>{points: 3}\n",
    "\n",
    "Describe the population from which the sample `cancer_sample` was drawn from.\n",
    "\n",
    "**Note:** this question has a fairly wide range of acceptable answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "758c3dca7a8f12f784480e93cc5f7768",
     "grade": true,
     "grade_id": "cell-c8e6f6b5bbccd05b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e70550d71dd0c5b7ae6b3e1bb3bc0fe5",
     "grade": false,
     "grade_id": "cell-26332d818a4387fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br>{points: 3}\n",
    "\n",
    "Use the `infer` package workflow to calculate an 80% confidence interval for the proportion with malignant breast masses (`diagnosis == \"M\"`), using bootstrapping with 1000 replicates. Set your seed to 8943. Your final dataframe should have a single row and two columns named `lower_ci` and `upper_ci`.\n",
    "\n",
    "**Hint:** If you're stuck, don't be afraid to explore the [documentation for the `infer` package](https://cran.r-project.org/web/packages/infer/infer.pdf), peek at [Section 8.5 of ModernDive](https://moderndive.com/8-confidence-intervals.html#one-prop-ci), or ask someone for help! You can use your code from the previous section as a blueprint.\n",
    "\n",
    "_Assign your data frame to an object called `cancer_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58015b6a9d8a9e6e428715fbcd47c743",
     "grade": false,
     "grade_id": "cell-b3208e919708e3a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(8943) # DO NOT CHANGE!\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "cancer_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d81ba5294bb7787e00ad3ad3c806239b",
     "grade": true,
     "grade_id": "cell-a48f1ab67ab90f8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1eff2d367e1f321f38171a9c0bc2fce8",
     "grade": false,
     "grade_id": "cell-c136664317b779e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2**\n",
    "<br>{points: 3}\n",
    "\n",
    "Does the confidence interval capture the population parameter we are interested in? If there is no way to determine this for certain, explain why that is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0dc8ab43fb616518a71a405b362d4869",
     "grade": true,
     "grade_id": "cell-dace4e4a65f80abb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c509c810af1159e3a2a3d46f89b41b1",
     "grade": false,
     "grade_id": "cell-439bd5e9841feb5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br>{points: 3}\n",
    "\n",
    "In 1-2 sentences, explain one way you can interpret the confidence interval you calculated above (`cancer_ci`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47c8d031c2acec306273fc5d57fa2b61",
     "grade": true,
     "grade_id": "cell-7d0ade0ba996d669",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17ef2f8a26ea5a754f79a87d1748a67d",
     "grade": false,
     "grade_id": "cell-e62dad9584edaeb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Suppose you calculated another 80% confidence interval for the population proportion, but with a sample that was 5 times larger than `cancer_sample`. How would you expect this second interval compare to the first confidence interval you calculated above (`cancer_ci`)?\n",
    "\n",
    "A. The second confidence interval would likely be narrower than the first.\n",
    "\n",
    "B. The second confidence interval would likely be about the same width as the first.\n",
    "\n",
    "C. The second confidence interval would likely be wider than the first.\n",
    "\n",
    "D. There is no way to tell how the second interval would compare to the first.\n",
    "\n",
    "_Assign your answer to an object called `answer2.4`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed6880dc41e3c65b21111c33e18ba7a4",
     "grade": false,
     "grade_id": "cell-f8ebc2b8a4e59c38",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.4 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cb27645bd1b22b9cbe2159742be08c1",
     "grade": true,
     "grade_id": "cell-1c527e7a33c44b58",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer2.4\"', {\n",
    "  expect_true(exists(\"answer2.4\"))\n",
    "})\n",
    "test_that('Solution should be a single character (\"A\", \"B\", \"C\", or \"D\")', {\n",
    "  expect_match(answer2.4, \"a|b|c|d\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59c10a1e2e63fdc78f6ebcdcb371813e",
     "grade": false,
     "grade_id": "cell-ede7d2d839cfd7d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Bow River at Banff: 100-Year Flood\n",
    "\n",
    "Sample quantiles, like the other statistics we have introduced such as the sample mean and standard deviation, can also be considered as a point estimate of a population parameter. Meaning, quantiles can be used to describe the distribution of a quantitative variable of a population; each distribution has a unique 0.4 quantile, 0.93 quantile, and so on. One common usage of quantiles is to estimate N-year floods. An N-year flood is defined as smallest possible severety for a flood that we **expect** to occur once every N years (but could occur more or less than once in any given N-year span). To calculate a point estimate N-year flood, one must find a quantile such that $\\frac{1}{N}$ known observations fall above it. Also, like the other population parameters we have mentioned, we can also calculate a **confidence interval** for this parameter, which is what we will be doing in this section.\n",
    "\n",
    "\n",
    "In 2013, a combination of factors lead to the Bow River reaching very high flow rates (466 ${\\text{m}^3}/{\\text{s}}$ near Banff), which contributed to extreme flooding throughout Alberta, the Canadian province that lies directly east of British Columbia. One photograph of the event is shown above. For many years the Government of Canada has been collecting hydrometric data at many different stations for several rivers, including the Bow River. So, what's the least severe flood due to high Bow River flow rates that Albertans can expect every 100 years? To answer this question, our goal is calculate a **95% confidence interval for the 100-year flood** (the $1 - \\frac{1}{100} = 0.99$ quantile) using the **maxima** flow rate data collected at the Banff Bow River station, recorded in ${\\text{m}^3}/{\\text{s}}$. This data is located [here](https://wateroffice.ec.gc.ca/report/historical_e.html?stn=05BB001&dataType=Annual+Extremes&parameterType=Flow&year=2018&mode=Table) but we have already tidied the data for you and included it in the `datateachr` package under the name `flow_sample`.\n",
    "\n",
    "`flow_sample` contains information about the maximum _and_ minimum flow rates for each year, so we need to filter the data set for **flow maxima**. We have done this for you in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "264de0861282cf155f80a526fe692a06",
     "grade": false,
     "grade_id": "cell-bd77bcb71614f9ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "flow_sample <- flow_sample %>% \n",
    "    filter(extreme_type == \"maximum\")\n",
    "\n",
    "head(flow_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a62b9f437a5fae6ed9b602708345eaf",
     "grade": false,
     "grade_id": "cell-899204d1a64f2bfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.0**\n",
    "<br>{points: 3}\n",
    "\n",
    "The data contained in `flow_sample` is considered a sample. Describe the population from which the sample was drawn from.\n",
    "\n",
    "**Note:** there may more than one solution to this question depending on how one interprets \"population\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50d40f9d93bd6e5036808cde1e064d62",
     "grade": true,
     "grade_id": "cell-31c1a7ca3535d01a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cf3095d95de7f39a0c10c4a40daa35c",
     "grade": false,
     "grade_id": "cell-c6f632ef113e101b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1**\n",
    "<br>{points: 3}\n",
    "\n",
    "Use the `infer` package workflow to generate bootstrap distribution of the appropriate sample quantiles for `flow_sample` using 3000 bootstrap replicates. Set your seed to 4629. Your final dataframe should have the columns `replicate` and `stat`.\n",
    "\n",
    "**IMPORTANT NOTE:** because the `calculate` function does not support using quantiles as the sample statistic, here we have to use the `summarize` function. Thus, in place of the line where you would usually use `calculate` with the `infer` package workflow, you can use the following line:\n",
    "\n",
    "```r\n",
    "    ... %>%\n",
    "    summarize(stat = quantile(flow, probs = 0.99))\n",
    "```\n",
    "\n",
    "_Assign your data frame to an object called `flow_bootstrapped`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b956204cc704c08c7e3a70de5382daf7",
     "grade": false,
     "grade_id": "cell-0355d24604d1db72",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(4629) # DO NOT CHANGE!\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(flow_bootstrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47e10cb1d924af0840b7ffb8ae2bd99c",
     "grade": true,
     "grade_id": "cell-6773d36ab69a5944",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"flow_bootstrapped\"', {\n",
    "  expect_true(exists(\"flow_bootstrapped\"))\n",
    "})\n",
    "test_that(\"Solution should be a data frame\", {\n",
    "  expect_true(\"data.frame\" %in% class(flow_bootstrapped))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c63b08b0eaf03c135810545fc1be74f8",
     "grade": false,
     "grade_id": "cell-0654e2f42a6a3bc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2**\n",
    "<br>{points: 3}\n",
    "\n",
    "Use the appropriate function from the `infer` package to calculate a 95% confidence interval for the 100-year flood from the bootstrap distribution you just generated. Your final dataframe should have a single row and two columns named `lower_ci` and `upper_ci`.\n",
    "\n",
    "_Assign your data frame to an object called `flow_ci`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "183cc268fd2176442c27288ac786313d",
     "grade": false,
     "grade_id": "cell-4b586362c8579701",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "head(flow_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "068c492e6e95a8b4f765c3c8acc46a98",
     "grade": true,
     "grade_id": "cell-0452ee4cd567c75f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"flow_ci\"', {\n",
    "  expect_true(exists(\"flow_ci\"))\n",
    "})\n",
    "test_that(\"Solution should be a data frame\", {\n",
    "  expect_true(\"data.frame\" %in% class(flow_ci))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85ef64954d9286a02648c326d3bb5e51",
     "grade": false,
     "grade_id": "cell-38ba2cf206a30f11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br> {points: 3}\n",
    "\n",
    "Create an **effective** visualization of the confidence interval `flow_ci` and its associated bootstrap distribution `flow_bootstrapped`. Use whichever layers and arguments you wish. \n",
    "\n",
    "**Hint:** if you want some inspiration, check out https://www.r-graph-gallery.com/index.html!\n",
    "\n",
    "_Assign your plot to an object called `flow_ci_plot`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8aef645e0a789179cf12d3127b7f14ca",
     "grade": true,
     "grade_id": "cell-b2ea95c2613769e0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "steam_ci_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22f33c6ff2c2aadb3c8d44c7e6b363fa",
     "grade": false,
     "grade_id": "cell-d8c1d59bb6a4338c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_Use your plot above to help you answer the **next 3 questions**._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d27982dacde907bf7d8c0e46c0d276f",
     "grade": false,
     "grade_id": "cell-83d097657c5a693e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "There is a 50% chance that the true 100-year flood value is captured by the confidence interval `flow_ci`.\n",
    "\n",
    "_Assign your answer to an object called `answer3.4`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5eb1cc95b98041a9d937075d7f7dd5bd",
     "grade": false,
     "grade_id": "cell-d9a4eb2e56e2ecbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.4 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1273d1a108bc3b986eb3b77da8991ea",
     "grade": true,
     "grade_id": "cell-3eb0b62c08bdfbe9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer3.4\"', {\n",
    "  expect_true(exists(\"answer3.4\"))\n",
    "})\n",
    "test_that('Answer should be \"true\" or \"false\"', {\n",
    "  expect_match(answer3.4, \"true|false\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0155c66c81fcdbc77819fe910c19e6b",
     "grade": false,
     "grade_id": "cell-d03d1d2daa5f780e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "We are 95% confident that the true 100-year flood value is captured by the confidence interval `flow_ci`.\n",
    "\n",
    "_Assign your answer to an object called `answer3.5`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba88552f56b0fc18f9bdccaf0504f839",
     "grade": false,
     "grade_id": "cell-f67f3bc2d2cecd09",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.5 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54113c16b8c59d11e1c4a1afcd5ba752",
     "grade": true,
     "grade_id": "cell-2c25ad9596dad135",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer3.5\"', {\n",
    "  expect_true(exists(\"answer3.5\"))\n",
    "})\n",
    "test_that('Answer should be \"true\" or \"false\"', {\n",
    "  expect_match(answer3.5, \"true|false\", ignore.case = TRUE)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d005791cc14cfdbef2be34df2bb7ee1",
     "grade": false,
     "grade_id": "cell-008bc1078d0f8846",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "If we increased the confidence level of the confidence interval `flow_ci`, we would expect that it would become narrower.\n",
    "\n",
    "_Assign your answer to an object called `answer3.6`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2484a9220502b270eb1ead910fbdb627",
     "grade": false,
     "grade_id": "cell-91d3dae1fa9afd59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3a1b6a0d2ff99c9da63385dad92c518",
     "grade": true,
     "grade_id": "cell-8375139f411d5d82",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we check to see if you have given your answer the correct object name\n",
    "# and if your answer is plausible. However, all other tests have been hidden\n",
    "# so you can practice deciding when you have the correct answer.\n",
    "test_that('Did not assign answer to an object called \"answer3.6\"', {\n",
    "  expect_true(exists(\"answer3.6\"))\n",
    "})\n",
    "test_that('Answer should be \"true\" or \"false\"', {\n",
    "  expect_match(answer3.6, \"true|false\", ignore.case = TRUE)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "docker": {
   "latest_image_tag": "v0.4.0"
  },
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
